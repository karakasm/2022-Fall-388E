{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bf1d5d9-ebc2-4c75-bea7-ea145ca2270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wbgapi as wb\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d5c5c7-3cfd-4ef7-bdad-165a379ec8d3",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "For today's lecture, I am using the 3rd Chapter of [Introduction to Statistical Learning](https://www-bcf.usc.edu/~gareth/ISL/) by Gareth et.al., 3rd Chapter of [Elements of Statistical Learning](https://web.stanford.edu/~hastie/ElemStatLearn/) by Hastie et.al. and the 3rd Chapter of [Pattern Recognition and Machine Learning](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf) by Bishop.\n",
    "\n",
    "## Ordinary Least Squares Regression\n",
    "\n",
    "Assume we have a data set consisting of numerical pairs $(x_i,y_i)$, and assume also that upon some inspection, we guess that there is a linear dependence between $x_i$'s and $y_i$'s of the form\n",
    "\n",
    "$$  y_i \\approx \\alpha x_i + \\beta + \\epsilon $$\n",
    "\n",
    "In this scenario, we assume the $y_i$ values depend on $x_i$ values functionally, moreover, we also assume that the functional relationship is linear. In such cases, $y_i$'s are called *dependent variable* and $x_i$'s are called *independent variables*. Our task is then to calculate the best fitting $\\alpha$ and $\\beta$ for this set.\n",
    "\n",
    "## How and why does linear regression work?\n",
    "   \n",
    "The question we need to ask is, in linear regression what is our **fit criteria** or what is our **error function**?\n",
    "\n",
    "$$ RSS(\\alpha,\\beta) = \\sum_{i=1}^N (\\alpha x_i + \\beta - y_i)^2 $$\n",
    "\n",
    "The (ordinary least square) regression finds $\\alpha$ and $\\beta$ that minimizes this function $RSS(\\alpha,\\beta)$:\n",
    "$$ \\alpha = \\frac{\\sum_i (x_i - \\overline{x})(y_i - \\overline{y})}{\\sum_i (x_i - \\overline{x})^2}, \\qquad \\beta = \\overline{y} - \\alpha \\overline{x} $$\n",
    "    \n",
    "## How do we judge if the model fit?\n",
    "\n",
    "The $R^2$-statistic tells us how much of the error is explained by the independent variable:\n",
    "$$ RSE(\\alpha,\\beta) = \\sqrt{\\frac{RSS(\\alpha,\\beta)}{n-2}}, \\qquad R^2 = 1 - \\frac{RSE}{RSS} $$\n",
    "\n",
    "\n",
    "## Examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd531602-b91a-450e-b88d-6bbbf4c8bd96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>series</th>\n",
       "      <th>economy</th>\n",
       "      <th>aggregate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SE.ADT.LITR.FE.ZS</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>False</td>\n",
       "      <td>YR2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SE.ADT.LITR.FE.ZS</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>False</td>\n",
       "      <td>YR2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SE.ADT.LITR.FE.ZS</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>False</td>\n",
       "      <td>YR2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SE.ADT.LITR.FE.ZS</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>False</td>\n",
       "      <td>YR2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SE.ADT.LITR.FE.ZS</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>False</td>\n",
       "      <td>YR2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16487</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SE.ADT.LITR.FE.ZS</td>\n",
       "      <td>AFE</td>\n",
       "      <td>True</td>\n",
       "      <td>YR1964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16488</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SE.ADT.LITR.FE.ZS</td>\n",
       "      <td>AFE</td>\n",
       "      <td>True</td>\n",
       "      <td>YR1963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16489</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SE.ADT.LITR.FE.ZS</td>\n",
       "      <td>AFE</td>\n",
       "      <td>True</td>\n",
       "      <td>YR1962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16490</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SE.ADT.LITR.FE.ZS</td>\n",
       "      <td>AFE</td>\n",
       "      <td>True</td>\n",
       "      <td>YR1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16491</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SE.ADT.LITR.FE.ZS</td>\n",
       "      <td>AFE</td>\n",
       "      <td>True</td>\n",
       "      <td>YR1960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16492 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       value             series economy  aggregate    time\n",
       "0        NaN  SE.ADT.LITR.FE.ZS     ZWE      False  YR2021\n",
       "1        NaN  SE.ADT.LITR.FE.ZS     ZWE      False  YR2020\n",
       "2        NaN  SE.ADT.LITR.FE.ZS     ZWE      False  YR2019\n",
       "3        NaN  SE.ADT.LITR.FE.ZS     ZWE      False  YR2018\n",
       "4        NaN  SE.ADT.LITR.FE.ZS     ZWE      False  YR2017\n",
       "...      ...                ...     ...        ...     ...\n",
       "16487    NaN  SE.ADT.LITR.FE.ZS     AFE       True  YR1964\n",
       "16488    NaN  SE.ADT.LITR.FE.ZS     AFE       True  YR1963\n",
       "16489    NaN  SE.ADT.LITR.FE.ZS     AFE       True  YR1962\n",
       "16490    NaN  SE.ADT.LITR.FE.ZS     AFE       True  YR1961\n",
       "16491    NaN  SE.ADT.LITR.FE.ZS     AFE       True  YR1960\n",
       "\n",
       "[16492 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "litrate = pd.DataFrame(list(wb.data.fetch('SE.ADT.LITR.FE.ZS')))\n",
    "litrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4f28b5c-a037-46a7-b640-e8e60e14386d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>series</th>\n",
       "      <th>economy</th>\n",
       "      <th>aggregate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SH.DYN.MORT</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>False</td>\n",
       "      <td>YR2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.9</td>\n",
       "      <td>SH.DYN.MORT</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>False</td>\n",
       "      <td>YR2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.2</td>\n",
       "      <td>SH.DYN.MORT</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>False</td>\n",
       "      <td>YR2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.8</td>\n",
       "      <td>SH.DYN.MORT</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>False</td>\n",
       "      <td>YR2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.0</td>\n",
       "      <td>SH.DYN.MORT</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>False</td>\n",
       "      <td>YR2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16487</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SH.DYN.MORT</td>\n",
       "      <td>AFE</td>\n",
       "      <td>True</td>\n",
       "      <td>YR1964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16488</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SH.DYN.MORT</td>\n",
       "      <td>AFE</td>\n",
       "      <td>True</td>\n",
       "      <td>YR1963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16489</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SH.DYN.MORT</td>\n",
       "      <td>AFE</td>\n",
       "      <td>True</td>\n",
       "      <td>YR1962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16490</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SH.DYN.MORT</td>\n",
       "      <td>AFE</td>\n",
       "      <td>True</td>\n",
       "      <td>YR1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16491</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SH.DYN.MORT</td>\n",
       "      <td>AFE</td>\n",
       "      <td>True</td>\n",
       "      <td>YR1960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16492 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       value       series economy  aggregate    time\n",
       "0        NaN  SH.DYN.MORT     ZWE      False  YR2021\n",
       "1       53.9  SH.DYN.MORT     ZWE      False  YR2020\n",
       "2       54.2  SH.DYN.MORT     ZWE      False  YR2019\n",
       "3       54.8  SH.DYN.MORT     ZWE      False  YR2018\n",
       "4       57.0  SH.DYN.MORT     ZWE      False  YR2017\n",
       "...      ...          ...     ...        ...     ...\n",
       "16487    NaN  SH.DYN.MORT     AFE       True  YR1964\n",
       "16488    NaN  SH.DYN.MORT     AFE       True  YR1963\n",
       "16489    NaN  SH.DYN.MORT     AFE       True  YR1962\n",
       "16490    NaN  SH.DYN.MORT     AFE       True  YR1961\n",
       "16491    NaN  SH.DYN.MORT     AFE       True  YR1960\n",
       "\n",
       "[16492 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mortality = pd.DataFrame(list(wb.data.fetch('SH.DYN.MORT')))\n",
    "mortality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4fd0a11-6cbe-4caa-b4f2-82c9f868397e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>literacy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>YR2021</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YR2020</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YR2019</th>\n",
       "      <td>94.424042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YR2018</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YR2017</th>\n",
       "      <td>93.498268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YR1964</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YR1963</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YR1962</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YR1961</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YR1960</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         literacy\n",
       "time             \n",
       "YR2021        NaN\n",
       "YR2020        NaN\n",
       "YR2019  94.424042\n",
       "YR2018        NaN\n",
       "YR2017  93.498268\n",
       "...           ...\n",
       "YR1964        NaN\n",
       "YR1963        NaN\n",
       "YR1962        NaN\n",
       "YR1961        NaN\n",
       "YR1960        NaN\n",
       "\n",
       "[62 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltr = litrate[['time','value']][litrate['economy']=='TUR']\n",
    "ltr.index = ltr.time\n",
    "del ltr['time']\n",
    "ltr.columns = [['literacy']]\n",
    "ltr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56aaa058-e607-4a53-bcf5-004cb1432b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mortality</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>YR2021</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YR2020</th>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YR2019</th>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YR2018</th>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YR2017</th>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YR1964</th>\n",
       "      <td>225.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YR1963</th>\n",
       "      <td>233.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YR1962</th>\n",
       "      <td>241.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YR1961</th>\n",
       "      <td>249.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YR1960</th>\n",
       "      <td>257.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mortality\n",
       "time            \n",
       "YR2021       NaN\n",
       "YR2020       9.5\n",
       "YR2019      10.1\n",
       "YR2018      10.7\n",
       "YR2017      11.4\n",
       "...          ...\n",
       "YR1964     225.7\n",
       "YR1963     233.5\n",
       "YR1962     241.4\n",
       "YR1961     249.3\n",
       "YR1960     257.0\n",
       "\n",
       "[62 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtr = mortality[['time','value']][mortality['economy']=='TUR']\n",
    "mtr.index = mtr.time\n",
    "del mtr['time']\n",
    "mtr.columns = [['mortality']]\n",
    "mtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d4938fa-9f64-4253-84a6-1c553c79eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(df,cntry,name):\n",
    "    tmp = df[['time','value']][df['economy']==cntry]\n",
    "    tmp.index = tmp.time\n",
    "    del tmp['time']\n",
    "    tmp.columns = [[name]]\n",
    "    return tmp\n",
    "\n",
    "def litvsmor(cntry):\n",
    "    lit = extract(litrate,cntry,'literacy')\n",
    "    mor = extract(mortality,cntry,'mortality')\n",
    "    res = mor.join(lit)\n",
    "    res.dropna(inplace=True)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d1ce9e7-ae09-4722-9c91-dec8b734f428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f6cab537490>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr = litvsmor('TUR')\n",
    "plt.scatter(tr['literacy'],tr['mortality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4db80dd3-404d-44c2-b6ab-676df5e9a270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              mortality   R-squared:                       0.945\n",
      "Model:                            OLS   Adj. R-squared:                  0.942\n",
      "Method:                 Least Squares   F-statistic:                     275.9\n",
      "Date:                Sun, 16 Oct 2022   Prob (F-statistic):           1.64e-11\n",
      "Time:                        19:52:12   Log-Likelihood:                -67.223\n",
      "No. Observations:                  18   AIC:                             138.4\n",
      "Df Residuals:                      16   BIC:                             140.2\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const           273.0338     14.304     19.089      0.000     242.712     303.356\n",
      "('literacy',)    -2.8762      0.173    -16.611      0.000      -3.243      -2.509\n",
      "==============================================================================\n",
      "Omnibus:                        2.728   Durbin-Watson:                   0.508\n",
      "Prob(Omnibus):                  0.256   Jarque-Bera (JB):                1.852\n",
      "Skew:                          -0.596   Prob(JB):                        0.396\n",
      "Kurtosis:                       1.976   Cond. No.                         467.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaygun/.local/lib/python3.10/site-packages/scipy/stats/_stats_py.py:1477: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=18\n",
      "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6cab24ae30>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = litvsmor('TUR')\n",
    "X = res['literacy']\n",
    "Y = res['mortality']\n",
    "XX = sm.add_constant(X)\n",
    "model = sm.OLS(Y,XX)\n",
    "results = model.fit()\n",
    "alpha,beta = results.params\n",
    "print(results.summary())\n",
    "plt.scatter(X,Y,c='red')\n",
    "plt.plot(X,alpha + beta*X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a976e7b-247e-42ee-9014-32b2863a90d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>series</th>\n",
       "      <th>economy</th>\n",
       "      <th>aggregate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SI.POV.GINI</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>False</td>\n",
       "      <td>YR2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SI.POV.GINI</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>False</td>\n",
       "      <td>YR2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.3</td>\n",
       "      <td>SI.POV.GINI</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>False</td>\n",
       "      <td>YR2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SI.POV.GINI</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>False</td>\n",
       "      <td>YR2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.3</td>\n",
       "      <td>SI.POV.GINI</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>False</td>\n",
       "      <td>YR2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16487</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SI.POV.GINI</td>\n",
       "      <td>AFE</td>\n",
       "      <td>True</td>\n",
       "      <td>YR1964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16488</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SI.POV.GINI</td>\n",
       "      <td>AFE</td>\n",
       "      <td>True</td>\n",
       "      <td>YR1963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16489</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SI.POV.GINI</td>\n",
       "      <td>AFE</td>\n",
       "      <td>True</td>\n",
       "      <td>YR1962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16490</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SI.POV.GINI</td>\n",
       "      <td>AFE</td>\n",
       "      <td>True</td>\n",
       "      <td>YR1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16491</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SI.POV.GINI</td>\n",
       "      <td>AFE</td>\n",
       "      <td>True</td>\n",
       "      <td>YR1960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16492 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       value       series economy  aggregate    time\n",
       "0        NaN  SI.POV.GINI     ZWE      False  YR2021\n",
       "1        NaN  SI.POV.GINI     ZWE      False  YR2020\n",
       "2       50.3  SI.POV.GINI     ZWE      False  YR2019\n",
       "3        NaN  SI.POV.GINI     ZWE      False  YR2018\n",
       "4       44.3  SI.POV.GINI     ZWE      False  YR2017\n",
       "...      ...          ...     ...        ...     ...\n",
       "16487    NaN  SI.POV.GINI     AFE       True  YR1964\n",
       "16488    NaN  SI.POV.GINI     AFE       True  YR1963\n",
       "16489    NaN  SI.POV.GINI     AFE       True  YR1962\n",
       "16490    NaN  SI.POV.GINI     AFE       True  YR1961\n",
       "16491    NaN  SI.POV.GINI     AFE       True  YR1960\n",
       "\n",
       "[16492 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini = pd.DataFrame(list(wb.data.fetch('SI.POV.GINI')))\n",
    "gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0c8c1f5-abd6-4ca8-92d3-599c6c00203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def morvsgini(cntry):\n",
    "    gin = extract(gini,cntry,'gini')\n",
    "    mor = extract(mortality,cntry,'mortality')\n",
    "    res = gin.join(mor)\n",
    "    res.dropna(inplace=True)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37d16130-1432-42ba-8271-a8a9445f5e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              mortality   R-squared:                       0.117\n",
      "Model:                            OLS   Adj. R-squared:                  0.068\n",
      "Method:                 Least Squares   F-statistic:                     2.390\n",
      "Date:                Sun, 16 Oct 2022   Prob (F-statistic):              0.140\n",
      "Time:                        19:52:40   Log-Likelihood:                -85.053\n",
      "No. Observations:                  20   AIC:                             174.1\n",
      "Df Residuals:                      18   BIC:                             176.1\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       -153.7370    115.269     -1.334      0.199    -395.908      88.434\n",
      "('gini',)      4.3506      2.814      1.546      0.140      -1.562      10.263\n",
      "==============================================================================\n",
      "Omnibus:                       14.299   Durbin-Watson:                   0.259\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               12.989\n",
      "Skew:                           1.519   Prob(JB):                      0.00151\n",
      "Kurtosis:                       5.521   Cond. No.                     1.18e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.18e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6caaeac040>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = morvsgini('TUR')\n",
    "X = res['gini']\n",
    "Y = res['mortality']\n",
    "XX = sm.add_constant(X)\n",
    "model = sm.OLS(Y,XX)\n",
    "results = model.fit()\n",
    "alpha,beta = results.params\n",
    "print(results.summary())\n",
    "plt.scatter(X,Y,c='red')\n",
    "plt.plot(X,alpha + beta*X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0f44f21-15ba-485b-a7ee-51c890efc06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def litvsgini(cntry):\n",
    "    lit = extract(litrate,cntry,'literacy')\n",
    "    gin = extract(gini,cntry,'gini')\n",
    "    res = gin.join(lit)\n",
    "    res.dropna(inplace=True)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0f3434a5-1a3e-460c-9323-895698a59a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f6c902a5e10>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = litvsgini('TUR')\n",
    "plt.scatter(res['literacy'],res['gini'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8e8fc4a4-9c3a-430f-be4e-71106bf6f6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               literacy   R-squared:                       0.107\n",
      "Model:                            OLS   Adj. R-squared:                  0.033\n",
      "Method:                 Least Squares   F-statistic:                     1.445\n",
      "Date:                Mon, 17 Oct 2022   Prob (F-statistic):              0.252\n",
      "Time:                        15:01:55   Log-Likelihood:                -42.787\n",
      "No. Observations:                  14   AIC:                             89.57\n",
      "Df Residuals:                      12   BIC:                             90.85\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         35.4346     43.975      0.806      0.436     -60.379     131.249\n",
      "('gini',)      1.2991      1.081      1.202      0.252      -1.055       3.654\n",
      "==============================================================================\n",
      "Omnibus:                        3.230   Durbin-Watson:                   0.141\n",
      "Prob(Omnibus):                  0.199   Jarque-Bera (JB):                2.368\n",
      "Skew:                          -0.954   Prob(JB):                        0.306\n",
      "Kurtosis:                       2.351   Cond. No.                     1.21e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.21e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaygun/.local/lib/python3.10/site-packages/scipy/stats/_stats_py.py:1477: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=14\n",
      "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6c902c8ee0>]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = res['gini']\n",
    "Y = res['literacy']\n",
    "XX = sm.add_constant(X)\n",
    "model = sm.OLS(Y,XX)\n",
    "results = model.fit()\n",
    "alpha,beta = results.params\n",
    "print(results.summary())\n",
    "plt.scatter(X,Y,c='red')\n",
    "plt.plot(X,alpha + beta*X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0148fbc-3578-4521-b757-b913f0bc65e5",
   "metadata": {},
   "source": [
    "## Multiple linear regression\n",
    "\n",
    "This time the data set we have is of the form $(x_{1i},\\ldots,x_{mi},y_i)$ and we assume we have a functional relation of the form\n",
    "$$ y_i \\approx \\beta + \\sum_j \\alpha_j x_{ji} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49e06bee-9218-4a51-ab32-c9c08e07956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lit_gin_mor(cntry):\n",
    "    lit = extract(litrate,cntry,'literacy')\n",
    "    gin = extract(gini,cntry,'gini')\n",
    "    mor = extract(mortality,cntry,'mortality')\n",
    "    res = lit.join([gin,mor])\n",
    "    res.dropna(inplace=True)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "aa573d98-5fe3-4035-8d6b-4292ee667864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              mortality   R-squared:                       0.115\n",
      "Model:                            OLS   Adj. R-squared:                 -0.771\n",
      "Method:                 Least Squares   F-statistic:                    0.1293\n",
      "Date:                Mon, 17 Oct 2022   Prob (F-statistic):              0.885\n",
      "Time:                        15:16:49   Log-Likelihood:                0.31045\n",
      "No. Observations:                   5   AIC:                             5.379\n",
      "Df Residuals:                       2   BIC:                             4.207\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const             4.3881     11.511      0.381      0.740     -45.139      53.915\n",
      "('literacy',)    -0.0226      0.062     -0.365      0.750      -0.289       0.244\n",
      "('gini',)         0.0556      0.245      0.227      0.842      -1.000       1.111\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   1.365\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.512\n",
      "Skew:                           0.335   Prob(JB):                        0.774\n",
      "Kurtosis:                       1.583   Cond. No.                     7.14e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.14e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaygun/.local/lib/python3.10/site-packages/statsmodels/stats/stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 5 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n"
     ]
    }
   ],
   "source": [
    "res = lit_gin_mor('GRC')\n",
    "X = res[['literacy','gini']]\n",
    "XX = sm.add_constant(X)\n",
    "Y = res['mortality']\n",
    "model = sm.OLS(Y,XX)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d0aa36-3ea8-4419-b69f-2ffff124dd47",
   "metadata": {},
   "source": [
    "## Which of the independent variables explain the dependent variable better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24b0845e-7b13-452b-99e6-59b44b63d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ef839240-bb66-4329-a291-70d0196db307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              mortality   R-squared:                       0.985\n",
      "Model:                            OLS   Adj. R-squared:                  0.981\n",
      "Method:                 Least Squares   F-statistic:                     219.2\n",
      "Date:                Mon, 17 Oct 2022   Prob (F-statistic):           2.03e-09\n",
      "Time:                        15:21:58   Log-Likelihood:                -14.460\n",
      "No. Observations:                  14   AIC:                             36.92\n",
      "Df Residuals:                      10   BIC:                             39.48\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept      -398.3536    115.915     -3.437      0.006    -656.629    -140.078\n",
      "gini             12.3062      2.822      4.361      0.001       6.019      18.593\n",
      "literacy          4.7553      1.344      3.537      0.005       1.760       7.751\n",
      "gini:literacy    -0.1404      0.033     -4.294      0.002      -0.213      -0.068\n",
      "==============================================================================\n",
      "Omnibus:                        0.555   Durbin-Watson:                   1.551\n",
      "Prob(Omnibus):                  0.758   Jarque-Bera (JB):                0.554\n",
      "Skew:                           0.020   Prob(JB):                        0.758\n",
      "Kurtosis:                       2.026   Cond. No.                     1.94e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.94e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaygun/.local/lib/python3.10/site-packages/scipy/stats/_stats_py.py:1477: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=14\n",
      "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>mean_sq</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gini</th>\n",
       "      <td>1.0</td>\n",
       "      <td>32.362351</td>\n",
       "      <td>32.362351</td>\n",
       "      <td>50.032349</td>\n",
       "      <td>3.402071e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>literacy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>381.000077</td>\n",
       "      <td>381.000077</td>\n",
       "      <td>589.027934</td>\n",
       "      <td>3.212981e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gini:literacy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.926429</td>\n",
       "      <td>11.926429</td>\n",
       "      <td>18.438316</td>\n",
       "      <td>1.576286e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>10.0</td>\n",
       "      <td>6.468285</td>\n",
       "      <td>0.646829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 df      sum_sq     mean_sq           F        PR(>F)\n",
       "gini            1.0   32.362351   32.362351   50.032349  3.402071e-05\n",
       "literacy        1.0  381.000077  381.000077  589.027934  3.212981e-10\n",
       "gini:literacy   1.0   11.926429   11.926429   18.438316  1.576286e-03\n",
       "Residual       10.0    6.468285    0.646829         NaN           NaN"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = lit_gin_mor('TUR')\n",
    "model = ols('mortality ~ gini * literacy', data=res).fit()\n",
    "print(model.summary())\n",
    "sm.stats.anova_lm(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a171e79a-4199-4e7e-9100-e93cfc873b9c",
   "metadata": {},
   "source": [
    "## Another example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1f74f35d-7065-4c8d-9f8c-a1704b93fa07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BP</th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight</th>\n",
       "      <th>BSA</th>\n",
       "      <th>Dur</th>\n",
       "      <th>Pulse</th>\n",
       "      <th>Stress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>47</td>\n",
       "      <td>85.4</td>\n",
       "      <td>1.75</td>\n",
       "      <td>5.1</td>\n",
       "      <td>63</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115</td>\n",
       "      <td>49</td>\n",
       "      <td>94.2</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.8</td>\n",
       "      <td>70</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116</td>\n",
       "      <td>49</td>\n",
       "      <td>95.3</td>\n",
       "      <td>1.98</td>\n",
       "      <td>8.2</td>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117</td>\n",
       "      <td>50</td>\n",
       "      <td>94.7</td>\n",
       "      <td>2.01</td>\n",
       "      <td>5.8</td>\n",
       "      <td>73</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112</td>\n",
       "      <td>51</td>\n",
       "      <td>89.4</td>\n",
       "      <td>1.89</td>\n",
       "      <td>7.0</td>\n",
       "      <td>72</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>121</td>\n",
       "      <td>48</td>\n",
       "      <td>99.5</td>\n",
       "      <td>2.25</td>\n",
       "      <td>9.3</td>\n",
       "      <td>71</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>121</td>\n",
       "      <td>49</td>\n",
       "      <td>99.8</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.5</td>\n",
       "      <td>69</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>110</td>\n",
       "      <td>47</td>\n",
       "      <td>90.9</td>\n",
       "      <td>1.90</td>\n",
       "      <td>6.2</td>\n",
       "      <td>66</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>110</td>\n",
       "      <td>49</td>\n",
       "      <td>89.2</td>\n",
       "      <td>1.83</td>\n",
       "      <td>7.1</td>\n",
       "      <td>69</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>114</td>\n",
       "      <td>48</td>\n",
       "      <td>92.7</td>\n",
       "      <td>2.07</td>\n",
       "      <td>5.6</td>\n",
       "      <td>64</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>114</td>\n",
       "      <td>47</td>\n",
       "      <td>94.4</td>\n",
       "      <td>2.07</td>\n",
       "      <td>5.3</td>\n",
       "      <td>74</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>115</td>\n",
       "      <td>49</td>\n",
       "      <td>94.1</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.6</td>\n",
       "      <td>71</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>114</td>\n",
       "      <td>50</td>\n",
       "      <td>91.6</td>\n",
       "      <td>2.05</td>\n",
       "      <td>10.2</td>\n",
       "      <td>68</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>106</td>\n",
       "      <td>45</td>\n",
       "      <td>87.1</td>\n",
       "      <td>1.92</td>\n",
       "      <td>5.6</td>\n",
       "      <td>67</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>125</td>\n",
       "      <td>52</td>\n",
       "      <td>101.3</td>\n",
       "      <td>2.19</td>\n",
       "      <td>10.0</td>\n",
       "      <td>76</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114</td>\n",
       "      <td>46</td>\n",
       "      <td>94.5</td>\n",
       "      <td>1.98</td>\n",
       "      <td>7.4</td>\n",
       "      <td>69</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>106</td>\n",
       "      <td>46</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.6</td>\n",
       "      <td>62</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>113</td>\n",
       "      <td>46</td>\n",
       "      <td>94.5</td>\n",
       "      <td>1.90</td>\n",
       "      <td>4.3</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>110</td>\n",
       "      <td>48</td>\n",
       "      <td>90.5</td>\n",
       "      <td>1.88</td>\n",
       "      <td>9.0</td>\n",
       "      <td>71</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>122</td>\n",
       "      <td>56</td>\n",
       "      <td>95.7</td>\n",
       "      <td>2.09</td>\n",
       "      <td>7.0</td>\n",
       "      <td>75</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BP  Age  Weight   BSA   Dur  Pulse  Stress\n",
       "0   105   47    85.4  1.75   5.1     63      33\n",
       "1   115   49    94.2  2.10   3.8     70      14\n",
       "2   116   49    95.3  1.98   8.2     72      10\n",
       "3   117   50    94.7  2.01   5.8     73      99\n",
       "4   112   51    89.4  1.89   7.0     72      95\n",
       "5   121   48    99.5  2.25   9.3     71      10\n",
       "6   121   49    99.8  2.25   2.5     69      42\n",
       "7   110   47    90.9  1.90   6.2     66       8\n",
       "8   110   49    89.2  1.83   7.1     69      62\n",
       "9   114   48    92.7  2.07   5.6     64      35\n",
       "10  114   47    94.4  2.07   5.3     74      90\n",
       "11  115   49    94.1  1.98   5.6     71      21\n",
       "12  114   50    91.6  2.05  10.2     68      47\n",
       "13  106   45    87.1  1.92   5.6     67      80\n",
       "14  125   52   101.3  2.19  10.0     76      98\n",
       "15  114   46    94.5  1.98   7.4     69      95\n",
       "16  106   46    87.0  1.87   3.6     62      18\n",
       "17  113   46    94.5  1.90   4.3     70      12\n",
       "18  110   48    90.5  1.88   9.0     71      99\n",
       "19  122   56    95.7  2.09   7.0     75      99"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp = pd.read_csv('https://online.stat.psu.edu/onlinecourses/sites/stat501/files/data/bloodpress.txt',sep='\\t')\n",
    "del bp['Pt']\n",
    "bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a353e87c-3727-4419-a900-150d2742c9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18272/1833220112.py:1: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`\n",
      "  bp.corr().style.background_gradient(cmap='bone_r').set_precision(2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d743f_row0_col0, #T_d743f_row1_col1, #T_d743f_row2_col2, #T_d743f_row3_col3, #T_d743f_row4_col4, #T_d743f_row5_col5, #T_d743f_row6_col6 {\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d743f_row0_col1 {\n",
       "  background-color: #738093;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d743f_row0_col2 {\n",
       "  background-color: #0b0b10;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d743f_row0_col3 {\n",
       "  background-color: #1e1e29;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d743f_row0_col4 {\n",
       "  background-color: #bfd6d6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d743f_row0_col5 {\n",
       "  background-color: #687188;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d743f_row0_col6 {\n",
       "  background-color: #ccdfdf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d743f_row1_col0 {\n",
       "  background-color: #5b5f7b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d743f_row1_col2 {\n",
       "  background-color: #899ea9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d743f_row1_col3 {\n",
       "  background-color: #8ea4ae;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d743f_row1_col4 {\n",
       "  background-color: #aac9c9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d743f_row1_col5 {\n",
       "  background-color: #8fa6ae;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d743f_row1_col6 {\n",
       "  background-color: #90a7af;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d743f_row2_col0 {\n",
       "  background-color: #0d0d12;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d743f_row2_col1 {\n",
       "  background-color: #deeaea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d743f_row2_col3 {\n",
       "  background-color: #1c1c27;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d743f_row2_col4 {\n",
       "  background-color: #e4eeed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d743f_row2_col5 {\n",
       "  background-color: #7f909f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d743f_row2_col6 {\n",
       "  background-color: #fafcfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d743f_row3_col0 {\n",
       "  background-color: #242432;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d743f_row3_col1 {\n",
       "  background-color: #edf4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d743f_row3_col2 {\n",
       "  background-color: #1d1d28;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d743f_row3_col4, #T_d743f_row3_col6, #T_d743f_row4_col1, #T_d743f_row4_col5, #T_d743f_row6_col0, #T_d743f_row6_col2, #T_d743f_row6_col3 {\n",
       "  background-color: #ffffff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d743f_row3_col5 {\n",
       "  background-color: #dae7e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d743f_row4_col0 {\n",
       "  background-color: #cadddd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d743f_row4_col2, #T_d743f_row6_col5 {\n",
       "  background-color: #c3d8d8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d743f_row4_col3 {\n",
       "  background-color: #d7e6e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d743f_row4_col6 {\n",
       "  background-color: #9db9bc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d743f_row5_col0 {\n",
       "  background-color: #4a4a67;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d743f_row5_col1 {\n",
       "  background-color: #8294a1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d743f_row5_col2 {\n",
       "  background-color: #4f4f6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d743f_row5_col3 {\n",
       "  background-color: #7a8999;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d743f_row5_col4 {\n",
       "  background-color: #9ab5ba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d743f_row5_col6 {\n",
       "  background-color: #707b90;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d743f_row6_col1 {\n",
       "  background-color: #f3f7f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d743f_row6_col4 {\n",
       "  background-color: #b7d1d1;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d743f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d743f_level0_col0\" class=\"col_heading level0 col0\" >BP</th>\n",
       "      <th id=\"T_d743f_level0_col1\" class=\"col_heading level0 col1\" >Age</th>\n",
       "      <th id=\"T_d743f_level0_col2\" class=\"col_heading level0 col2\" >Weight</th>\n",
       "      <th id=\"T_d743f_level0_col3\" class=\"col_heading level0 col3\" >BSA</th>\n",
       "      <th id=\"T_d743f_level0_col4\" class=\"col_heading level0 col4\" >Dur</th>\n",
       "      <th id=\"T_d743f_level0_col5\" class=\"col_heading level0 col5\" >Pulse</th>\n",
       "      <th id=\"T_d743f_level0_col6\" class=\"col_heading level0 col6\" >Stress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d743f_level0_row0\" class=\"row_heading level0 row0\" >BP</th>\n",
       "      <td id=\"T_d743f_row0_col0\" class=\"data row0 col0\" >1.00</td>\n",
       "      <td id=\"T_d743f_row0_col1\" class=\"data row0 col1\" >0.66</td>\n",
       "      <td id=\"T_d743f_row0_col2\" class=\"data row0 col2\" >0.95</td>\n",
       "      <td id=\"T_d743f_row0_col3\" class=\"data row0 col3\" >0.87</td>\n",
       "      <td id=\"T_d743f_row0_col4\" class=\"data row0 col4\" >0.29</td>\n",
       "      <td id=\"T_d743f_row0_col5\" class=\"data row0 col5\" >0.72</td>\n",
       "      <td id=\"T_d743f_row0_col6\" class=\"data row0 col6\" >0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d743f_level0_row1\" class=\"row_heading level0 row1\" >Age</th>\n",
       "      <td id=\"T_d743f_row1_col0\" class=\"data row1 col0\" >0.66</td>\n",
       "      <td id=\"T_d743f_row1_col1\" class=\"data row1 col1\" >1.00</td>\n",
       "      <td id=\"T_d743f_row1_col2\" class=\"data row1 col2\" >0.41</td>\n",
       "      <td id=\"T_d743f_row1_col3\" class=\"data row1 col3\" >0.38</td>\n",
       "      <td id=\"T_d743f_row1_col4\" class=\"data row1 col4\" >0.34</td>\n",
       "      <td id=\"T_d743f_row1_col5\" class=\"data row1 col5\" >0.62</td>\n",
       "      <td id=\"T_d743f_row1_col6\" class=\"data row1 col6\" >0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d743f_level0_row2\" class=\"row_heading level0 row2\" >Weight</th>\n",
       "      <td id=\"T_d743f_row2_col0\" class=\"data row2 col0\" >0.95</td>\n",
       "      <td id=\"T_d743f_row2_col1\" class=\"data row2 col1\" >0.41</td>\n",
       "      <td id=\"T_d743f_row2_col2\" class=\"data row2 col2\" >1.00</td>\n",
       "      <td id=\"T_d743f_row2_col3\" class=\"data row2 col3\" >0.88</td>\n",
       "      <td id=\"T_d743f_row2_col4\" class=\"data row2 col4\" >0.20</td>\n",
       "      <td id=\"T_d743f_row2_col5\" class=\"data row2 col5\" >0.66</td>\n",
       "      <td id=\"T_d743f_row2_col6\" class=\"data row2 col6\" >0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d743f_level0_row3\" class=\"row_heading level0 row3\" >BSA</th>\n",
       "      <td id=\"T_d743f_row3_col0\" class=\"data row3 col0\" >0.87</td>\n",
       "      <td id=\"T_d743f_row3_col1\" class=\"data row3 col1\" >0.38</td>\n",
       "      <td id=\"T_d743f_row3_col2\" class=\"data row3 col2\" >0.88</td>\n",
       "      <td id=\"T_d743f_row3_col3\" class=\"data row3 col3\" >1.00</td>\n",
       "      <td id=\"T_d743f_row3_col4\" class=\"data row3 col4\" >0.13</td>\n",
       "      <td id=\"T_d743f_row3_col5\" class=\"data row3 col5\" >0.46</td>\n",
       "      <td id=\"T_d743f_row3_col6\" class=\"data row3 col6\" >0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d743f_level0_row4\" class=\"row_heading level0 row4\" >Dur</th>\n",
       "      <td id=\"T_d743f_row4_col0\" class=\"data row4 col0\" >0.29</td>\n",
       "      <td id=\"T_d743f_row4_col1\" class=\"data row4 col1\" >0.34</td>\n",
       "      <td id=\"T_d743f_row4_col2\" class=\"data row4 col2\" >0.20</td>\n",
       "      <td id=\"T_d743f_row4_col3\" class=\"data row4 col3\" >0.13</td>\n",
       "      <td id=\"T_d743f_row4_col4\" class=\"data row4 col4\" >1.00</td>\n",
       "      <td id=\"T_d743f_row4_col5\" class=\"data row4 col5\" >0.40</td>\n",
       "      <td id=\"T_d743f_row4_col6\" class=\"data row4 col6\" >0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d743f_level0_row5\" class=\"row_heading level0 row5\" >Pulse</th>\n",
       "      <td id=\"T_d743f_row5_col0\" class=\"data row5 col0\" >0.72</td>\n",
       "      <td id=\"T_d743f_row5_col1\" class=\"data row5 col1\" >0.62</td>\n",
       "      <td id=\"T_d743f_row5_col2\" class=\"data row5 col2\" >0.66</td>\n",
       "      <td id=\"T_d743f_row5_col3\" class=\"data row5 col3\" >0.46</td>\n",
       "      <td id=\"T_d743f_row5_col4\" class=\"data row5 col4\" >0.40</td>\n",
       "      <td id=\"T_d743f_row5_col5\" class=\"data row5 col5\" >1.00</td>\n",
       "      <td id=\"T_d743f_row5_col6\" class=\"data row5 col6\" >0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d743f_level0_row6\" class=\"row_heading level0 row6\" >Stress</th>\n",
       "      <td id=\"T_d743f_row6_col0\" class=\"data row6 col0\" >0.16</td>\n",
       "      <td id=\"T_d743f_row6_col1\" class=\"data row6 col1\" >0.37</td>\n",
       "      <td id=\"T_d743f_row6_col2\" class=\"data row6 col2\" >0.03</td>\n",
       "      <td id=\"T_d743f_row6_col3\" class=\"data row6 col3\" >0.02</td>\n",
       "      <td id=\"T_d743f_row6_col4\" class=\"data row6 col4\" >0.31</td>\n",
       "      <td id=\"T_d743f_row6_col5\" class=\"data row6 col5\" >0.51</td>\n",
       "      <td id=\"T_d743f_row6_col6\" class=\"data row6 col6\" >1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f6c8ac43a60>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.corr().style.background_gradient(cmap='bone_r').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c6295f47-31e8-43c0-96fe-241fcb3794e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Stress</td>      <th>  R-squared:         </th> <td>   0.730</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.7215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 17 Oct 2022</td> <th>  Prob (F-statistic):</th>  <td> 0.714</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:07:45</td>     <th>  Log-Likelihood:    </th> <td> -87.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    20</td>      <th>  AIC:               </th> <td>   206.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     4</td>      <th>  BIC:               </th> <td>   222.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td> 1.258e+06</td> <td> 8.47e+05</td> <td>    1.486</td> <td> 0.212</td> <td>-1.09e+06</td> <td> 3.61e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BP</th>               <td>-1.197e+04</td> <td> 8190.273</td> <td>   -1.461</td> <td> 0.218</td> <td>-3.47e+04</td> <td> 1.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>              <td>-2.511e+04</td> <td>  1.7e+04</td> <td>   -1.475</td> <td> 0.214</td> <td>-7.24e+04</td> <td> 2.21e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BP:Age</th>           <td>  239.0091</td> <td>  163.870</td> <td>    1.459</td> <td> 0.218</td> <td> -215.968</td> <td>  693.986</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dur</th>              <td>-1.759e+05</td> <td> 1.37e+05</td> <td>   -1.285</td> <td> 0.268</td> <td>-5.56e+05</td> <td> 2.04e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BP:Dur</th>           <td> 1701.0762</td> <td> 1292.457</td> <td>    1.316</td> <td> 0.258</td> <td>-1887.358</td> <td> 5289.511</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age:Dur</th>          <td> 3465.9688</td> <td> 2789.759</td> <td>    1.242</td> <td> 0.282</td> <td>-4279.644</td> <td> 1.12e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BP:Age:Dur</th>       <td>  -33.5852</td> <td>   26.122</td> <td>   -1.286</td> <td> 0.268</td> <td> -106.111</td> <td>   38.941</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pulse</th>            <td>-1.735e+04</td> <td> 1.14e+04</td> <td>   -1.525</td> <td> 0.202</td> <td> -4.9e+04</td> <td> 1.42e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BP:Pulse</th>         <td>  165.4187</td> <td>  110.349</td> <td>    1.499</td> <td> 0.208</td> <td> -140.961</td> <td>  471.798</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age:Pulse</th>        <td>  345.7404</td> <td>  227.896</td> <td>    1.517</td> <td> 0.204</td> <td> -287.002</td> <td>  978.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BP:Age:Pulse</th>     <td>   -3.2973</td> <td>    2.198</td> <td>   -1.500</td> <td> 0.208</td> <td>   -9.401</td> <td>    2.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dur:Pulse</th>        <td> 2418.4654</td> <td> 1800.934</td> <td>    1.343</td> <td> 0.250</td> <td>-2581.729</td> <td> 7418.660</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BP:Dur:Pulse</th>     <td>  -23.4499</td> <td>   17.092</td> <td>   -1.372</td> <td> 0.242</td> <td>  -70.906</td> <td>   24.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age:Dur:Pulse</th>    <td>  -47.5164</td> <td>   36.580</td> <td>   -1.299</td> <td> 0.264</td> <td> -149.080</td> <td>   54.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BP:Age:Dur:Pulse</th> <td>    0.4618</td> <td>    0.344</td> <td>    1.343</td> <td> 0.250</td> <td>   -0.493</td> <td>    1.416</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.031</td> <th>  Durbin-Watson:     </th> <td>   2.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.362</td> <th>  Jarque-Bera (JB):  </th> <td>   0.629</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.277</td> <th>  Prob(JB):          </th> <td>   0.730</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.669</td> <th>  Cond. No.          </th> <td>2.52e+11</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.52e+11. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Stress   R-squared:                       0.730\n",
       "Model:                            OLS   Adj. R-squared:                 -0.282\n",
       "Method:                 Least Squares   F-statistic:                    0.7215\n",
       "Date:                Mon, 17 Oct 2022   Prob (F-statistic):              0.714\n",
       "Time:                        16:07:45   Log-Likelihood:                -87.032\n",
       "No. Observations:                  20   AIC:                             206.1\n",
       "Df Residuals:                       4   BIC:                             222.0\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "Intercept         1.258e+06   8.47e+05      1.486      0.212   -1.09e+06    3.61e+06\n",
       "BP               -1.197e+04   8190.273     -1.461      0.218   -3.47e+04    1.08e+04\n",
       "Age              -2.511e+04    1.7e+04     -1.475      0.214   -7.24e+04    2.21e+04\n",
       "BP:Age             239.0091    163.870      1.459      0.218    -215.968     693.986\n",
       "Dur              -1.759e+05   1.37e+05     -1.285      0.268   -5.56e+05    2.04e+05\n",
       "BP:Dur            1701.0762   1292.457      1.316      0.258   -1887.358    5289.511\n",
       "Age:Dur           3465.9688   2789.759      1.242      0.282   -4279.644    1.12e+04\n",
       "BP:Age:Dur         -33.5852     26.122     -1.286      0.268    -106.111      38.941\n",
       "Pulse            -1.735e+04   1.14e+04     -1.525      0.202    -4.9e+04    1.42e+04\n",
       "BP:Pulse           165.4187    110.349      1.499      0.208    -140.961     471.798\n",
       "Age:Pulse          345.7404    227.896      1.517      0.204    -287.002     978.482\n",
       "BP:Age:Pulse        -3.2973      2.198     -1.500      0.208      -9.401       2.806\n",
       "Dur:Pulse         2418.4654   1800.934      1.343      0.250   -2581.729    7418.660\n",
       "BP:Dur:Pulse       -23.4499     17.092     -1.372      0.242     -70.906      24.006\n",
       "Age:Dur:Pulse      -47.5164     36.580     -1.299      0.264    -149.080      54.047\n",
       "BP:Age:Dur:Pulse     0.4618      0.344      1.343      0.250      -0.493       1.416\n",
       "==============================================================================\n",
       "Omnibus:                        2.031   Durbin-Watson:                   2.115\n",
       "Prob(Omnibus):                  0.362   Jarque-Bera (JB):                0.629\n",
       "Skew:                           0.277   Prob(JB):                        0.730\n",
       "Kurtosis:                       3.669   Cond. No.                     2.52e+11\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.52e+11. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols('Stress ~ BP * Age * Dur * Pulse', data = bp).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d669eb94-5523-415c-9714-0af5f7f909d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>mean_sq</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BP</th>\n",
       "      <td>1.0</td>\n",
       "      <td>702.016071</td>\n",
       "      <td>702.016071</td>\n",
       "      <td>0.398195</td>\n",
       "      <td>0.562283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3128.103722</td>\n",
       "      <td>3128.103722</td>\n",
       "      <td>1.774312</td>\n",
       "      <td>0.253677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BP:Age</th>\n",
       "      <td>1.0</td>\n",
       "      <td>780.631843</td>\n",
       "      <td>780.631843</td>\n",
       "      <td>0.442787</td>\n",
       "      <td>0.542187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dur</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1380.850173</td>\n",
       "      <td>1380.850173</td>\n",
       "      <td>0.783241</td>\n",
       "      <td>0.426146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BP:Dur</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2415.971244</td>\n",
       "      <td>2415.971244</td>\n",
       "      <td>1.370379</td>\n",
       "      <td>0.306729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age:Dur</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.344928</td>\n",
       "      <td>0.344928</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.989510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BP:Age:Dur</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2108.075423</td>\n",
       "      <td>2108.075423</td>\n",
       "      <td>1.195735</td>\n",
       "      <td>0.335611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pulse</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3269.455608</td>\n",
       "      <td>3269.455608</td>\n",
       "      <td>1.854489</td>\n",
       "      <td>0.244914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BP:Pulse</th>\n",
       "      <td>1.0</td>\n",
       "      <td>279.962256</td>\n",
       "      <td>279.962256</td>\n",
       "      <td>0.158799</td>\n",
       "      <td>0.710620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age:Pulse</th>\n",
       "      <td>1.0</td>\n",
       "      <td>948.187084</td>\n",
       "      <td>948.187084</td>\n",
       "      <td>0.537827</td>\n",
       "      <td>0.503999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BP:Age:Pulse</th>\n",
       "      <td>1.0</td>\n",
       "      <td>354.397638</td>\n",
       "      <td>354.397638</td>\n",
       "      <td>0.201020</td>\n",
       "      <td>0.677113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dur:Pulse</th>\n",
       "      <td>1.0</td>\n",
       "      <td>237.580586</td>\n",
       "      <td>237.580586</td>\n",
       "      <td>0.134760</td>\n",
       "      <td>0.732144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BP:Dur:Pulse</th>\n",
       "      <td>1.0</td>\n",
       "      <td>169.896648</td>\n",
       "      <td>169.896648</td>\n",
       "      <td>0.096368</td>\n",
       "      <td>0.771735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age:Dur:Pulse</th>\n",
       "      <td>1.0</td>\n",
       "      <td>124.128474</td>\n",
       "      <td>124.128474</td>\n",
       "      <td>0.070408</td>\n",
       "      <td>0.803858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BP:Age:Dur:Pulse</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3180.966685</td>\n",
       "      <td>3180.966685</td>\n",
       "      <td>1.804297</td>\n",
       "      <td>0.250342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7051.981615</td>\n",
       "      <td>1762.995404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   df       sum_sq      mean_sq         F    PR(>F)\n",
       "BP                1.0   702.016071   702.016071  0.398195  0.562283\n",
       "Age               1.0  3128.103722  3128.103722  1.774312  0.253677\n",
       "BP:Age            1.0   780.631843   780.631843  0.442787  0.542187\n",
       "Dur               1.0  1380.850173  1380.850173  0.783241  0.426146\n",
       "BP:Dur            1.0  2415.971244  2415.971244  1.370379  0.306729\n",
       "Age:Dur           1.0     0.344928     0.344928  0.000196  0.989510\n",
       "BP:Age:Dur        1.0  2108.075423  2108.075423  1.195735  0.335611\n",
       "Pulse             1.0  3269.455608  3269.455608  1.854489  0.244914\n",
       "BP:Pulse          1.0   279.962256   279.962256  0.158799  0.710620\n",
       "Age:Pulse         1.0   948.187084   948.187084  0.537827  0.503999\n",
       "BP:Age:Pulse      1.0   354.397638   354.397638  0.201020  0.677113\n",
       "Dur:Pulse         1.0   237.580586   237.580586  0.134760  0.732144\n",
       "BP:Dur:Pulse      1.0   169.896648   169.896648  0.096368  0.771735\n",
       "Age:Dur:Pulse     1.0   124.128474   124.128474  0.070408  0.803858\n",
       "BP:Age:Dur:Pulse  1.0  3180.966685  3180.966685  1.804297  0.250342\n",
       "Residual          4.0  7051.981615  1762.995404       NaN       NaN"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.stats.anova_lm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f9a76094-2ad9-4f0c-a52e-4e62b189bb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Stress</td>      <th>  R-squared:         </th> <td>   0.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.848</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 17 Oct 2022</td> <th>  Prob (F-statistic):</th>  <td> 0.166</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:09:20</td>     <th>  Log-Likelihood:    </th> <td> -93.964</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    20</td>      <th>  AIC:               </th> <td>   201.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    13</td>      <th>  BIC:               </th> <td>   208.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td>  -60.5810</td> <td>  632.976</td> <td>   -0.096</td> <td> 0.925</td> <td>-1428.044</td> <td> 1306.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>              <td>    2.1364</td> <td>   17.917</td> <td>    0.119</td> <td> 0.907</td> <td>  -36.571</td> <td>   40.844</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dur</th>              <td>   82.4467</td> <td>   38.820</td> <td>    2.124</td> <td> 0.053</td> <td>   -1.418</td> <td>  166.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BP:Dur</th>           <td>   -0.7183</td> <td>    1.143</td> <td>   -0.628</td> <td> 0.541</td> <td>   -3.188</td> <td>    1.751</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BP:Age:Dur</th>       <td>   -0.0158</td> <td>    0.037</td> <td>   -0.433</td> <td> 0.672</td> <td>   -0.095</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Pulse</th>            <td>   -0.1824</td> <td>    7.609</td> <td>   -0.024</td> <td> 0.981</td> <td>  -16.621</td> <td>   16.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BP:Age:Dur:Pulse</th> <td>    0.0002</td> <td>    0.000</td> <td>    0.981</td> <td> 0.344</td> <td>   -0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.289</td> <th>  Durbin-Watson:     </th> <td>   2.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.865</td> <th>  Jarque-Bera (JB):  </th> <td>   0.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.189</td> <th>  Prob(JB):          </th> <td>   0.924</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.784</td> <th>  Cond. No.          </th> <td>2.35e+08</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.35e+08. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Stress   R-squared:                       0.460\n",
       "Model:                            OLS   Adj. R-squared:                  0.211\n",
       "Method:                 Least Squares   F-statistic:                     1.848\n",
       "Date:                Mon, 17 Oct 2022   Prob (F-statistic):              0.166\n",
       "Time:                        16:09:20   Log-Likelihood:                -93.964\n",
       "No. Observations:                  20   AIC:                             201.9\n",
       "Df Residuals:                      13   BIC:                             208.9\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "Intercept          -60.5810    632.976     -0.096      0.925   -1428.044    1306.881\n",
       "Age                  2.1364     17.917      0.119      0.907     -36.571      40.844\n",
       "Dur                 82.4467     38.820      2.124      0.053      -1.418     166.311\n",
       "BP:Dur              -0.7183      1.143     -0.628      0.541      -3.188       1.751\n",
       "BP:Age:Dur          -0.0158      0.037     -0.433      0.672      -0.095       0.063\n",
       "Pulse               -0.1824      7.609     -0.024      0.981     -16.621      16.256\n",
       "BP:Age:Dur:Pulse     0.0002      0.000      0.981      0.344      -0.000       0.001\n",
       "==============================================================================\n",
       "Omnibus:                        0.289   Durbin-Watson:                   2.070\n",
       "Prob(Omnibus):                  0.865   Jarque-Bera (JB):                0.158\n",
       "Skew:                          -0.189   Prob(JB):                        0.924\n",
       "Kurtosis:                       2.784   Cond. No.                     2.35e+08\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.35e+08. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols('Stress ~ Age + Dur + BP:Dur + BP:Age:Dur + Pulse + BP:Age:Dur:Pulse', data = bp).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "57613c09-0c98-44fe-adba-54eda77f6a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>mean_sq</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3543.278114</td>\n",
       "      <td>3543.278114</td>\n",
       "      <td>3.265689</td>\n",
       "      <td>0.093931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dur</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1014.785886</td>\n",
       "      <td>1014.785886</td>\n",
       "      <td>0.935285</td>\n",
       "      <td>0.351142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BP:Dur</th>\n",
       "      <td>1.0</td>\n",
       "      <td>718.377300</td>\n",
       "      <td>718.377300</td>\n",
       "      <td>0.662098</td>\n",
       "      <td>0.430472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BP:Age:Dur</th>\n",
       "      <td>1.0</td>\n",
       "      <td>207.503688</td>\n",
       "      <td>207.503688</td>\n",
       "      <td>0.191247</td>\n",
       "      <td>0.669058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pulse</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5498.604298</td>\n",
       "      <td>5498.604298</td>\n",
       "      <td>5.067831</td>\n",
       "      <td>0.042315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BP:Age:Dur:Pulse</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1044.980350</td>\n",
       "      <td>1044.980350</td>\n",
       "      <td>0.963114</td>\n",
       "      <td>0.344316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>13.0</td>\n",
       "      <td>14105.020364</td>\n",
       "      <td>1085.001566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    df        sum_sq      mean_sq         F    PR(>F)\n",
       "Age                1.0   3543.278114  3543.278114  3.265689  0.093931\n",
       "Dur                1.0   1014.785886  1014.785886  0.935285  0.351142\n",
       "BP:Dur             1.0    718.377300   718.377300  0.662098  0.430472\n",
       "BP:Age:Dur         1.0    207.503688   207.503688  0.191247  0.669058\n",
       "Pulse              1.0   5498.604298  5498.604298  5.067831  0.042315\n",
       "BP:Age:Dur:Pulse   1.0   1044.980350  1044.980350  0.963114  0.344316\n",
       "Residual          13.0  14105.020364  1085.001566       NaN       NaN"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.stats.anova_lm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9d71c53-a973-4a37-9d5a-e803cb54fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "51271bf2-6977-437a-a144-19fb5579a61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "ms = yf.download('MSFT')\n",
    "ap = yf.download('AAPL')\n",
    "cs = yf.download('CSCO')\n",
    "nd = yf.download('NDX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d0a6eeee-535d-470c-b607-ffde0342c196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ms</th>\n",
       "      <th>ap</th>\n",
       "      <th>cs</th>\n",
       "      <th>nd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-02-16</th>\n",
       "      <td>0.682292</td>\n",
       "      <td>0.305804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>209.929993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-02-20</th>\n",
       "      <td>0.678819</td>\n",
       "      <td>0.299107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>208.354996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-02-21</th>\n",
       "      <td>0.685764</td>\n",
       "      <td>0.292411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>205.065002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-02-22</th>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>204.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-02-23</th>\n",
       "      <td>0.664931</td>\n",
       "      <td>0.292411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>204.190002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-10</th>\n",
       "      <td>233.050003</td>\n",
       "      <td>140.419998</td>\n",
       "      <td>40.630001</td>\n",
       "      <td>11048.509766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-11</th>\n",
       "      <td>227.619995</td>\n",
       "      <td>139.899994</td>\n",
       "      <td>39.810001</td>\n",
       "      <td>10865.320312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-12</th>\n",
       "      <td>225.399994</td>\n",
       "      <td>139.130005</td>\n",
       "      <td>39.700001</td>\n",
       "      <td>10810.299805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-13</th>\n",
       "      <td>219.850006</td>\n",
       "      <td>134.990005</td>\n",
       "      <td>39.029999</td>\n",
       "      <td>10481.580078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-14</th>\n",
       "      <td>235.539993</td>\n",
       "      <td>144.309998</td>\n",
       "      <td>40.840000</td>\n",
       "      <td>11130.080078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8229 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ms          ap         cs            nd\n",
       "Date                                                       \n",
       "1990-02-16    0.682292    0.305804   0.000000    209.929993\n",
       "1990-02-20    0.678819    0.299107   0.000000    208.354996\n",
       "1990-02-21    0.685764    0.292411   0.000000    205.065002\n",
       "1990-02-22    0.671875    0.303571   0.000000    204.750000\n",
       "1990-02-23    0.664931    0.292411   0.000000    204.190002\n",
       "...                ...         ...        ...           ...\n",
       "2022-10-10  233.050003  140.419998  40.630001  11048.509766\n",
       "2022-10-11  227.619995  139.899994  39.810001  10865.320312\n",
       "2022-10-12  225.399994  139.130005  39.700001  10810.299805\n",
       "2022-10-13  219.850006  134.990005  39.029999  10481.580078\n",
       "2022-10-14  235.539993  144.309998  40.840000  11130.080078\n",
       "\n",
       "[8229 rows x 4 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = {}\n",
    "tmp['ms'] = ms['Open']\n",
    "tmp['ap'] = ap['Open']\n",
    "tmp['cs'] = cs['Open']\n",
    "tmp['nd'] = nd['Open']\n",
    "data = pd.DataFrame(tmp).dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "04c98375-8d25-4ed3-9e97-2cc6694e274a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>nd</td>        <th>  R-squared:         </th> <td>   0.984</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.984</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>1.721e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 17 Oct 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:18:48</td>     <th>  Log-Likelihood:    </th> <td> -61704.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  8229</td>      <th>  AIC:               </th> <td>1.234e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  8225</td>      <th>  BIC:               </th> <td>1.234e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  245.2269</td> <td>    8.561</td> <td>   28.646</td> <td> 0.000</td> <td>  228.446</td> <td>  262.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ap</th>        <td>   62.2430</td> <td>    0.682</td> <td>   91.204</td> <td> 0.000</td> <td>   60.905</td> <td>   63.581</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cs</th>        <td>   58.5234</td> <td>    0.491</td> <td>  119.211</td> <td> 0.000</td> <td>   57.561</td> <td>   59.486</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ms</th>        <td>    6.5543</td> <td>    0.425</td> <td>   15.429</td> <td> 0.000</td> <td>    5.722</td> <td>    7.387</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1836.886</td> <th>  Durbin-Watson:     </th> <td>   0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>8422.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-1.015</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 7.521</td>  <th>  Cond. No.          </th> <td>    172.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     nd   R-squared:                       0.984\n",
       "Model:                            OLS   Adj. R-squared:                  0.984\n",
       "Method:                 Least Squares   F-statistic:                 1.721e+05\n",
       "Date:                Mon, 17 Oct 2022   Prob (F-statistic):               0.00\n",
       "Time:                        16:18:48   Log-Likelihood:                -61704.\n",
       "No. Observations:                8229   AIC:                         1.234e+05\n",
       "Df Residuals:                    8225   BIC:                         1.234e+05\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    245.2269      8.561     28.646      0.000     228.446     262.008\n",
       "ap            62.2430      0.682     91.204      0.000      60.905      63.581\n",
       "cs            58.5234      0.491    119.211      0.000      57.561      59.486\n",
       "ms             6.5543      0.425     15.429      0.000       5.722       7.387\n",
       "==============================================================================\n",
       "Omnibus:                     1836.886   Durbin-Watson:                   0.009\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             8422.090\n",
       "Skew:                          -1.015   Prob(JB):                         0.00\n",
       "Kurtosis:                       7.521   Cond. No.                         172.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols('nd ~ ap + cs + ms', data=data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2913e0ec-fd13-4486-9750-f32a91c341f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>mean_sq</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ap</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.329547e+10</td>\n",
       "      <td>9.329547e+10</td>\n",
       "      <td>488759.625701</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.200825e+09</td>\n",
       "      <td>5.200825e+09</td>\n",
       "      <td>27246.266237</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ms</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.543916e+07</td>\n",
       "      <td>4.543916e+07</td>\n",
       "      <td>238.048294</td>\n",
       "      <td>5.759128e-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>8225.0</td>\n",
       "      <td>1.570005e+09</td>\n",
       "      <td>1.908821e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              df        sum_sq       mean_sq              F        PR(>F)\n",
       "ap           1.0  9.329547e+10  9.329547e+10  488759.625701  0.000000e+00\n",
       "cs           1.0  5.200825e+09  5.200825e+09   27246.266237  0.000000e+00\n",
       "ms           1.0  4.543916e+07  4.543916e+07     238.048294  5.759128e-53\n",
       "Residual  8225.0  1.570005e+09  1.908821e+05            NaN           NaN"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.stats.anova_lm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6b4a6f3d-69ae-4b1c-9a5a-63733072a42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>ap</td>        <th>  R-squared:         </th> <td>   0.964</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.964</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>1.113e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 17 Oct 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:25:07</td>     <th>  Log-Likelihood:    </th> <td> -27756.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  8229</td>      <th>  AIC:               </th> <td>5.552e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  8226</td>      <th>  BIC:               </th> <td>5.554e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -2.1516</td> <td>    0.136</td> <td>  -15.791</td> <td> 0.000</td> <td>   -2.419</td> <td>   -1.885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cs</th>        <td>   -0.3480</td> <td>    0.007</td> <td>  -50.136</td> <td> 0.000</td> <td>   -0.362</td> <td>   -0.334</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ms</th>        <td>    0.6035</td> <td>    0.002</td> <td>  358.613</td> <td> 0.000</td> <td>    0.600</td> <td>    0.607</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>43.164</td> <th>  Durbin-Watson:     </th> <td>   0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  61.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.010</td> <th>  Prob(JB):          </th> <td>4.10e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.424</td> <th>  Cond. No.          </th> <td>    153.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     ap   R-squared:                       0.964\n",
       "Model:                            OLS   Adj. R-squared:                  0.964\n",
       "Method:                 Least Squares   F-statistic:                 1.113e+05\n",
       "Date:                Mon, 17 Oct 2022   Prob (F-statistic):               0.00\n",
       "Time:                        16:25:07   Log-Likelihood:                -27756.\n",
       "No. Observations:                8229   AIC:                         5.552e+04\n",
       "Df Residuals:                    8226   BIC:                         5.554e+04\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -2.1516      0.136    -15.791      0.000      -2.419      -1.885\n",
       "cs            -0.3480      0.007    -50.136      0.000      -0.362      -0.334\n",
       "ms             0.6035      0.002    358.613      0.000       0.600       0.607\n",
       "==============================================================================\n",
       "Omnibus:                       43.164   Durbin-Watson:                   0.009\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               61.653\n",
       "Skew:                          -0.010   Prob(JB):                     4.10e-14\n",
       "Kurtosis:                       3.424   Cond. No.                         153.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols('ap ~ cs + ms', data=data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "53eade92-d847-4d5b-b767-2c1c478985ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>mean_sq</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cs</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.681580e+06</td>\n",
       "      <td>4.681580e+06</td>\n",
       "      <td>93964.887424</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ms</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.407340e+06</td>\n",
       "      <td>6.407340e+06</td>\n",
       "      <td>128602.947572</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>8226.0</td>\n",
       "      <td>4.098411e+05</td>\n",
       "      <td>4.982265e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              df        sum_sq       mean_sq              F  PR(>F)\n",
       "cs           1.0  4.681580e+06  4.681580e+06   93964.887424     0.0\n",
       "ms           1.0  6.407340e+06  6.407340e+06  128602.947572     0.0\n",
       "Residual  8226.0  4.098411e+05  4.982265e+01            NaN     NaN"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.stats.anova_lm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cba8fa88-ab1f-4d7b-a1a5-c86e9c021776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaygun/.local/lib/python3.10/site-packages/pandas/core/internals/blocks.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Date'>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+EAAAFfCAYAAAAh5s3KAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAADiuUlEQVR4nOydd3gURR+A39279F5IQui9CkgVVCyABVSsFAEVFFERsAufvSD2hgUrFkABBZUOIr0X6b0mJCQhvbfb/f7Yy91ezSWkAM77PEpud3Z3dnd2Zn51JFVVVQQCgUAgEAgEAoFAIBBUO3JtV0AgEAgEAoFAIBAIBIL/CkIIFwgEAoFAIBAIBAKBoIYQQrhAIBAIBAKBQCAQCAQ1hBDCBQKBQCAQCAQCgUAgqCGEEC4QCAQCgUAgEAgEAkENIYRwgUAgEAgEAoFAIBAIagghhAsEAoFAIBAIBAKBQFBDCCFcIBAIBAKBQCAQCASCGsJY2xWoahRFITExkaCgICRJqu3qCAQCgUAgEAgEAoHgEkdVVXJycoiNjUWW3du6LzkhPDExkQYNGtR2NQQCgUAgEAgEAoFA8B8jPj6e+vXruy1zyQnhQUFBgHbzwcHBtVwbgUAgEAgEAoFAIBBc6mRnZ9OgQQOLPOqOS04IL3NBDw4OFkK4QCAQCAQCgUAgEAhqDE9CokViNoFAIBAIBAKBQCAQCGoIIYQLBAKBQCAQCAQCgUBQQwghXCAQCAQCgUAgEAgEghpCCOECgUAgEAgEAoFAIBDUEEIIFwgEAoFAIBAIBAKBoIYQQrhAIBAIBAKBQCAQCAQ1hBDCBQKBQCAQCAQCgUAgqCGEEC4QCAQCgUAgEAgEAkENIYRwgUAguMQ4kXWC0ctHszN5Z21XRSAQCAQCgUBghxDCBQKB4BJjwj8T2Hx2M/cvvb+2qyIQCAQCgUAgsEMI4QKBQHCJkZyfXNtVEAgEAoFAIBC4QAjhAoFAIBAIBAKBQCAQ1BBCCBcIBAKBQCAQCAQCgaCGEEK4QCAQCAQCgUAgEAgENYQQwgUCgUAgEAgEAoFAIKghhBAuEAgEAoFAIBAIBAJBDSGEcIFAUPPkpkBRbm3XQiAQCAQCgUAgqHGEEC4QCGqWvFR4vwW806i2ayLwkG1J29iVsqu2qyEQCAQCgUBwSWCs7QoIBIL/GAk7tH+V0tqth8AjcopzGLVsFAA7R+zES/aq5RoJBAKBQCAQXNwIS7hAIBAIXJJVlGX526SYarEmAoFAIBAIBJcGQggXCAQ1jFTbFbj0UWu7AgKBQCAQCAQCVwghXCAQCC41TEW1XQOBQCAQCAQCgQuEEC4QCASXGtXkNq4KE7tAIBAIBALBeSOEcIFAAKoKKQfBJJKlCQQCgUAgEAgE1UmNCOGff/45jRs3xtfXlx49erB161aXZb/55huuvvpqwsLCCAsLo2/fvm7LCwSCKmDLNPjiCpg3uvqvJYmY8IsVScTzCwQCgUAgEJw31S6Ez549m6eeeopXXnmFnTt30rFjR2688UZSUlKcll+9ejVDhw5l1apVbNq0iQYNGnDDDTeQkJBQ3VUVCP67rP9I+3f/vNqth0AgEAgEAoFAcIlT7UL4hx9+yOjRoxk5ciRt27Zl2rRp+Pv78/333zstP3PmTB577DE6depE69at+fbbb1EUhZUrV1Z3VQUCgUAgEAgEAoFAIKhWqlUILy4uZseOHfTt29d6QVmmb9++bNq0yaNz5OfnU1JSQnh4eHVVUyAQCC4pJJFATSDwDFV8KwKBQCCoeapVCE9NTcVkMhEdHW2zPTo6mqSkJI/O8fzzzxMbG2sjyOspKioiOzvb5j+BQCAQCAQCt+z7Hd5vAac9MwoIBAKBQFBVXNDZ0d9++21+/fVX5s+fj6+vr9MyU6ZMISQkxPJfgwYNariWAoGgYojkXgKB4ALgt1GQdw5mDa7tmggEAoHgP0a1CuGRkZEYDAaSk5NtticnJxMTE+P22Pfff5+3336b5cuX06FDB5flJk2aRFZWluW/+Pj4Kqm7QCC4AMhPh1+HwcGFtV0TgUBwqaKaarsGAoFAIPiPUa1CuLe3N126dLFJqlaWZK1nz54uj3v33Xd54403WLp0KV27dnV7DR8fH4KDg23+EwgEFeRCjYv85004tBBmD6vtmggAVcSaCwQCgUAgEJw3xuq+wFNPPcX9999P165d6d69Ox9//DF5eXmMHDkSgPvuu4969eoxZcoUAN555x1efvllZs2aRePGjS2x44GBgQQGBlZ3dQUCQXVTEW/03OTyywgEAoFAIBAIBBcR1S6EDx48mHPnzvHyyy+TlJREp06dWLp0qSVZW1xcHLJsNch/+eWXFBcXc/fdd9uc55VXXuHVV1+t7uoKBP9NpAs0TltVarsGNUp+ST4A/l7+tVwT50ginl9wSSLatUAgEAhqlmoXwgEef/xxHn/8caf7Vq9ebfP71KlT1V8hgUBgy4Xqjn6h1qsaKFVK6TGrBwA7R+zES/aq5RoJBAKBQCAQCKqDCzo7ukAg+I/zH7KE5xbnWv7OKso6r3NFZqmM+9NE46SqVWKImHCBQCAQCASC80cI4QJBZSgthmlXwx+P1XZNLkIq4vophL7KMPYPlasPqLw73UXW55JCKM6r2UoJBBcqF2o4jkAgEAguWYQQLhBUhpNrIGkP7JpZ2zWpGi7USWhVu6OrKiTugtKiqj1vFSBV4TuITXOzU1Xh3SbwVmyFn4OICRcIBAKBQCA4f4QQfjFyeAn8fCdkn63tmvx3udTcpC/U2Ou8c1V7vq1fw9fXaGuPXyIcS8llx+l0zw8wFYM5ARxZZ6qnUgKBQCAQCAQClwgh/GLklyFwfCUsfb62a/IfRlgEa4Szu6r2fJu/1P49tqJqz1uL9P1wDXd9uYmEzIJqv5aICRcIBAKBQCA4f4QQfjGTm1LbNfjvcqG6b18MiGdXLmolPBNOpVpjvN0dvS5hAwPq12WXj3claiYQCASCC4qCTPhtFBxZXts1EQgEFUAI4QKBQHAJoJfb3ak5Hls9gTgvL0bHRFV7nQSCiwOhGBRcxKyaDPt+h1n31HZNBAJBBRBC+MXMhRrH+59ATNouTi6Ob6Ym3L4LZdH9CwQCwUVPdmJt10AgEFQCMQu7qLk4BIpLEiGDnwe1+PAuYMVVVWZHv5DuUlVV0grcpWsXCAQCgUAg+G8hhPCLmQtYoLjgUFWY+wDMG1PbNREILijyyzKle0BlYtWfX/c81865lvUJ6yt8rEBQIwilqkAgEAhqGCGEX9QIIdxjcpJg/3zY8ysU5VTBCcWsrcoxlcBPA2HlG7Vdk1qnMsJuZVzYPz00gx6zerAxYWOFj/WUJSeXAPDt3m+r7RqCKibjNKz/CAqzarsmAoFAIBBckggh/GJGWMIrgO5ZVcUa3yLDd9VzeAmcWA3r3q/Gi1y434xkr9hJOw4HF1Trd/7Nsd8AeHvb29V2jTIqo1gQ1BLfXAd/vwoLn6ztmggEAoFAcEkihPCLlCoQI/9j6AScqhDChSW88ugVGHrBzFRc83W5kJnaGWYPh2N/13ZNqo34nPgKucMLaoh8cwz/ybW1Ww+BQCAQCC5RhBB+EfJTcBC9G9bjqFRS21W5eHAl+AnM1NAzOboCFjxRM9e6VDizvdovURtW6iMZR+g/rz83z7u5xq8tuPBZtj+J4d9uITm7sAauJpSqAoFAIKhZhBB+EfJeRBhZBgNvGqoitvk/glTFTf1Cd0cvzNb+u9CYeTdknLT+rmnh7yLRv6iVCJ+weZQXePMEWHtGs7KmF6bXck0EFyJjft7B+mOpvPrX/tquikAgEAgEVY4QwgX/Ef5D7uimUni7gfafyVNviQv4fs4XVYUjyyEzngtZCneICbdQiTpfuLdp4ZKKEU/eD4cW1XYtLknS8kSYikAgEAguPYQQfhFw4lwuD0zfyvZTthYjT6ewc4/M5dWNr6JUifB5kaK3hDub/OckQf4lYpEr0lnACzI8POgSEojsObIUZt0DH7ev7ZpUjqoSVnPPwaopVXMugS1f9oJf74UzOyp23KWkiKguxCMSCAQCwSWIEMIvAsb8vIPVh89x97RNNts9XZLo9U2v8/vR31kTv6Y6qndxILmxhBflwAet4N0mlTtfLfH8b3u4dep6SkwXs3JF73ZdhbPtzDjY9h2UFMIp6/rUB2WV1yLCSDVcgF1faYH172JdsjI3yjNVVfGOWIUxaJ/tdl3zXB2/Wvvjt5Gw5vyyoFdmGbRKX+tiFFDPHfS87NyR8OWVFfBW+W9Sk21OIBAIBIKawljbFRCUT0JmgdPtFZ2a5Jbknn9lLgnsnlxmXCXOUftC+Ozt8QCsP5rKda2jzvt8BZJEkSQRet5nugD4/AooyXN4t4NCZSCIs0Yj02qnZq4p0SWgKs7T7XD9pe9M2YlP1DLzr1EALD25FH1rGPfPOPbevxdOrauyqlYGe2HKnXD1wvoX2JWyi99u+w0/o191V6122D9P+/f0Bmh6ba1W5UKmJnQxpaqYDAkEAoGgZrkAzUECezyOFDWVwqYv4Oyeaq7RRY7DrO48M6fXssWuaixFElc3rMfVjeqTVZRVBeerTBWqULFRYhZiTzr3/jjg411116oGVA89BFILUh22Td8/3e25W8WrvDqjlEbJF66F8a/jfxGXE8equFW1XRXBf4DcwtLaroJAIBAI/mMIIfwiQD9VVhQ3E+cd02HZJPjq6mqv00WNvXuvO1d1V7ha8iwzDr6+DvbPr3z9KojrhF4VQaVI1rqDw+mHq+B8nl7WhbCZl1atly26AMIJ7HGtTHH9zeuPKfvLIBncXueNGSbaxsMLs00VrGHNI12A78kt7hRySXth8XOQ56g4udgoMZVwOP1wjYQM1ISq6MJVRwkEAoHgUkUI4RcYqQWpbEva5nJ/r28et/ztMP9J3FXh642dtZPh3265OOMvK4uNqy9UzhKuFw50x3x8GSTuhLkPVK5u50l+SX75hcrhgojB/LxbtZ4+X675rq+g2OQytMSejKIsXo0IZ7ePd4U9LWQPl+MLtf8MQPOmsYtRVlWVJ+ebGLvg/IR2+z7Gkz7njU1v1J5nRlWQvB8+ugx2/wrTroKtX8GCCbVdqwrgXAkybtU47l5wN3OPzK3h+lQ9hWWKnsRd8POdVk8yUykcXQGFF3H7qyLWnVlHXHZlwrYEAoFA4AohhF9g9J3bl1HLRrEhYYPT/Xm+ay1/OwhLFcx+rqoqi/acZf2xVI6fczYjv0T5c6zt76q0hNciK+NW0mNWD7488EOt1mNT4iZe3fgqeSWetCkXzy6/ei3htcF176/myrf/4VhKjssyTZJUmpxVmbL7M34PDmR4bEyFv2tPhXAHFEVTIn3UHhSrwK0mn6PnIZVr9qmYCjxTIrijoLQAk+KZQJ9TksO7294972vWGr+Phqw4mD/Gui1pb+3Vp4ooG59mHZxVbdd4xPAXn3pNRaqKVT2S98Nn3WD/Hzabfw4OolvjBqz194LvboDjK+GHW7Sd6z+CmXdbf/9H2ZG8g8dWPsaA+QNquyoVIr0wncmbJ3MwrQLJEgUCgaAGEUL4BYZJ1SanGxKdC+F6qlL0u+Qt4fr7O7PVbuf5riF+YTy71ze9DsAX5cQEVzcPr3iY34/+zld7vqrVelSU45u/ZNxPz7Pq0NlqOX9StpZ4beXBFKf71aIS3plu4p0fTJxJj8NYquJTrKJu+kzL9F4OZd+whOTYIj2x5hVmQk4i5CbZKkFKq85tPac4h+4zu3P3grtdV6O00Ob3RW2BMxU5bruIXOxrc92FiV6/cpthE4NyZ0BhdvkHuGPuSEg9AnPvt9n8bkQYAG9GBVrfVZnnxZ5ftX+T/ts5Vval7iu/0AXIaxtf49fDvzJo4aDarkr146RPURT10p/XCQQXOUIIvwhw1Y86bq5Yhyv6ZzM2lsNKuKNX84N0mwfArioXEom5ibVdBc9J2Mnth79gtbqYh//8tFaqYCq0Wpn9ilS+nmri5w9M/O3lB4ueIrc4lzc3v8mOZN1a1JnxDueRnHXrC58s9/r6pe6Kq1DwLkNFtdT9WOYxp2EPn+78lG4zqzcUofapwQ9WVWHew7DmvQofmitJ9Ivw4aUNL1VDxTxnUP4v8M3153cSF2E64dkqQ1ebCMuu/sHw23UnmDRvjxCMaogjGUdquwq1RmGJiWveX8XDP+8ov/Alwp5ze9h8dnNtV6NqKSmgJDeZ09mna7smgmpCCOEXMfZDeUFpMdNDgtjv7XXe57r0cHOH7tzR9/1O8futIH6r62Oq8ekt3ZdE+1eXseJAsssyVT2lP6+Y8IrGT14oE9L0E5Y/Df4nq/96+ek2977oxCJe3W51u5ZUCDQbhM/m+QLw2a7PmH14Ng8sfcB6nmyr1b5scn82y4n19YTzLPF68oqsgndOQfWvXe0s1vubvd9U+3VrFidfZ01awuM2wZ7ZsOrNCh+6IDCAFIPEH8f+KL9wcR78NBC2VtP7Szt6nidw/swnzjVxxyaV5+ZUv83/zUUH+WVrPFtPplf7tS5YMuPh9KbarsUlz8bjqcSnF7idN1xqDFs8jNHLRztdMeSi5f2WjJp5NbfMv4U18eWP4YKLDyGEX9TYCjBfZMTzYXgYQ+rVrfDRF4osVOvYPYgZyyfQpY43a34f5vExFebUelj5ukNCLIBHZuwgv9jE6J+2n981aoq3G1r+rJqs7U7Y9zt8fxNke2ZpL0Lhf5ERLPN3vd50QnFm+SdySOhXOY6c/ZgZ0zrAvNGWbRPXTWRLyk7Lb2dZz526ZSsmRi430WeXwvv7xqKoChl5ngvQkrnt5pfkM//0X5wzlDcknF9b17eJGQdnnNe5HDj+D2z+8iLozKrhu4jfBh+0hn3zbLdXQaJGj9j6DZxYDYufqZnrnSfZ2WcY93MvGpsjQ+rVYAqK/OIq8DJJPap5NxS5zi9xQfJxe5h+U6WSyFYlp9PyuOnjtfzxb0Kt1qO6qLax9yIgreASyidTlM0uXx8Afjvym+typcUw8x7YUDtefILKI4TwCxRPXNbsdffHqaEJlxv+N38vT83ZVdvVqBhuLOHvmGMGJ4X42B+k+/s8J/0/DIB1H8D278/vPNXF76Nh+gAtcVcFqLaJwG+jNAvf0okeFZ+Vd4IFQQE8E13H6f4SpYQvz5ajZT60CN6qB5u+qGhtNeK28KRxLl7GVJYXreadiDBMe20zS6u6xyWpjtudJVzzOZTMzTtUxixRiM85xJJjCygwHvK8XubrpBSk8OG+T7m/brR5s+5dn1rr5MALkJ/v0NqEi7XhLxiqwxL+672QcxZ+G2l/saq/ljOKc2vmOlXEN8vHsVpxFGB3+3jzVFQkCbnVJ5xVyeoTn3XVvBuWv3j+56oNzjhfAaZEKSGjMKPaL/+/+Xs5lJTDE7N3Vfu1agJTQSlnNoSRk6DNUy6itBOCqmDf73B0Oayo3dAhQcURQvhFTIldrLDD0L7jR/hrXI3Vp7DExKwtcczbmcDZrPPPouyMElMJGxM2VnwpLo+tY87L5ch2o5qL7OhJBgO5lR0B046TVpDGM2ueqdXYJgcF0N45cHo9nN1VHVer/KEFnk3WUs+4f5bTdk/jz7Rd7s+xbCKbfL1Rl03ytHa2fH8DE4zzucu40mUR/ZOQnHhFSE7avJxndT1vE68ycaOrSbnz52zfUuO9vHghMtz2e1n9totzQkJuAm9ufvPCSp6Wcaq2a2DFaV9QDTNkpbQC168OLq5Zf3qx80Rvw2NjWBHgz3PLH4W0Y9Vy7Sp11LAPk6oGatKqOmThEHrP7s2prFPuC26cCoufrfTD1IfeXAqcW5lITrwfZ9ZFACAJKfySw63yzi6Z6YWIqqrsT8yisOTS+vbOFyGEXwS4+vjKhCWL0GRfbMF42PmT5edbW95C0Vl6y44LJpcGf96tCe3ngaIbEE3lJROrJB/u+JAxf4/h2bXPVuFZPcuOvinRVSybdq/Jecn0a1iPqxvVr3RN3t76NstOLWP08tHlFzYjSRKH0g+RXug81vBE1gn2p+6vdJ2suHin88bAV73BVEKefvC/SOYBbt28zPQPVnm4bjQr7F3asxO19YQ9pJFkjdFTgLVn1vLl7i+1DbrnlWsqtikHYEjWLbWjqvDHY6i6+EqDvul6+OwlJ6/0r6BAMoudx/bbJ2wb+/dYZh+ezcil9hZYR1TUmpkcerj82SWFB8vSrYxbyZ5zl0am74TscxSXFpdfsAy7Zie7+EDCclRu2KGQnOwYg/7Qj9u4+6u1LDmxlMzCzArUVuApZcnUlp1aZrM9vySfOYfnkJJvjh9Y/iJs/RoS/63Udex16hc7JTm2SttL7PbK5T+R7LA4z2nIIgCy0fp3duIFGZI1d8cZBny6nvu+r37F4cWEEMIvYlTgzc1vcsPvN5BdnF2um1tuSa7T5A6PGRfgf3azJrSXh6LA0RUsPTiHL3d/6bbz25Wyi5c2vORSOKwMvx7Wlo1Ze8YzF9kzOWf4cteXZLkQKgCP1/zelbJLf5Dlr/icMzz696N8u/dbAErPQ9CobEbxexbcY/P7Xx9vy98D/xjIkEVDPE5YUl47WnEgmX/jdFboPb/C2d188M/TXNG4gUP5IxlHmHFgBiVK5ZJ97ff25puQYErsBiBVVSHtOOS5jwEr720o9ooXJ5JpgXnWtl4vhJ/ZDh+2gR/6A1BqUsgpdHKPOUnWU9ude+zKsXyxS3Nxd/XUy7bL+naVdoySXTNZ4+Xp0gnOn4IzIRxAUZ0LsorJdvvxrOOA5s5eRlx2nFNPlaSsymnr3Qnucdlxju2qKtaVdkZOsubyfuCvChxUQ4nZXJ5T237cy8gTq55g2GI3uS2cHnm+1zezZw580weyzt/Ne3vCEW6afz1XzrhVW7os+YDHx6bKMqqq2n5LOl6bYeKh5QpD7BxWiksV/j6Ywt68X3lu3bM8tPyhStf/ApwfX/B8sP0D3tj8BsMXD7fdUcmcB5eapdj+dly170pTnAdr3q3Qt1aTVEmIxwWOemqdFvftDL0Q/mEbLWRven849nfNVM4DZm7WMrz/pxNTOkEI4RcxKjD78GyS8pKYt+kdfBTHAenTsBCb3+cKztkcDxBYkVjyXTNh5t08u/UNvtj1Bf+mWDXR9pOLEUtG8MexP5i8ebLn5y+HirrGDVs8jC92f8FL290t0aM75xdXaJmrnaGf3OsGuYmbXmF9wnqLgqCmcfZE7ouN4bBdlvyzuZVY/3qt9tz2e3vxd8p2jqXkMvqn7dzxxUabYie9jPyQuMrhcFVVueuvu3hn2zvMOTzH8fwezEiH1Ivh0/BQZh2aZbM97uRRmNoZ3mtagRuyZeaW0+QUVsCipqfMyyR+CwC3TF3PZa8uJyVbJ2xu+w4+aGX5qV/B2/7O9THhPQ7bOKfr/q+xOWUHnZs0JMGoG3zdop0v96xtbgNXQrj+vRzxtip08qZ+6fYq+9P2M2D+AG774zab7a3OqOQlepDYTlUJyfNsQrX81HIGzB/A2L/H2u6oLkv4sv9pyd/mjCCvyEPvB6ex0lLV19GVJdzcT53xuJ1UE/NGQ8J2WPq88/3FebDwKY+y+H+5bT4AhVIifNoJvuwJcVvKPW5RgD/XNarPW1vecjqOlAIxmdrfHY47P4cxeBcAhzMOl3s9V1z64oIHVFATsfrMagDO5lViDHNClYmo/7yp/XeBUeU6hn8mw6rJ2rd2AfKfsIQDnLDOsU5mneT2P25n8YnFtkI4wP55cHoDzLirhivommA1m3eMX9NF8rzvfH/b+7y52fp95RWVkldUWv6yvRcRQgi/iDntretpd/yIv+IY5/ZNqJ0QnusocCsVaAaf7J/O7fViLL9dJVHRa5qrcr1OfXKqwtJCXtn4CqviHIW/Msqs8NtTd7s+qX7Eyk2GjS4yTCZoa24qqkKeLgYnMS/JefnKUIHBUzLk4W5Kt8/bm5TzWa4jP90ywRhSry5P7vmMjfG7nBYd6CQj/4aEDXT4qYPl94E0Ry26qqq8tuk1rv71aj5K+Jus034UpDpfYu9wum3n3Uhy8dxLPM9H8ML8fZTaJZwz+p9wUdqO5H02P1OTzvCZ1yfs36CzlC6xFTr0lnDVzbt+YKW1TkpZYjZd43hx7zTtfPpzq9q6x4PXmPB3oVeIXxNh8zssF+qmObahJYkryS/JZ1vSNk7ts/YhhXN+d11pYOVpzYSYnG91u+9wQuGNn01M+z4OVJW71ylcuV9BVlS8SlSaJarkmzPPP/mHwjefmpgzpZSr97q3aM88OBOATWftw0SqaYDOt35LX6/1sI3knXPcJklaEp3zIe24lsixzDukHHf0C8bu5yqb99r3Yft38NNtzve7It/sBXNkSTkFJT4MDwU0bypnz+OlOtZvw+W3eR4PUkbhYhTBK2w1VhRNWeXWQ8n9c/Dcslm5F1IlQmp+uqakXvueQ36SnXEZ7Euo4HKdVUiVC+GJO8svU1WUFELRxZXosSaw/yJe3vAyx7OO8/y650E21EqdKsJDmdPod2Irv5R4prQqLC3kxwM/MvvwbJLztPnEm2/+jzdef57k1EsnA34tq8cFZaiqytztZ1zsVZB941AKY92fw4Pr5Dqx4CjmgeyQtxcnTy7h5iY3W/ZlFGbw4Y4PuavFXXSK6sS3yjnQWcY8wcHd9zzQWzB+PvAz847OY97Reey9f285dVApAQ76eNO2qNh9w3cRd1OYosVVj1w6kp0pO1luMFDXZHLquqtSyemBBy/xcPphfjn0C4EtywSif5yWUyTos3iwdYOb5B1F+mQZGz+D8FXQ7UGHckn5Z5AJ4GXjT7CvENrfxRZfH1Qno362i+RHejYnb7XEZK/evYGbNmnZ6NsMSWTdmXX8os9oXpAOvznWCWDPmUxiQ/2IDPSBA3/a7JMUeHK+iWZnVSY+YCDX31rXzj6bOGqwfS6SwUO3abNSpoxXvX7gFsMW2LIFbh5k3mr7QmUUeu9VKPKCt+qF2163HM9yZ9Y7+2MmzjVZll2yId/5oPXZNO29v3+nzNZWVkHu2+Mz+OnkHIqVYuYc9GxCrKoqJiffwuUntON9TCrpWw4yaL3WH4xdCEZz17BAGcvgF36g5yHrtcYtVEiMkCDKo8tXH8teAKMv+i86Lc/JWuzA3oQsLutc3gmlyi93l3FK658+66r9LsqBKyfgure5YMRv92ScrNRh1n7WzX1u/QYyT0OQdfx0JliWHvKjLAODvRBuFQorKUQX57PeZzz7lcZA7XhM1Ri7Z8GfYyGoLjztYqWGlIPaeuGNPLOsViY5nDvlQZW4o+uTIeo8W7IKSrjT7Cl2/K3+GKogAL2wxIRBlvAqdwlJDf3zUtUaysVRFagqvNNIm6u8kARe1vCvczlFpOQU0i42xPEw3Xd50dzreVJQqjM22FvCL0Cid50meX8oybtU2rxffnm93FA2r3hV/h4fQwlJRY8CkdVU05pFWMIvEL5ee4IX13xg+V2ilLD2zFpyi3ORwlYS0OQLfOvNdnuONbp41ficeDb72i+rZesFpqrgXWcpK6I0i+I99ery3Nrn2JZkXT5kypYp/HHsD0YsGeE0ptjZesaOyCzdd5aiUs9dMA+mHeSdre+QVWSrTdZ3sBVxTcsrzadzk4YMi43h/fAwbampkkLtIax6y6NzfG/I541Nb7DTvJ7z4kB/dvl4k1/qaHl1eadV4DZ194K7+f2o1SIZn+fc0yDf3jo2vb9L17kcvXLm+EpY+y78eKtDOUVVGCBv5gHjci3uCHjIvKxVeRSVOCpj8nTvt2667bN5bOVjrNO1afX4KtjnPInabZ9toOubWvxTdp7O26MgkzpxMj0PqURlwT3rFRonqRhLtWsdbfqns9NVipaSnRLt9CZQSikFvgwNZoePD94FpTy+UOHp+QrzAwI8Oq9/ltbm9XM5qdjRo0UCpwL4TdsVSgtkt01vwp+O76ZYcWFON5XCL/fCz3fabL5l/i18v89xmT39ZfNTMi1/G3WXjFnmPMFSdKbrSlfFZCspL4mNCRtt3RlPbdCWpAPIOgObPoN179tMui3ecBmn4NR6y/afzHFvulo6q3jlKqso8ElHqwAOWhuDct3RHchJhi1fQ6Fra50ntbS+A0/vyV66VWH3bDhXOffusS6WHbTBydrlzr6FUSt0SUs9KF8hTqwiVkqnn2Fn5VxnM+Pg4MKLI6D84ALt3xw34/OO6dp64VmuDA+2uLSMV/JbcnaUqqoUl56/wSA9z9pv2ntZVYaiUhOXv76Cq95xrmx3hv6xXHSeu2XGArtVLrpN/psBn65nX6L7eeilRJLBauEuctfWDc69B8uYf3Q+c4/MdVumulGTzbNipfLjdu4pHzJP+EFh9ay+VBsIIfwCYcqSQ/jUsWaDmX14NmNXjmXcP+MwhGlxcl7B7q29ubL1dcbnxDM/KNBJKZ3QrKr4RK5mT0gmcbqYwWOZ1qVZTmWfsvx93ZzrHM72164EtpxIc1h2QP+ZJWUV8siMnby9xPP1iwctHMSMgzN4Z+s7due1nrmyncrMkCBYNklzI4vfArt/8fjYOUescc0fh4cxIjaGQpOjVazEvsMszodXQ+C1UJcx59/kHWdPasWzF2cVOz/f++Y1zstQJbR7Pr4KPr9CW97GnNnb6RCW6ijcq0CUlFnhOgKciXMMtJR2WZ+9O/dsgGKdlXW9ny9PRUWSIdt2YUeTc5i8SOf2nnGSiATrQHbzDpV3p5t4Zp5SKQ+Nv/39OZfvxMUYaCnbJZ2afhMA84MC+CIslAdiozHqFBGyh/OGDqs1zxObjM7Fjm69Rhean1ErFI7+GcO5PUGeXbAcvvr7CTi8SFPW6IjLKX+ZsvTiioVuuGsTlV46qSgX9syFgkz6/daPMX+PYV3COuv+H/pr625nxrt0n7YIUp90hB8GVOz6KQcqJ0w5S5ZX1s/I7odyh70/3wFLnoU/H69YHUwlmjKvqjiyFOY/rD2TSmBR0lVQGMvIq3iSyPpSCgbOX6iqlLjw8WUwe5iDl0/FL17xq1f4O3N1DWdJ+SqznGAVKCK03By25xn27RY6vracbGfJNd2QLsvMOPqbJTRPr2SpiuXdTqflU1BiIjm7yONVZ/SJ2ZSLQXFTRjl1NQQeYuiK6/hx/492x1VjnWqRt8xzuLAclesXeJGbaDWs2SihJdfu6AXFeby88WVe3/R67a7q4O5TyE6EJPfyDcC5bUGc3RqGklNJT7ILECGEX+BsT95uk8zJUxIyynepVXQTirV6i6OuI1RN7pNWLd6XxOCvNzP6p+2W47pKh/A9tthSpkhKxif6L+bttltiqcyFS1Hg99Gw/iOH8x/N1JaKic+OZ/LmyeSXOk8iZ8mcXVqsxUuWw0FvL8bHL+DEuX3llq0MZTazwtJCTdjTWXC3rH2D+Jx4h2M+za9c7Lynw7xFk/rz7XDuIHzXD96IgF2zKjBVUMk1FtguReYhQcVOhFddopHyWvnyAD92mbO+PxoTxYoAfz4yx3mWsXDPWXPspXs6H1d5dtnD5ZazJ8cgM/CPgY477BUr31wPQJos83qkNda0hc5a7qkQ7lVS5nDr/pkPXeP+vtMOli+E37FB4a717s/zWVL5ybMAdhxL5L1FtrkYDmZtc1rW1RXdKc3tJ6R7fLy5oUEsf2Qdcm9tXDAe5j0E31iVinrvHwu5yVDq3O3clYHL4766qkJ0yizgLmPCXThrm0NrOFiRTO/AsZVawp+yn5nH2Jiw0c70pmi5EPY4ScSoL3dmB/wyBIAjXl4UnI9nQ0FmhYqbTCo9D5T/DhKMBobVjWbJiYWsKn2aFpl2ITbJB+DXYZDk+ThyXjLR6Y3kleSxxs+XCqeTXP8xvNccUqtn/fNyWfKck42VeOcuvkmPUVVeT32KP7xfQtL1PBuPp1FQYmL1YedKVmfnAXgiOpJ3dn/O02uePr96uUDvgl5i8qzfsLWEOza4P3clsFO/wskFg/uPw6+u1qe8v90Df+ZLgGxZJjZN5avPTHQ+rhK/1jqXsPly3MSEF2VY58Onc+w9taqffQlZDP5qk2vvUNAyuk+7CtLdhyVZQvM8WJLzYuHSuZNLGbl8zexhH9s47dnbHIU8gE2nf0U9vorCaVeyavsnlu3v2FlNKc5j44llHMoqX6AFE+uOplo+kLcDp3ByxaOWvZKk4h2+ESVSZ3H+rh9M7aJZYk+sgr1z+HTHRw4azjLB46HlD7nNPv7jgR9JK0hj3Y99UaZ2Rl37PlM3vu6y/L2xMaySCnj48PRqUaKWSBKHFo2j28xuPLD0AcvEYZ+3Nw8l/03/eRWzJkmGXO5b/CDf7JjnsO+LQ//z6ByjzG7jSQY7e84fj9qUm+vUg0Jj07mFLG66jRsauM9P4AzJyWRAcvnDOR+E27bTFLO7VpngLUue2x6WJ7vOqGw6oymMlhyc7ZB9O6ckBz7rTq4k8X1IEAlGg2YR1WOOF/8xJNhms5fB6kYlKxCRpdIqXkVSVJf1LvbRnpshy/Gb1seEN/Rw7ugMSQW/IpWhaxUGr1MIKHD/VRR58JA7/tyO8Vv72GzLKc10WrbU5Px6T89XCMhyLm4kJ+UweI2JRsnaseOi63DWaOSlpH94ccOL1oK/jYIfbrFKzvvMoRzpuuRqSinMuQ/+nUGWrL3XpMI010K4h5LUTh9vjns5iderjBDu7JqKyXxfVRAHuelz7T93OFlmcMzfY2yvf2ghbJmmZUR3RnGeVudvNUXVWj9f7qpfl8Gx5oSf8Vu1OO6KsP07WPk6iqow5/AcDqW797pqc6CQJ52EYJShSJAvSdzUoB57fH14ZdMLHFsQzZvfgG+R7j38eIt2vxXyDjiPEUeSeGr1UzweE8V79mN2efz9ipZccNmkyl//fCjwXOhzcC/Wt313bu4e1qNlyUE6ySeIxDEco6LhAv/6+gLOFXlV4SZt1MUhFblwl7e/ij50yf52dsdnMuHXXZa4dXvKvqGqTKjrMeU9exeJU7KOLLIWQSI5u5Apiw+SvOcf+P7mCinJHFAUzbDjabsoC3OsAgYukvn4a1vx9UjGEe5ddC8H9X2cm5jwUp2Y98nOT2DjVFg6qcZCWwZ/tYktJ9PL9XQE4Owuj855KcX9X/jR/AL8ClVu36ywvq1MfJTzxrcw0Da+dHfKAZo5CTk9UZLC5MUjOWcw8M+RHx0LmEl9twljGpQf6+tXfwYAhcn9UdUbALijvmOmbAC8zVZAVYUz2oCVn3iApEP/YjQatUzu29/n/nb3W48xW8sT89yvn709aTs/H/iZdGMGLwUFwraP+Doy3GX5srW8k0uymRAVyacp55FF3MX570ldDaAt47ZFcyPc6+OY1G6Nn6/zeJ+NU6lLCGkRu/GJWs6/5+Dfc1tdXrNOpsqIfxQWdJc5Wt95O1kU4M/EqEhuy8llcqpzN/a/A/xJl2UO+XjTvqiIYJ3F8WSuNphlm4XfU1N6gIfyuLMa6bd5MiS4mjaf8B1O28LvkSU8soSXEZqrUj9VZV8jyWI+GLHSxJEpd7J4RCQ/1M90etzh/WfYdS6Kz2725oeQYNbGaa6WSimoioTBW3V6T5MjwylTDckqfPmFdYBd0cn5Oys7h73GVFJUDFW4JLasO5dXOekb3g4P45U095Nqo6RgRPFs8HXDDfPiYIjj9v4rk7hhh8pdG02YnjGRrouf++v4X0w+cwoGfm4VulMPQ1Qbp9dQk/dp638f+JOXoiJZFeDP7zvfZVFUP5tyvwQFsjAwgAjFjTvcxqlwaDEJAz/l/ugwIIy9J+1d9XUtQynVXPGi25fjVu3kCzmyRLPo21sG4rdpIQsGrb9xuRQdaJPM4lyUZZoyT+6krSVe6deW5ywzoJnsRHgrFpr0tmwqG7tOli2p+F0/Z0e6RQWkdR+wrGk33tj8BoDbZJ2x8e6tqaoEO3Q5VfShHrduVVjaReZYSg7NyxIemnNbrE9YjyzJ9IrtVeF78AyJjYma8PR7UCAvVG6ZbM/JTrSN1//xVugwGC4f7voYlz15FU2cJYnsOF9KCwyEF+dpISM+lQ21cayTx+7blRQEvpkxixRjDC8Mud7p/r+O/0Udvzr0jNWS1hkN1uu4soQ7Jtx17Y4el+6+0Sw4vqD8byg/HXKTUeu0Zva2eDrUD6VtbLBjuWN/a2EIXe533OeUygmGT699FszKEICr3vmHUpOJSb7mdjrzHnj6oMNxa8+sRZZkrqp3ldPzZheWUPDn00Qf/BH6vQFXjndZhzM5Z1h65HcGL3yFoGZ9Ybjz/DUVofVRRzvp+H/Gk5CbQFC+yr2rFf7pKLsVwhNzrF6xpUopLDcrqIPrabkZbv0EGju//xJTCV7lxJs7xVRiiVPPK9Y6T2fJex2Pc770p4SkeWFZNgghXFCFxJfTKY5YpdB3l8odm0wMnmjAaIISo/tG6Bu9GFys8jA72MWApaoWF9mT5bQMSVUxmKDUXA/f6MUsOXkFQW1ednmMT5kDnW5QePGPfXyY9obNmtb6WN2DmUeYtb/8zmxDotVF8g03wrczVgX4O91euuKVCp1Hzxw31mQ9puT9PB7jIv3z8hf5zSeCm6I8S+A1/i8TrRLgisMmBk1y/gK/NK8b/1dQoI0QHillA6GW3z+EBDM9NJjmxcXMT3Adx9u46BDQ0KP6bfRJI0uWCdH58uqFA72wVplVlAcaNiDLHZFQKZJgUUAAvQoK3c79pk01IQNT7pH5t7lW8NatWqVaL0+FUc6fo7IqhA5A/0iVP3tahb+jf8aglMi0vOssBi/HCUWa0WC5O/sY7n67nE9Ayp6L3pMgD4n3vzPRoGp1RxbcCW03bVfY3CiQlN2lBMSo5PlZH7CsqFy3W+VAQ+u2y49bT9bURVNyd70gF5bwNqczLX/rvWSiM1RSg4FDCykMisHX8VBHSq3XKEtwGVeQAqun2BR7y9y3NCr5E3AhaJknOad2fO36enpL+J/jICcR+rwCPR/XJi9LJ0JIA+ili9l2JRyc3QURLay/sxLgu77a33d9B5TjJq+aUEuLGRwbgwrM2fFDxV3kVuuSW7oTYs6ZrTcn11b0CtrE3z8cCQjKV8n1BVWWmB4SxLchwUxMz+CYzjqkKCqztsbhTFwsb0LoThS4Z73KFYdM3FL6CHN8vOlQpLWd3OJcHv1b8yraPnw7PgbHxKhwngYoJ0lAqwNVVdl9JotO37VBCg6ECPOYenItnFzLu2uSaHTlIAZ386zvN5+1air39XUkbNTqE/DFEHxCSuGlVNvkVCfXuV4OTx9u50wIP0/Fpv4u7d91wbH1jD6mtZGU7GSign0h8V/wCYbgWI790I8XvDWFjjMB2FXiOO/SHIp19+IuMVt52dr3p+132JaeV4zNrOrdJgBsvGYWE5dpm0697SQ3Rtk61fU6Q8xlbq8L2D0w23rKKBgxOZ0b7NQJ4MnZhdyTtpxROxeR19mbgJhiyLUbeBQTeT/0Z6xBM+5sG7YNX6PjSDHwsw2syjUbq1a+BiH1ILQx1O/iUHbooqFkFmVyPDKcKcdWlH+v5eGioyhbdvfB5Qq9Dqr02W2CW117h3y1+hCYPw2bPDjLX9D+/WEAvOroERKfHc9tf9zGXS3v4sUrXrTZtypuFVuStvBM12cw2isADvwFc0ZoCnCdss6dMl41p2iQnHhaWZhxJ6XEYgTSClOJcV3yokK4o18A9P3hafybfuByf9Oz1o/xtZ9N/PiBCf/CqnclGf+XwjefmFCycyyuy654bYaJHz4y4adzzZu8zbUADlBkKIXUo5QNU/mSxL5ELcZOfzfvbHnb5rgp21/z/CbOg2xZ4s2IMHYXp0PyfsYcn1Xpc31lFnbLyDQnTtL3Q5tPpPHvdMdkd3piJc/WQ7xmj0IrJ3lv7PG01UwP1bTax9wsR/e9MYQDcsW0pDMJ4ez2EIpzNcHVlXDwty5HgR77GGH9T/+wNew98hMSKl+FhvBKnQhuLsdtvqwD7HDSXA+bpDrlE56jlU9XDBxNDEAp0c5YlOnlcA5jqUov3XJfH3zjmarBBDwfGUGKLnliAXKVCuBGBcI9XJp11AqF9781kXYwiKfmK9y+USHM/Bz67VQZs1ThE7ML3REvL+rrmvDgdZWf4X6z5xue+/txsg+u5NFf/6ZBqvVci05o7oiXnVSYOs3EazNM3Fc3im6py5lUtv7z3Ac4M/sJlgT4k2xwHUOnuBLQsq0fWKlavjBk0uXTiDfaTVT0k6Ecs5fPytfgzTpajPGWadokaft0eKuelh3b3ddboqvPR21159YmnzYeJ1l2XkWF2WSWZHPIx5vDPt5k/FO9/e1OHx+brL/lfWclZZn9328JQNSZVL77xMQLs7Vn+GF4GNkGA/+rE4lcbH0Of+xK4MU/XFjyyls2yn633aNvkApewXt4SYpmxbq67M/2t8lXUuhmOUgV4MRq+LAd7P3NZnkrgLSCNIrKkn0eXKh5NZSx4wf39a4Ey04tcxC8/tqdyO2fb7DZ1jxBJeeMLyagnvIRkxb87flFMk7b5BKw4OpbczdQFViVx6VF5h68IFP7Bo6u0NyBf7wF8lzF56hO/rKSkmN+9mnHtbCI841B1yGftiaALFFU7fv8+lqY2hn2zCEp/ahjbXWVdGUJl1Vde/vuBmRVv5KD7V1qQriCV9gG9p4rPxkWwLFzzgeHBv96GJud7d6T0Tm29X7AsIwAXPe7BnNI06nUPO5bt4SSbCNxqyPNZ7JrZ2e2k59g9SoscpJcFyAuVZcDQinVQpu+de7BkFmUCcBWJ6sSVQbVRciSal6lIzZN93x+d750K8DzJ5/gmd9NdDxesWS03+//nlK1lNmHHVdlGr9qPDMPzmT+sfmOB84Zof37p20Yn43i0y4vRcKGMI4tjELJM3uY2bXZsrAOi7JexIQLqgRTKez+Fe+I9Rh8XAd06ruP1gnahLnjScfhw79Q5X+/mui9V/vQFgd6ZkEt46oDKkGFYFq4rNyyrc+Adym0P1W+WGcwqTROUpFUFbUgi/2p+7msSUN6NG5AbpiWuGm2znI867Dn2cqrkg/DwpgdHMTw9PXwZS92evkQk141yo6rG9Un1y5eecTc93k6yv1ahwe8bYXc63Yr3Pe3CVQVn2KVkDytfmMX2XauZXGy9jjbmi9p1iRXOItpjUlX6TkjgNSFHiwRpKPnfF8yjwVwZr2mV3c1FX7GxdJDrpbpmBwRxpw6xWzwnY+MygY/TatdKkns8XWuSPAqtRW4659T+XqqdUIsqZplt+MJLUY6IksrH5Tv+BTn7Y2hdK1O8SJpw8aJuECu3qtwzR6FWe+ZGLba+p5CPXQlDSiUeOAzHx7/xIs5U0rpeOL8Xbyd8eR823t3R9nAcdlplXvXKEyaox3bKsF6YHGugS8yPFvkW0Ll+G4Xy1SZSiEvjYSpH9P6s3+YtnwU64uetCmyN1WbTPbZrV2/ZaI1VtMSqnPuEHOT5vFcVCQD69e1/bY8GdR1MeSKk5CHBKPBJgZU2WOdvAyPtVNqujOHHrbGN7LwCSjO1ZLWuDsm28VST+Y8AjZC+Ed2LvnvNUXWZdd1mgxvzv2eZ1J3U89dPt7cHxtNv4b1LNvcNeXcJB+O/RnD0fUR9KtXh1kHZ9Fps+ZW2sHJ2JMQl8DYBSZ6HlT488RcPvZzvvykwUWCzzIis2Gdn6YIDM1VXSZRfH2GifoJEuqSUJvEiWdyz/DA0gdYe8aFxf+ngdo7+/1B7W8zibmJXDvnWm6ZfwucO6JlRDd7NegT13U4ofDsHBNL8osYtWyUxTrmEbr3s+fcHp5Z8wxDFtrGexzeuJCfvKaw2s+Pt81W8Ld+MnFmfTi7joTydkQ4Ac0+AlUlLjuOcf+MY1fKLufXy0+HTy93UZUqNCb88RjMvBsWlZMgzd4Svvc3Sw4PgHeWHtKSPk7tDIufoWTdx/zxbwJpuZqgVlyq8M+hZHILK5waz64aqnU5NwClxOn4rN/myhJ+3Ms6xuUf3ca5l+7lo7UfcMuJDQ7pJwyShDFoH74xC7h38b2VvwEqkojS0/fsulx/g+scLtfsUfjlXRM9DygYC9JQTbb9uWS/soRqcuoFAZC3dSvxj42lJCGBH7zecVrGHQ53UJDpoGgD7f07zXavKMz4/DVufsG5J5Vi9toqb6WvTcdD2XA4nMIdQXQ/ovLCHMWy3nYZhZKkze8SdmjeIzoMbjKul5GY41q5kmqQbb9vveLzsy6assxMzhk/SvON5P57RPMM+aA16l7b1Y9K8gwYzKeTDJeO6Crc0WuTde+jrp4CTdy7dDmbEKvADTsUGqSqfHeDDJLEwM0KnU6qdDqpsvYymQ4nFFolqFxxSCUxXOKDO2WPYin2Zh3GU/1Mw3Ows7mKyeD6vI8vULjyoMrMa2Uulx/EpBsVcqLXc/yMkd9cucjXECbgpLf1czjs5cXrM0w0PwuTB8nsbnb+H/1qfz+Kdc/fN2Yh6bju6HIkiSH1bOPrH12sPbvjdVXGLlQwKvDQeMdzvPe9iZeGGzjcwPa9xHs5Wq6fjIpkowvLM8DjOoFYUlXG/6nQ6YTWKOuYFcVepSolRglJUWmcDKejQXFibfIt0LaVWYoBwrNVCnzKX6IM4KidZX69vx9r/Xz5Vdd+ZFRLZw2uz3vnBms7bJys8vBSE6G6UN/gfBizWOG6vdaTvTzcwN122cN9ilWuPGj7kRbIEjskPwflSFXwwmyFoc+VP0BWFL3FWgJu3qbQ71/P6t84BW7brHDVAetzOL4wmjEeTtIUqZTsYXc6dR1XSwv5+6suDF6ntdE3OgUS4UFq+aZnVU7U1V7+Hh9vCiSJ70M1RUmeLNsmo4xznqSoQJLwU1VyJIl4nTJKsZvMzA4K5M3IcBpmHoQMKMY2/0O6veX96PJy629DYRbsd2J1KI8t0wBbQVfBsXeXdS6FJmeT0wN/aP82c++5o+H63exwYiXSX22Vvx9X5xdYJibphzUFiinBhySjkSlbp/BJfgFl/pVhOSoZQdYz1F36L9fsU7lmn8qgNt9zrIGJ252snOcjFVvO4Qrjdn8GG03ctVFld2PnnYi32eBoUEHSLcH18oaXOZJxhB3JO5jYdiTDglpZ9jnII6esk9/1Cdqa80l5STbLdz0UE8V2bx8+OXeOLkcVnv9N+y53qYVsq7ON19Z9QAvDAzzcyZeSn+7km8K+XDXkWbo2dh+adTxTl3i1OA+8tef9XMpzYIDLYhznJv47/eFG7e8f1/yP908vBGB1/GrNhdr+Bj/p6HR5vffDQ1m86XnmRv9JhF+EFq/qChcWvLNGA83Lfuw3Jy3dNcOxXFYB8/9NYGi3hoTp2mdP+QD8/qn5l9XzrbDERJkJ48jW5TyR0Z5mdQJY+fS1fPT3Eb7bN42QiD0sLkcYsH8U+laUXphG/cXPaLcmuVZG6QWZYntLePoJlMNLifM2Us98Xzt2RVL/lKaUa50+H0V91eYQg0FC9rHmbcgvycd/0xdwaBHcX7HVEjzXBZ+/sK64uVrZOPvknwoHbnR0rXbERc6cPWdpep8Wv56QlUXXlvs5aPSiaYaCd4DJ5fR572nr89TXc93WbVy9uC/U6wKjdeu8lxYxbs5+dpzO4O+nriHAx9zjFWSQM+9Jhp+bz3AfOOgk4Y6kqFx+QsXXjed2iQlCt2lhliUh1tRsppxkm3L31Y3moI83n8wcQJEksTK2FdEtB/Bst2eRPVBMH0zK1G7HpGDUfQtluYeGbJkMaAo4/Tws46Qfxw6f4n/Lk3n99jaWQEiloJDCaQ8g5aaiLpgAjRto94zEiaW6eWhV5Ze4ALh01AkXGaa0o3z77+e8a7fEkqd0PKny0HKFG3eqtDEnTfa386h5cbbCPetVGqRCjyOq1eW2HJyVanpW5aVZJrofVhix0jqgDl6n8OQf7ifqZQLKwM2KjQAelK/iXaJye/2KZ9quakokiSM6Ae/u+nVpbg6zeWGOQuv489fYT4qK5N0KZLS1X+dbz4S/NAEc4Jatzp9/12Pu34sJGBUT5VQAN5aqvDqjlKGrTaQYrBP0NnGawBmga2tX7leY+Z6JPrsUhq9SeOcHEyOXK3z2RSlzppRyzzqTy2zbCcXeTPvcxPQPTbbtzs1gfOpQEC/PMuFVYvYC0MXUdzqu0GnrRk6o3niXqLQ9rdgkHNOjd99vG695d+gJz8VGAAfNE8HeAvfl544TzFGx0aylYp4oFaE8S/X5EpumMvJvxUYwL4/hqyqvcPApAV8XVp5CSeLJCKuSpetR1eGZNz2r0vG47fGPLbKWGRYbw//K3NJdUChJHLNTUvVsVB8TcHe9ujzpG4NPsfbgS9V8fl402uJW/UlYKABxofHs9/bm6ahIvrYLSbHh0EK3dXHKn49V+JB4o5Hn6kRwWNe3ldd08mSJfCezzSIJzR3TDSZg2rmtbPX1YWmAP0nHy1c26JOKjo+uw096rxxnCmidAmbEP9o7H7hJYdQyE60KbSeZZQkkN/j52oRzHHSSINOeW7eq3LVRu1ZHDzy+0ndZ3+mRDKtb8dsHptPv3ylkyDI/BAexKN5JQtSFT0J2oq3lSDdWRu715pd3TXxeXMcigAOE52rldx76l/eXHyH+lycIyDzCE4VfMPjrzc4rqnu3Ntm7p13tvLiqMv5P56EzZQK4KxRFhaJsp/t+DAnmXHEWsw7NYt2p/Vz+s9Varp5cYy2YGWdjSdQ/oixzmBfFjvHf+hZ87zdbeHfpYZ6ZvR3iNlm2f+79qcNxYNvszuVq0s7xc5qGdtr67fjUWUmhfI6Jddx7stlnR1fRXuuM4CCGLe/P9MAgji+OIn5NOCyZ6OBfU1RqYsoSa54DB0v4Z934Z93rNEyxXseYYavw81/0KDlf30Lij6Mg/QQR57aAai3z66Ff4J83yDn7Lyc2fuj2fuyRPE2Caq9EUVUt7Gb2cLuxXv+3bR+keCiuGIpthfD1fr7EG22fSX5xqY33n/TPZNjyNWNn7bRsKzm+nwcjo/nrSBQnFkaTfMjqrVmYehrObIfCLBIzC8j+9nbrHZirnZJTyKY/tVUefs86xIt/3YvpwF+aR9GbUcj7fufO3F/ZtGUzeSV5rE9YT8k31xN01L2y9bk5CpPmKsTqnF9SDwRyZkOY5TGXqNZnpbeYm3JtY8fL+sEJ0XV4LiqSZaVp/HTgJ0qVUo8s4en5hew4nUHbl5fx7Tqrp1jZ0rG/ml3ZR+1fiO8Zq+dI0pYwnpy+iaMpuYz41boSRmlGDifnFHNicZRD7H9ZqB9wSbmjC0t4LTFv+6d84qEA7mzCXeZ2CeBbrAISpeW0yxaJsKep7bbLTir4lsC2ltaDnVkO3/zJhFHR3E/t6X5EpcE5lZQQuH2TQmge5PnCjOtcW94D81W++8REgTfc/7QRVJWYDEgO1ZLtOENWVKfWVVdlh61S2NdI4t/m5X+wObJEruy63PNzTYx8SvtcfItUQvIhOax6tXHzggJpE6dy/W4tG+/xWOfXu32z8wmiPvGXb5FKoY/t8Z10Hhj+hSo37lRZ31biXKhEz0MqbeOhbbzKL9daj/N2YqyY8JfW849ZYh1ob/zXWqd71qu0SFB4a4htpz5vfSwdzIKvDDZj7sDNKimhKptbSaiyhKyojFyusK69TMGuINqjcu1elRWdrQcZTCr/m6MABUz/GHY2k+h83PXk2SamykPshfIrD6gEOgn/fPkXE3Ov8sV1PvfzY9Z7lUld5zkv/Vo99XZFHefzdEBTLg5eY73fm3c4vre3f9D26yccDc9p/Uyuv7Yxv9hgNllqv/XJfFb5+zksJwdgkiSWBvgTlGzgjZ+1axyuB2/fs4N3UyW+j41hVXyCTZ85pJ4uZYxqvd6nYSE8npFlM5Vc4e/Hfh9vJmRkOej2N/j5Emc0MjTHw2B9rPPZsm73hTrh/OvryxKdoLvVz5fuBYU2duA9ZzK4d5V2f3+URmOSoWFH62T2lchw5gUF8mJKOj0LHeMy02SZNf5+HPf24qe0rWDOKeK17il+i/iLZ2NjuLqgwCac5J3wUOqV2ruJqvxZFEpCsBdjNheTl+ToG6F/1oEF2uohZWEe5yKdW7d/OxvJE5tNTL1V1ry2qqHrjtj2ATSqX1ZLQOuTTDIkFWfRu2xf6kxSDTKReqvm9u/h3GGUHjr3YPOMuijLyP0rtb9fm+n8u+8uH2KVz3CM57Ry+729UEypFJaY8DbIxOWcJkaS8FVVGy8MmxjRdOfLkbY9rdp4uIAWurKrqcSqjrZjZolSQppaYkmadPkbK9iNo/dFyp4gxu8x8dmtMnJBFo/tsVv+4PRGLVmibET5+DJSdGOVU/3sjwMdNumLxadmsdD7ZdrHnQInnhEA7xmncVSK4GvTrTbKkGsNu3lM+YMvTLcDIBmt36Oz1U5s6mBX18I5n3NiTSy7bpAhAhYXhnJFromSXCMrfAt4yi4M66eNp1m05yxeIdtpqqQx/IsC1r10G+EB2nXzVROLA0MZrRPICu3mXJ8n/s2N+fm0Ky6GT3+nA/BycBDvoCn501drcd03NYglO+43Lq/jPHTAGWVXqi+dg487wBWPwRWP2JRZ6e/HnrglTGh1s8W6+s+OA1xfpojMT4eACOcPTMcV8kGgnsv9ZQQcsHVbX3YikqOxoF/g9u5Zi4hvrOvvt30NisoowwjLptLMQl6aKlPWkjJ2BxPRMB+vAAVlajeQNEtE3MC1XGnYT1mC2hKzk35mrrWffLVOBGTsZdmW3byams4A4FPvzwBQVs3jwfzb2J68nYeVLMYBcUYjo2Oi+NjJ/V122nHbuT3avZzMNtL05nMUpFr7QZ087jbHjx6TamLGQTuPkqwEWDUZeoyxbCpVSnnut90UmxTeXHSQwd0aEIQmszRJUomrA3fnreKeo6sdruFrKsJbLuHWw7ss23JWrQO0Oo6K0YVwpdhmthdLlAnOm2NFGVV2LkW2/Rds413LGLxO4ferdIVU1TLZHj3efaM2ljMn/+BbE+eCbSfTm1rDcRdG7haJWv38zMqxPrtVxixRWNtO4rPbDA4Cd88DCuP/Uvj4dpktrbV7CMtR6fevgkGBhd1lcvyt5a/Zq3LrVu2/QZNkp0Konhcj3VvJvExYJtRTp5kIyYenHzIQX0fnCpmmkuuHTT0qS3SGyn0rFbod1Z7TNftMjHbidu6OAdtUgvNMXG2eQP3VQ+JAAwm/YkgKkygxQpx5ybuRKxSu2acydI22VNZpF0vhVdYC2+mk6tAm29hZnvV7yybVcZHQUJeA7MZ/rZPQMoVAdLrKpLkmG80w4FYAB88Tkbkj2EWeGP8iLBNnwfkRm47FIlke9l7qN+1QWdADrjikMnaRwuKuEisul5FUOBcCRd4SXqUq9Y4ZSGtsm+m9jIlRkVoeBjOtEjRl48zrDaQaDQyKjcErT2L0ehPLusiWb8pgUpnyg4nGKfDJbTLftAuheXEJXQuLiDJp5yubdAcqKg9l2WoiHjF7eLQtLuayomJKJPBx8xiKcwycWhmJd1Apja5PQ5IgzugolD4SE8X9Wdk8k54JaK76P86cypN2yrxtzQ1cfVZhW0uJeUGB+BSrNJ4VzMboEIcFER6JieKQE4GkRJJ4ft3zHPHx5ojd/hl2Sg9ZUbl1iyZQJ4T7kpZuK4BHZaikhEns9vW2TMU7nVT58SPru6mT6vj+zm4N4eET2re4u4nKqo4S9Srg4eEKyU5gsH81PsUqU780cTpKYvJQ27672MkkUj27B3XJbihb3cOcWOzEEtd5FRqeA1SVFf7+vGjIIMnoxSBzCFMg79HljShiY86SFPAhLWKjmadf6UJVUXTJA0swO+gX55MvSXiZ78+Z4rXnIZWeh1SOxkqc0Y2Boxbfxy7lBD/6+NC5qIjFyiMc9zZyX91oHsrKZmSWZrFOOxDEVahcdcDEqvtnQqzRZsz/MiyE+sf/4rbmA1lit3pJnwaxfGFXn7zsePywFfT17+NaeTft5VOW30WSpo/TT4AHGtfSpUlDgtjBriX/oPcLeM5rDrNMfaAggyDyylWtGjBh0oea7fgB8tNIXKNZXx9crrCss20bsBfAH/v7Meqk38F3fi/xRGwJicCc46t4Z0lL3rm7A2Sc5onoSDb5+TEa1678P4YEMT0smH9PxmEETnoZ8VJULj+mYJLBKyCf0kKZOsky2bHw77l/y7k7K1JBBjGk0T/0W5YXp3DD0udthPBkg4EnouvA2TV0iFtFn0Z9iE/P5/nfdrHN6bIVurdWnKutLe/nufcgwI8le3lB9/veNea39Yr2z5xt8cQ3XkRAgYp3KTbhLC9KMziMiyV2gfSjgUR3ysZfsroCtl/9kOVvSVUZuEbl04g63HP0LyKkbFQVIrJV0oIlCmWZiVGRDNAtWSmrpWxP3g7A96HBjMvM4ofMCK4/KuHYq7inKEvr78+ts4aheKXbinnJBgNRpSaUEomAAhWjSVOmjPhH4e9OMvGRsHrnVwB4l6gUe5mfT1nCz10zLSG0YfnHaZq+k2/Xfk5Ymzwefv0pXg/w4tP3AUzsbSRxjc9s0nFcLWjq0k8cthVmWMeIJJM5ua2q8vrMxxiv05x64ip/sSCE8NpEVfEtxq1wCOUr7V+YrbC1pUr3I9YPdqYHljK9QBWoEybuWa9wMlqiUYpKRI7KnN6eCX/21qyAQs1CXx6+RarFitp7v8o/HRUmzVFY2UkiIgfmXC3z5J/a/qfnKwx9TuLpeQpdj1lv4I5N1mW5JEUlMlu3b4PC0LUKH9xhFuBVlVu2qpyMhv2NtY/ZXUw0aBORbz8x8eowAyHmnD4ffGsiyx++vVGmwFtz/wdcLg9WHtEZKo2TVba0kpjwh4nmdqtqPP17xa2fV+ssGLdtUblti22nPniiAVWSaBtn3d5vl0qR0fr7wWUmUG2t25XhwWXupy5lz1WPXgC3p6w2o5cpDgK4QAAwaL3CoPXW3/23q/Tfbv2OpveVaRun0kPXdz403kB2gES70wqKJHGwoaaw0tM4GZ6eZ2Jhd5mD9b155bdS2sVBv10mfu0ts7m1pH3P5lDBCX8pBBXA810199WJaekMy7ZqgT4JD+W4txd1S0sZn2HrTnnWaOTd8DAOeXszeWc2jf2KaO1v636hmOD4Is1yUFBowFQsY/RRCFIU0uzyTlyzR+GKtf4U9srleLTEsNgYAgocM1d3mxVAN7O4MewZAx1OqQQXOHfNdiaAl3HkXDJuUl8AmsLil3et76Wek+/5s2kmtrWQyPX1bHJaJtRlnrB6ATy6WGHkCsVtPKWn6PtMgO1FAdRLVSk2QlSmSu/9KqH5EKp7XrKiEpZrVRZlyTK7fbzpVVDIUl8jJ/Q6kwXjSTCWP/Y+P1ehy3GVF26NZUsr2/E235RNovEnZOzyaWQlwEdtWR8VCf5+9Disclud+rxycDEzV41jdeMGxJZogl2pmyo8vtDEVzcbeGe6ic8HyKzpsA+AeUEBdC4qop6UxqiIKLINBj4MD8NXUbk1N8/mHM13F/PIvxI9Dqs88bCBrEDtHl7Y/Bq3rZ7KTn0eAVUlU7Yu8wiwNMCfZ80JTt84l8bUsBBKSyRuXQObWqscqS8RLWVwwsvIK5ERjMzK5rk6EUSZTCw+Y3XPTS7wtrSZx7LXsguzUK9qYR09Gr3I1k/G87OPyjAXCyQdfac3UU07cMDnV+4ofk1zP886g7RggrmE1SpxzzqFPU1cCxPrEtbRO/cojY2nQa0LkkQrOY6UnEJUVUVa+CSb/BznLTGZtr+NJmh3QuH1zFg6N8ripToR9P1XYdLSsvHYn6P4MwUTL4wwcLS+tQ2tOBjHyrNzuMzXRLjqRfMS7cNZEOBPqtHAyKw4lvmP54nsehjOhFPaNoNps55j7j2TWRG/jEm6BIxphWlQnE9KihYyYgKuaViPgHnj+DYtlQZ1QuHu763lv+9HjizjNXYrgf6RhGCbmHXMjI10bRjDta1slRd9NzjXjE9bsYd2DaO48fuufN+8Dh+ZVycZ+YSBeKMX7YqLiVvtPofCaZMXPweG0kkpom++dp3ArCOAZoR5/rcyY4AXUYHjedAIiVtC+fKkdq17nzVQapTY5eVN++Ji7FcaLpUkSoF7Fhqo7JJ+Jfkyqsn1vPuUl5HS9UFkn/Znuvk7OtBAC8m7er/2++Dgd2niF8rkn0ws6SqxqkcKzrKBNMj9l6FrDlKY7s3ZDd5Ejv+KMSUxfG4+72WnVacCuCd8+6l2jp+vlxnxj939CEu44HxRgSf/UOh5SOXphwzctlmh/WmVcY8YLGtvg5a0qqHrxOkW9AK4OyRV5fJjKsdjJZsY8WG6eM7QPC0Tahk7mleuM3CWOyk8WyXdLgfb/2bbCpevztLq0n+7doL2p2z36ydreupkqnQ8qTJonWKTYGvoWqu79JZWEnPeth4/aJLnGrXgAvjwW9trh+RrigE9n31Ryrp2EndtVMkMgPFjDEz4U2FrK6v7XlC+yuilCqs6WN3lp07Tzv31TbKDAA5aZvyqRla0pGT2ChQfnWL9xp1VE4B8/R7359G7s3uCf5EWA+4sS7JA4Akj/3Zsc1OnmXhxhIFXzP3Q0OcMDt9AmSDa47Cm/GuiC0UeslZhiJOk2KNWKGxrIZEWIvF2RLgmhKsqDy5XiMqE9+/0pyRQ4t7sHBsFaZmA0e6UQqMVAagEoNx1FslLZVGAP9+FBnNfci6tddfq3bAeqq9KnRR4aJeJuVfJFuGmLInRyWVRbGgncW2aVi93fPy1yaGP8CtSKfCRuHG7Qo4/pAZLZATCuVDtXJKi8vBShdOxqSztpElyBpPW7+1rJLGpjYRJBiSJJ/707Nsv8wzyhF/fcT5OVIUADljaRxmNfg/iI6erGFt55ndNebzp5iBkCV5rG0SJ2dLUIkHl2m0KAddYPTImRNXhjXLq0cXs8TNugcKji2D4swaLRTmg2XtIBqvC5tuQYPrk59Pko7aoKuw2+TF6qUK/Xdo5BkU8DwH+eJWq9NgmE55jctv/N02Cd6Zr9zx2kYKsQqMUlUPdjZZIDP1TWpwVyqGkEIboBIwGu7xpYP79zVQTD04wkOsHfkWwNPsIklkIr5eq8spME2cibdvqS5FWweklc96HHz4pxb8YBmwzsaSLxF9XrGCxf126HVV5oVEkRbJEvCzzU3AQESYTVx1QyN0UzhOHFD68U2urDwTW5aqjJvruhGPBBg7fbuShGF/eOmd1oyiwC2FrUbAb9u8GCRb7/I+c4hFsPXSKHk6e3T0bVAZutraXG7crXL9HYfJgTQkIEK6cZKe3D59OM5EYIfFD32BKjv5Nl49X8pNPIp6kHblmr8poswL86YfCmTa11KUXWIdTKkfrS3Q6rtAiQeWNnP48slhhxeUSb7esy0+JSVwOLEsKJzwXljQ38W5YKF+8r53/szrhnIxZwlVfROAfbZsPQpZk+KAVXYqyiZSm8G1oMFkGA1nKXl7zLeSJ05lEbJhhsUNfWxa+8dftSEjsAYp0z3ujaQwbF7/MqRVzGK67Tg8Xc+FHNlxNxiJvEldF8tEq63OvnwpDGsTwQfI5GqS6X14s6KgPA47C0OeC+G5RLhFRhTSO1oTx974z4a37/I/OicV4dRalJ62eHNM+MzFmnIHMBZEczQSlWSFRPTIt+32LVIYYG/BGOf2IO4795X4FbRMS2adtvUvaxtuWCTvqzdPHtRDUW7eqvLBgLKlBAQQqqmXVCIBDPl5QZA022eTlR4Tr1RkrRVneDz2yXPWJaWsLSa3SNSJqn+zsbEJCQsjKyiI42DHG70Jh8oLh3PmstizG350k+u6yvoZ37pbZ0UJr1N9+XOrS5fVC5927ZNKDJEu8Zhl/XiEx0EUcc03z8/UyC3rIeJWoKLIWb3jjDpV9jSQ++K5q4m4zA7AoBR4dayAtWOKRRSaLULq+rcQfPWXer6LrVYThzxiY8X7NX1cguFgY9oyBmW6+kcceM/DR1yYbxZU7trSS+PB2me+TU3i3JMomznfI8wYanIOUEM0NPzxHZW9jzRL/wN+KRSAKrFfAy/d4sd3PF59ilQHbVIastZ2sDHneYBFEdzaVeHuwNnGZM8Wxoj/2kSsUPvFnD4mBW1TmXilxzwbbvvxkNHwxwED9VNWSL+LjgTLFRggshMd0KwYciYWAQueW70uJR8YauH+lpnTXk+0H791lIClME0ABSmVICoPAuoU81SeA7z+pWP+87HKJOtnWcJxPb5VZ316bT5S5l85dlQHbAh0sZoMmGYlNU/n466oZE1rcfZZREdHkFnhxrC7MdqEY0ZMSAlFmZ5BnRxnIDlSZOFuxUXSVceCWfN5qF4R3oeYiv7GNROszqk3yOtAsffk+El2PqZyIhokjDTRKgWx/iE1XeXFJMYYMzSY1va/MxjaS5X3Ys6irxIGG2mo0399gsKzAALD69BlMKhzOCCA8vJB2Sgm5qi9+JUVknfYjeUdoufe/opPENzcb8CpVeehoAVf/5W0JB1zTXuLb/hJhWRJJYZpnx7lgiUHrPft2dzeWyk0yOGiiwWKoKDJaFfLDnjUwLDeHexveSuaklYAWkpfvY01OmhEAextLfNLtJgJjNlEgWaX9J7J9eTBNsxrnqwbur1eHONWLfB+seTpOxFEsScw4UJcuh2HF5RKzrtP6rStTikgp8eZoPQnvEpW3fjDRIF9ByvfMkFLQoBi/eEePndeGyppHpKraGGjcsa6tZPEyvP9JAw/nZ3HlV5Wz+E65R7YYYpz1zVXJxwNl7o5Io/737l38s0NUgrN0YSYTDOT5Wdf6js5Q6X5YZWEPiVlfFGPI1iX66y07jEVVjfdv39Osfc9qvcb5UBE5tEaE8M8//5z33nuPpKQkOnbsyNSpU+nevbvL8nPnzuWll17i1KlTtGjRgnfeeYf+/ft7dK2LRQh/649h3DFxp8v9a9pLKDJcV471UHD+jH3UwOdfmkgLgr96yE6tY1VFji8EVbGmUCAQVB9PP2Tgg2+rVlH17Q0yp6Mk3pjh2XlTgyDSLgH0oElGjKUqL/9icsjsD/BvU4nLT1jHj8mDZV6YXXN5Ckrl8nOJCDSq+1nNuE62rF6wsqNkk9j1QmZtO4lsf7hlm/P6vjLMwMGGUoWFl09vlRm/wPUDt89F4o6pt8gMXaMQmQMHWyrsiTYyeJ3CzmYSN4dk4F+nmDPbQilJ9ywpFsDzDxi4a6PisYdjVfLFANlGUaZn0uNwPMho87zfHCxbQvHKWN89kN965dL9X5nD9bWQnqfTMhiemosEPOkVg5JrYOwiheMxcCpaE+6ctcsnRxtIiJT46KtS6qXDG0NkWp3BY8VDeSSHwsEGEiejpUrP/da0l7hmX+Xe1Y7mEqeiNK8SfX99IXKgAeT6SZZ2aTLnVqhpfH7/gabtnPmXXBhcUEL47Nmzue+++5g2bRo9evTg448/Zu7cuRw+fJioKMeEIxs3bqR3795MmTKFW265hVmzZvHOO++wc+dO2rdvX+71LhYh/LOXb6TPHBdpOgUCgUAgcMO+RhLtnaxWIRBcShyLwWl4VhmfD5AtIRaC6mfKPTKT5lb8eVf2uHm9JOqlunYzF/z38PvjJxq37lbb1XDJBSWE9+jRg27duvHZZ+Z0/IpCgwYNGDduHBMnTnQoP3jwYPLy8li40Lr+5BVXXEGnTp2YNm1aude7WITwxbdfSZNDl7gPnkAgEAgEAoFAIBBUAf5//Eyj1l1ruxouqYgcWq153ouLi9mxYwd9+/a1XlCW6du3L5s2bXJ6zKZNm2zKA9x4440uy1+sZLRvXttVEAgEAoFAIBAIBIKLAlm6dBKzVWt29NTUVEwmE9HR0Tbbo6OjOXTokNNjkpKSnJZPSnLuj1RUVERRkXXNvuzsbKflLjQii+PLLyQQCAQCgUAgEAgEAtRLaJ3wi/5OpkyZQkhIiOW/Bg0a1HaVPCI652RtV0EgEAgEAoFAIBAILgokw6WzTni1CuGRkZEYDAaSk23XlkhOTiYmxvladjExMRUqP2nSJLKysiz/xcdfHBZmWWTIFggEAoFAIBAIBAKPkCUhhHuEt7c3Xbp0YeXKlZZtiqKwcuVKevZ0vsZbz549bcoDrFixwmV5Hx8fgoODbf67GDAoIpvnpULpRe9PIhAIBIJLlUP1a7sGlz5/d5J4crSBI7G1XZPqYeqtcoXb0Y5mzoWlQZOMJISff53WtL/4hbHTdWq7BhcjF/97L6PaxYennnqKb775hh9//JGDBw/y6KOPkpeXx8iRIwG47777mDRpkqX8hAkTWLp0KR988AGHDh3i1VdfZfv27Tz++OPVXdUa5YTcrLarIDCzoY1Etl/lj3/3biGF1wSpF4d+TXCR896dnn/P51y0yV1NqmaS4BVe4rBtT2PruWdf7byuSztfeJOU9EDY2fTCq1dt8r/7HBMMjR5vIDUI5ves2LNKCnW975VhNZfI6I0hMj9fL5PvU7nji6o1U5Ejbw52/b1vai2xr5Fn76FJlwySI6Do+hwSr7C6Orp69oMmub7Rg/VhxeXW6973lHaOvAo8U30/cb4khsG69jIvjzB61JaO1oXjj/RlzTXNmT24HQcvc1yESfGgm93VROLdu2QeGWvgnbtltj+Qw562VgOWf/dsYm86V6F7scdUy11SWrC1An9ecWH2j4MmXliJ0C6lxeqqXXoYPHgw77//Pi+//DKdOnVi165dLF261JJ8LS4ujrNnz1rK9+rVi1mzZvH111/TsWNHfvvtN/744w+P1gi/mDjcrpfN76rQCl5onHJcBt4lX/a3bYqDJhndDlJ6Hh1roNDLfZnjzqMZAJjeT2bMuIp3Mtl+2mT3XEjFO84F3SVeGWawmaxn+mtrnlYlyaFVejrSA6v2fBXhzytknnmw6gaDirTP8+FY3Zq5jqBqKPT2vOwTY5y3x7eGGFwKyBWh0VVpvKAT1PY2kvjgDplBk4w8OMHA71fJDJposLE4fd9P5vsbDUhezr2t0oK0fyui1CqVte/lp+tlNrSpWH9377MG7ntW5pFxRt4ebODRsQam95V59V6Zoc87PqOzYRU6/UVNYEQxu+2EpawAicfGGvjl2oq1oWcfNHDQzlJZ4A2DJxq4sdHNLo9b1lli3CMGtjd3fK9xkR5f3sLeJjILesg88KSBHF/r9vEuvhV75l8HQ58rv+zmVhJ+UUXlltPj2yHXRsmW17aQuCjH+376QQOrbyvh1g5nOd2p2LLdmcA281qZB29/hFtMXmw+Hc+g0hz6NE5nz5XFHOpWzCxTPOGdHBMGjzzR1mU93xxq4F+dwmpbYjzfjiti5FNGJjzs2XNc307igIcpkh4da7AI+mUUds2z/F1qgK/OpgCQGWAt88s1zr/f21Yd5JYnprIifQw/FI2k6Nnl5OgMHT3qdELxoBuZ30tme0uZ9GCJHS1khhTm0KVxpmX/iNwcAkMdFZX2/NhHZu5Vzi8YV4F5wOOPGFjmRMF56irb+NIPb5cZPNHA6PHu39X3/WQbgXLmdQay/D2vjz2H61X+WLfYuX9/109m1WW228Y+WoOCevWurF2j1IgJ7/HHH+f06dMUFRWxZcsWevToYdm3evVqfvjhB5vy99xzD4cPH6aoqIh9+/bRv3//mqhmjXJnv3Y8PM7AI2MNTLlH5qnRtg14c6uKTXRGPG09flG3qtOm6S09yaGadvWX3o7NxpkW/rlRzj/K14fK7Gwmsam1tZ6rOsqW3/pJ3hceCKVpwRKjxxscXJNGPG2wTDg3tZFdukbl+oFJl+jhl94ya9vZTYz8ITXI9rgx4wx8f6OBhEhtYnwmwrpv9WWO15pyj/VefrtS5mBDiX86Wss9PMHImg7WMlXhavXnFa6fnyeT6W9ulPmyv8xrQ7WJ/yPjathMoUNWIM+3/HKesr9hzWidJw++sLTIAveokufuu4rk2ur9+1Wyx4rEyYNkHpxg4MnRBhvFmZe/wvX+2Ral5Bv3Gijw1a6X4y8xPCsbJIl3BhlY8Wgew541sLSr9s03uzmF2B4ZDn3RZ6NNvPC4yvgxBuZeWf43MGiigdP3ZfL8SAMLe8hsbu3+mC0tdf16B4lSo8SgvFzLtrRgiSXdZPLrmtgUl2Bz7I5mEk+NNnD82oJy6+WKfTX0XeuprHLy57PJ7HQi/CJJ/C81nawwz8PWirwlNgwowRBWwsxrZZ4bqSk8+jTqx6Rek3hytPN+KN8HksMk5veyHSseGWvgl2vPY4ooSaw3j6N5gQrJHipXXgpN5LNzzq2bn46wPo+z4dD4+jR+1E0P733WwC/XyKzsKDm938iQIjaor/LzdbImTHXLIzMAdjaT2NZCYvwYAy8PNxAfJfGO/Al1ZIXS2FLL8c7mI1k+DUmkOdTrio9ONhjcIJU7mqViBCJb5/L0Q7b18TN5URLg/P2WGB3bxPvn0lgSn0BwYAlzbzc5PU6PpMKbQwx8dbNnc6hCH4n7nzTwxMMGXnpSoaCJVaIzGaDuQ6vpVKcTxTqDx7LOkk0fdyIGpk+wLjE87vrmdKwfwu2d6rHvuiYA7Ggu8W3/n1nY3VHafF+nIPngDpmcuqW8lJrOkOwctpyKxwuoV2K9d0n2TIhZ0lVi7tUGdjQJddjn2yWU4Eb5+HTOKfc8Y6QiTl7lqPjpG5tu+XtdW4nNbWRUSULJsxoPF3WVmHqrtbYLu0laX6171RO7PY9ag92XK2+belel2/zeMXyHze9lXWW+vMXanlNCoGV4zWlPAwznoam4wBB+tLWEj8FAZqBEerDEv81lVFnihz4y21pIDH3OwEd3VOzVFHlbP6bVl8l8YHf8G0NkG8vfHzq3ly/7y3x4u2359EDNGj12rLWDzfPVNLQb2zp+uBvstmX7AZLEqAkG5lwls6exppV9cIKBfY1l3h5kYGtLu8nhrTKvDDMw9TZrXVZ3kJnswl0sPRCeH2mw3P/ntxpsBPsib4lnR2luTAu7S7xn5zb+S2+ZN4bIKLJE37x8y/bUEDgXYnut0eMNzLFTPph0P7e0lnnqYeuzygxwFHL/bS7z8DgDYx+1TqSD6xfw9t2au5U9oXUKOdbk/HIHZLvpq05FSwx+3sAsO2325EHW3yVGTUGyv7HjO8jzsW1HnuDqXXqC5KHyc1cTieO9yreQzLuyars/k4RTa5InGn/BhYMqaS6knlicFFmzemcElFuU1GBNoB3+jON5dzeTyfGXSIiUbCxGAI9nZrHzZBy/JDgu0zkypD2r4s6w92Qc4zOybCbvXv4KIU0KbNx7ozpmMysxmbmpZ3knLZU9PWwn8z/2kZlxne138XBmNn2LClBl7dzF9UsclK7BDQt4aLyBt++W+Vg/lqgwpcUwxmdkOtR9VFY2fnYWjXwfTSHaMyrLobwn/Hy9zEd3yDXuffLCfQbLM/nf8ArENjW7niSdk59fO4VbQ7/k78YPMfTeJXh7Bbk+1o6SrE60SOtByxvP8WdPmVMxEvm+Eh9d9xHhvuEkRFrbxkqd8rdOqdYGjtaT+LW3zJaW2hwkPVhihzMFgRv23tCM13q+xc2NNcv7zOtkYrplknZLDqokMebx8r8powGuKiikxe1JSH0yLdsHTzTQMKiIoMtyyAhT6dpU2yc1K2LCwwaGPmeg1KgpE77qrynHP7lNtvEmkI0qRaoPC66Q+e5Ggyb/SBJvDzKQ3jeX5DA41EC75xVP9gbAF4XBE7Vxe91lMmmddNp2wNfYip8f7A63fwE9H4dxO1GvGGtTxgB8WWD1+Czx18b1mIZ5eIoEFBTH8OuDB3n57SO02LiRmK6ZLstnBkCpUWJlJ7lcK6WpUPNMLfCVSIyQ8EFF0UmHpTI0iWzD9Jum83vbEdbj7IbQMxESPw+Zavn99A2t+PPxq/DzNnDHGz+z/bU7uWr6nwAc7Bbr0MdubSnR5KYU1jyUx5bWMh/QmEE5ubyQloG/ua84NfxP2+cS0dztvQEWwXb7kA+ZfMNlPDhB8zSY2ulWnvYez4HuzTDWK3/OMGjIH3xS7yZ8H7Rqfja0kSitZzUsbmojUXj2DnKP/o+g4ist2w81kFjXTmJtO4kT0bDiSk3Joe8Bh7Udfl6u1hU9dmkX53OggGjbZ+Ft8Ma/fQvL7zWnz/DnmUTLb4MCTw74nheetl1eurowlZbv/XCxIITwWsJYr6vDtsXdZd6724DJIKFKUrkd5zt3yxQbsWjX3rtL5vt+MqejJba0lm1cwfY2kXnuQetsrMjL2sGeiLEdbJ942MDYxxyvLTuRB//pILHqMonTdi5dsrk3yPWX+O1qmTeHGnh1uJEcf2u5jW0kFnWTLAqDEqNE87B8FNn2XMW6iaVem7yhrcTJGNuyp6Jtf+f6a25MiizZnLfEAPOvlNnbRLv2Bympln1GEzbayDGPGzStflvJNgmbmwyNR2Mlm9QRi7pqvzIDJc6FWvfUM5nY2UJzt7InwqSct1a02M4Q90MfmUSzwnJrSwlVlljU3e4Z6p7p8bquK5DrB/N6ue9C9EJ3th/sbirz0nADL42wvsdtLSS+7C87uGXaI4HNKGMfxz9+jIGPBsq8NVjmlGtPPwv6tlgVKDJ8fouT5yGE8Brh5+tk8u1cyaf3dd0+k0O1sBB7FEn7Ls5GSAyaqE3WTsRgUVad0M0zVHMfkObGtbssUdOa9hJIEvXUUlJCHMs9mpFF/9w8lvbQzrlO543jBbQvLuaqfFsLsXHwz0Sa3CvqbotO08oGlhLRJhcZTSi4Ib+A3xKTLC7Mp6JgUXfZxpPK4GtiXGYWvvfOZX2dG9h8Kp5xOZlMeMTAsGcMlrCaer0yyA6Q2NlCtvEqSoyQuKXXRBsL4cCcXP46k8jtuY4CyN+Xa8/Y4OS1eeJVsKCHzNiCDBJuzSX2ziQ2j8qx8VSYeT6WXR16IRbgeimXpHuyiRySwa6CiZbxNL1Pro3C4oyt/AZGXwhqwJuDNett/NXX8tbAq4i+ZgLU7cD14Y5heCkh2sT/xz629xIdXH7A8JIuEgnh8IPuu4j1CefHrlMATTH5wV0G6zuUJIo9cOTZ3lziu89uZNCnC7mz5a28e827/H7mLH8nJhDWLJ9+5PFWSirfZCfxyjADbwyRmfxyL14bKvO2s5wqka0w+io0jCpgel+ZLwbIlm+tfrscet14lhtMWvv5X2o6rXwLbNpdGRvayfx+lUxepwKCGhTgU6cEfYesH1+jS20VUi2iNQWIr6qiStZxu8nXv7Dh6taWcr3ateTqFnUgKAZunAwRzZBueguuexF6jbOUa2AqtfRPO5pE8MCVTQhvlYfBx0RAqzzGPqoZJmZfLdMh8jKnY3+CGonR/HEYw8MIbZZP4xscvQb+7CHR5xqroHguVHKafwDg15FFmPJtcxT1Kii0GbYk89zJKBuJ6H4/Dfvm0uCaNIvx56S5T1zjxAOwjLCACEYMnkzjOpowF+rvzdkI3bsINPFXm8fwDS3lEe9I9t6/l7beuknsFY/BY5spjm3H/f3+x5ibn0G94yu48S2X17Sc29x23hrajbD+Hcjxl5gy2MDixtdwx5UdGV3yNKtDbi/3PIQ3g4Gf0+TZD8j4cyVD772VVQOn4OfnT6O+59jSu4Q6dQs48vxr7H/5Hr65/wrLod4lYJCNfHabgYmjjMQ20JQHZe7t/ubQCndzvkx/zev029tcFPBwrhFQt5DY61LJCHJ+gLOpbcP3nqPJjSk0uyWZcEWhaYnVQyTCW6FVeAuyQ40OHqPnQ0aQ8/460OvSEV1rz7f0P46XX2i5ZeytsfbsaCFz39NW4XJbS61hvnUulf/VieRQA4luR1WnyTwKdJPV9kVFnPbyZV07Cd9iSAzH6VcoO1Gz/dhXpsBHwqvUdqdBgdGZWXwT6vomVFnix77awNDYN5IRma24Ne1X+ubnMyHaecrI+Dq6CaKTueeC7hK+xRI7mzv/SF8bKjPyb4WvbzJQr6SUBC/tE9CXNiiaN8HdG0zsaSxZOqpSo8Sw5ww8NU8hwUWs3PgxBpokq2xrKZEWLNHroEmbMPUzsCQ+gZsb2AbtuNNc5sWY4Izje3jmQQPvf1e+OxpAsk7gP1xPU/Qs7yyx9UgC0QF1OIuPg+ubihbfE54L0wrPMgDbdK9nw6BuBmxvITkdMLL9INgsK+xuKgPaiyqz8B02WxqGPWOgxIilrdVLM9HxlOt7kVXbNrihrcRPfWSan4WjsaDIEknhEk3Tm7BTKqAPZ8p7PFVKVgBMzk4FrG5Z2X5Q4FO1UnhmAIR6bkCpVo7VhUXdZCb8VfOrPaQGQaTOg9DPaOKjl9rxwksHLNuWdJPpcFKly3Gt4ay4XKLfv9rf/zaVmHG9zOXHTfgWW8/VvbCAg5hdSCSJKWbPEEmFgw0MnIyBiGzNS6RXeHs2pu9zqFuzoIYcz4kD4K3BBtrEq+wyx3iaJC1E4ZOvtW+4TFHWrbCQxzKLmFMnkEcfC6O+dzEP2xm/X01N59mut/Bvyr8A+Bps4zOaFRdz3NubNgH1Ae36TUMLKbk1GYOvY5/Rl68ouuNN+v6rsrKTuX4GzYPozo0Kw5poAjwt+hHSsCd4BdKtza3c/M94Fnvl8HMf88T+JHyUfI4nzf32S8MNdD6ucOwKa///YGYW84ODGZeRRbTJsS5r2kscNLuSyy56xnmDS7hztvsEIJ0Ki2hXXALeMDI/h+6DQrhir0RAIfRpnAarK+82ua2FxIkYicVdJf7pAA+uMDG9r4Hn8/LpVlhEihqKagpgbruHuG7QYVrd8zZrr7Pmf4m6JZU9Jb5k7wrC0DqfNkDd+h1ZXJrAnqYwLdf2vn1b2sZFvHqvFsakShItzljLLuomOZ04R/vbWqam3+AoiDUOjqRdu1tg+ySHfaC5IlPOcLPziev4X68XbLa1LLFaq2TgVrO32cEmEiBxf4vW/FiyFYASg4KXCXJ9gYnx4BsMr4bgr6oc6GTitJf2zn1Vx34mSFWZGtaDV2Pr8/upJZbtvyQkMbSelgwm//IC6hcUMqBosst7MKDJMPo3kFzvBq5PWcXnYaEAtAprSd2gevgYrJJG3YDGzk94zbPavxunWp7B6/f50zyukJibXsXPaxP4KrS4PRlJgnElpey6LoofU17l8E03s/bgS8ACm1PWCbbVPEsS+Nklb/S+KZ3b2reiTZ93ef+npQB4qSrjDbZjUxmNcrpQZLqJ6MCt+EuFPJCVzZ05uawL7wNs1s6pV3AExRDw0VGQjTDjcgBeHGEgMhsbobo8VLtv3EtRadL9UYi5HKLNWvSb3obpN8HVT1sUGkpcBikBWhIlqeMAMLm2ij428GZKGy63/Pb3NtI8KojV5lWQx/dpwRN9WjC4WwOyd2XBjPUuz1XcvsBmXtyrVSwrnnyDiABvmPUz/pElPMA58L4cJAl/byOB3n6UDdUlRvj2hm8ZuWwkAMF+Wpve3Uzms1ElfJar9bW+qooraXpDW20uSXE4SYNTeWaegm8ljMIRrXMJiC6mSbGtUgogoHMrwOq18eMAf94GJIMR37BSm7INr0sl7WAgUVfpRMkqnO7ktokkbKuWiyAhHOqZveSNhksnxO/SUSdcZBhlD/QfdqOqs6Qg9lZjgP65+VyXl8+0/jK/95KY+IC1wX53g8y/TSX+1mXevD87mzZFxUy9zcB7dxtcWni9nQzEZd1ogNG2c5cViC0tdTzABY0j21PfOxQ/VeX6fM/iAcuE8Acys3k0Q3NfLDVK/HKtgcP1nd/D/sYyzzxkJDPGxNIzifyYmMwKc1zimvYS6YGalSElTOL+pwxMHmL7iaiSxAd3Gfj1GuedQFK4xKY2Mrfk5XOirsQDTxr4ZKB2jlAnFitnrsojn9BcYT/3v9nGJWzE0wZGPmFwmkjGFWcjJOZeKXE8Bt69W6tzqVHCy08hxMUyeaqkac4P15do6OQdvjzCwOcDZGZdIztY2gEemqDtf9qcRO2tQTLHYuCDOw0sjLe6MJV4STZtzU83KNuHKoCjO/r8XprV7XB9Wy+HVqktyMXXwSpa1dS/Os3m90vDDQTpnumuJhIPPaE9oDodstlYwYRWrjgae+GY1l8eXnODYZqdhn3sWFuPih4Fhcy453eHJI2ZunjdO9olWxSQO5prwszTDxl4/DGDJVHZMEOm7QkkrZ2qssThBhLFXpqVPDVE4t3e7/FSajrpOovC+DEGnuthFUjyfTVvnDJLXZfCIs5GaKE683tqAi9AQ7Nl4e6cXD7MS+Hr5BSHZxBtMvHDTT/QNbor/Rr1w9/LNt5kWtI5Hmz/IJ9eP9Vmu1eACdnJq0ohjMxAzVupMEBlcXwiQ7JzOB0t8dEdBnxCdN+/TyD0ew3qd2XKiPW0jbB1N+mbX8APicn8fuYshxto/XBznbL5iYwsVuUH2Arg91uFjKCGBbycmsYPickYJc3qU0bZMj5PylaPJVe0Lbadla6OS2BVR5mFPWQal5RyorFnCiNnVvP4Olqsf4GvxNH6EhNHGjncQKLtLV9wWonioeKnAdgttaLefV8h+4Wxoq3m1ny4bgM6FhUzWMnmnk5nGemdAc2uZ3SH0QD0y8tHVmz7WzXMNs6hkSEG31PDATgZo4VkHYmFH/saCPcLQaqAQ2pEt0wMsUW0eWyiyzJGyeDgcmyPoU4kH/X9nDr+FV1rSeKFHi/QPLQ5L96nJSl97V6DJoADPLmf0gf/offJKxmbkUm7oiJGZTkmOANg6Cye7fWKzab2xdaEasev/QyeOsh+tYnL2hhb3+KwbVfPT/g6fxQL4xPZdCqeOQN+RZZkOsda277By3Nb1uG0Z5kXMhE/3yaWsa9sCJzBV/yYPBlUL3wMPvhG6ZblNWidVrurby/3Gs1CC2l7109IurE1zGTimjHbnJafUjqc2OBgOnh9ytIziQzJycUb6D7qA0uZ1t2usD3IyxcM1vturJZUSAB3hkk1zz0b9QRfs/IuqjU8d9LGo8ChhRtsO3y9l0qi2oPMQDsvTcnaoJ/q1xJZlmgVE1SuNFRXKcVewqwT5IMsS9DtIevGTsMsf4b5hPHNjTLr20psbSXRNcbqAav3lcwM0eLbAQyqa4+WsozyJpM/e5rK3P+UgbO6pM7Ovv6wO62eErm9c2nU9xwB0eZvI7ShJYeHwdtE81X/0ODn323O9NSQKeYTOX47AdHFNLw2Hd8wa1uoypRpdbAOAk8+bCCgbiHFMUYM9ZpW4VVqFyGE1xJesrXjaFtUxG9nzrIkPsHNEfBvM4kHJ2hZTMsyfM5ITOKj5HO8es4qEBiAT1NSyfGXmH2NgeRw68e+rIvMlMEGG+FJMqo8m55Rbp1lFVqEtbDZVmYJvTqyNcd0Gcj3NZKcWs7bFjmPu1FQOBqtuU9tUVo7LeNQH8Vah5FZ2QzMyXV/gB5zj9e5qIgY86Tw81u1RDZl8doFPpLFjclTlscl8HlSCm+dS6NbQSH5vlZBc0Thiw7lnU0H8/y0SX6Xzl0p1Slrirwl8vy0c5Vl0zdJWgz3/U85zrDL3BXn9jYwaaTRwf3aVWc56ZyuLYz/12F/VoDEmg4yJV6aYPL4I3bXlrT98WZlwa5mMv8baeRsJDRyo5iJMln3vX+XwSFDfpf8QgJ1ioyyJXDql5Sw5vQZwk0mhmblUKD6skdtygo3yzSt6OS4z5lr8gsjDA6T8d97aW7KQfWKbLxM0uyy5JcNmO+lpBLZNpePb68agdVgujDWpk8J0RQ6/STHhDbnmxxya0vJ4uJYxjO9nrT5rUqSjbKtIFL7ju2vPOtame3NtaVuoktLefxRAy8NN7C7mfYQexUW4o3KuEcMjHjaQF25lNZFxXhCsHcgg3Jy+e4G7RqTB8skmfvbz/t87vSY59K07yvXXxNUv23UnV8TzlqEUxmtX/J3kQFWlmSm3zSdD6/9UNvQ41HLvhivIJ7o8gQx4c01i2I5qMD49ExAs7I3GLebh/t9QrDJxL1ZOdBqAFz5hNM6NA1xnAh1KSqysYC28TJPpgf9BHXaIN89HRroJvRNejP2US05ad3oAu7JyaNLUREy8KgufrhMEHT1TPTYv38v3TESKkv6ezsNB7CndYssh20lTlyeh2blEND+blJGbWGP6rj06OoWg3j82id5pttYRhc/xWuNfyR0/B6ku76DrqNoHtacdafP8G5KKrJq2z92CbGe7+XhBnYrt5BSeBmgfXuPjTXwktnN+LObJtEu1nVcxNQkW7flqGb5tJyzDLn5lS6OgPm93iFAZ322SRoYUEpsz3Sazpvn8ngbvB39VIe0HsL8gfPp6SXx1hADPvpM1yH1MTboQurl43kkM5tfE5MJUVy//wCvAAY3cRSkAVrWj4XgMo8u532T3OpmkGz76JYxIZxTQ2lUWkqgqiKbx+M6IVaLdGig5+uGFapBqCXhFJU6jvw5Btt3V9SxG0dC67OkUQ8YtxPu/Aa6jS7/Iq9kQlhjm02SfwRyUIxTxdLOV/uzcVIfrr3MVsgKCgmn6Z9ziH7sXhq+/IXTS60fsp6FA/+ifonnBhdLnezfg6+LMcNuDubtLFbFTEoIdOlnbc9zxvRyKDO8zXCi/KO4r+19dnvKGVTddT2tbtKV0/U3ksy2jiqfDjQ4GMz0ShLJyw8GaP15ruQ6wciO5hL1A+vzZKeXtEvJEiru5xUx3tZvKqPplfgPfcm60+DFlwNkpveVafLDx3jVrYtkMECMNQwm1NssCAdFw+h/YOw2eHw7jPgD7vgaAupo/bv5nr72IBEgOIZK2vPGENn23UsSDa9JJ/OrlTbP7mLnApjK/TfRC+HP9HqNViUl+LkZYAC+uUlL3vPuPQa2tdJeXeRDq+l7zeuY6naoWAUkiZ+vl5nXS0IOVMq9NmiWyHevftfpvsaBUbx3t4ENbST+6SDxxS2y06HuiyTH+CUAVVUpCapP+8JvGVJsK6x2Lra1jC/oLlHoBX/01J6B2rg3fqrKm6npBJUTH6m7G+f1cOJZUBHqNrmO3uZ4qlA7S7MxvLHj9ezq0a/QOphJLuwasxPO8vY9Bta3lXh+lCZMFPhIfDRQZp0uQd6JGDf3ElzfqQIAIEqXfZRw1xrH0ZnaJDUlTOLpBw2cjNbyFLiit52HQ7cC22U9/Mtpg16hpUwwCwygUwDlFxKuKKyKS+B/6RlMeeklOjYMZ2VH13U5FyIRbacQmHGdbJPZGeBofYm8DtZ67mskaQndzIPA9hZ2A6vR6h4cbjKx82QcN+mS/lUFRgXufc7A8w/UrktWWXhBaZTJYdmWsjCTyvDVTTLv32WwJF0EzWMkyS/WaflxYwy8PlSmqI7WopeajQ3bzO+mrM/c3lJGNv8uC4kAuKKgkMuLijAZJEuMo74ldg5t6bKuZZOBjCDtGlr4BSBB7/q9+XfEv3zRx3YCG2gnSDb0i6DdA3+7vEa53PCm7ofu3L6uBTJLaRVGZ2Wz4XQ8/fPyIbgedbxDWRuXwKT0DBg6S7N+O8FhEq3jt4SzPJOWwaA63bQNbQfC2M2am6lk+11+l3uWe4PTua7A2j8YguvbxPi6Sm5oH0/coKSEg0pDxjZeCG1uNddTX2coDfTi8cfKt14Oz8lh8mCZo7okb6VOmnWYovWX3RqH07lhqMP+Vwe253hoPUKDA0iMuZ7Rt98IoQ3gsrspc08IVRSM4GAJD2p6HTH9Unn1XplDDSSi617G9het2acV2aoojg2O5KrmrtcUu7aggI+T7cbfyBbOCwNj6vamcfMb0Ucrrb7M+rx9w0sIaVSIsY6HFnCD6zCCWzNhWlIK05OSHfa9e3dHHip+ml9Lry33EuN6TORGKYjPkzQvkhFyBD1CW9Gjbg9dKeeNKcovymFXk8gA/nezzihgftYhuhV76kVUPDV+TIivQz3svye/AF8mXPsEn15+j9ZeOgyysT67xImAInn5gcGLVi2zWHO37bgb5Ku9F1XfL3UYAoBPq8sIH/8Sko9zRUOITwiNQptwOrBT+fVywWtDZfyjigi52rPy7WKDuaVDXcb0dpybyCrQapDld7OYUIcyYb5h/H333zzb7dmKVVTFbR4gaznd/Mngzcup6U6L2bzvmMug24MA5FzvejWogpbXsOSuJYy+Qqdc0PWnTuPJG11l+bM4sD5cOQGePqwZWGQD+b7aahVena3XlR5YqDu/7qT1ukCdllq/0ew66DgYnjkKDbpZ7ml3U5lvbjTnLfB3rpxRvRSGP2OwMdyVsbCbZuTY3SDI5t5ua3YbvJrFNa1qaG3ZGkII4bWEQadxLQ1vDLIRLzeqts8HyE6TKEh+YdDjYUo6j3BylHsW9JD59RotQ2g9D1zHDQo0D2vO120fsWwLOT2IvONPEeYTSkaQxCe3G5g2wECOv0TzYsdgFVcNTkVlaPeGNK1flyf7teaZrs8A8EHyOa73z2FNe82t+on0DH7uYyDn3nRLohRFtp61tIoUZL4uXLWdERugEw7qd3da5sXOn/LjqCv4KdE2yNP+Kl26j7f+kBw71Ztz82hVXEJyuMSnA21d0ze1lZk60NquXklNc6qUaBjUUHOvdXE/TaUiRl82mondHd0ULw+xTtqa6d5vfJTE86OM7GjhukspcyW8zeyx8Gim1dJkBDoXFTo7jGdHGfhigExWQxNX6QR3P/M76m2evJddOdDPl9hQX5LCtSVXnKHIcK1OKXDmSi37s7Pll27SJZBa0kWixChZ1kylay5HW6u8NtSsEBo211JWlSFBqfpsoUaTCpJEqgfWvOriSCx8epv2bCXguxu1EIp373Ke6b8irLy8TJDVK5TKruRIcrjEPl32/oM9VF4ZZuDjgY5tUT+FjSot5facXIbm5PBSajpti4p4L8XR3fnHgb/zcIeHXdTWeZ3KJlhG2cjV9cuZXQbV1VnpgNjL3Ze3x93E/K7v4Fq7WF+DdUJdNvEOLlOAmZ+5J2/Qpfuxbwitbv6E+xvdhFfPsc7L6GhSUspNefk2T1IevdKmjCLDzzf/7HDsTrv+5ua4jowqfhbF6A+hjQDHNzRRCaFBiftASu8ozRNid1OZFx6wPl+TDKriTWme1WrorRNeTE461X5to9nz6g1sf7Evi8ZfTWyou+zpdv11QARhV97AKCUQ09GnkORgIitgea0sA5sNZNR17wHWpFwArbEK+TFdHD0FXHLPjw7KFz0yElcWFFrboR1/K12YWGr3DTpJbhviE8L79QfQ2zxOPDdiNd8O/M1t+N/7yecY3Xo4PWN7Ot3fKsbRgu/TogV+Xbrg07Ilfh07ujw3oCmgAK4Yy4wHezDmmqYM6mq3gPe9cwnxt1VS9GwawYAOdXm6n2sloKfI5tFxRHYOjxjTkYyO8wKbJx/d1mG/OxrWd64g9YT9jWUaXZ9GVKxn8WOSJPHZvZ2Z1L+Nwz6DajuvkVy8d2eW1IBQ98okzWDiiRCue7YBEZqyzcM6ANww+XkO9neuuO/WsJHDtn/7WPMM2bvehzbNg5vfZnMribhIyO1obuNBMRDe1KUiVfL1J7hhPoGxhXjFljOHcXIfKy6XaNT3HE1vPsfXN93G1I532njv+dYrAknLm2RPm/QgTAWNKIgbZdNlTL7KdT6HixkhhNcS+g/QpJpg4Od4nUcwRbB3+VYPVwSoCgaTLzPtBER7nGVHjy9pSV3/RhidaLnbj9nCkGxbV1UJ+DkxiRvC2nF5yEDLdlVVCfAx8tfjVzG+Twvub3c/y09lcEN+AZKkuYrP7W3gwawctp+Ko7cLgc2d6LzqtC5RlxutfFv/LgRX4NO4p9U91h9XjtfcQ+9fAN5WDfngy67D39uLy+3cXB0sPDrrlSwZHQTll1LyPa6ZCrQocXSrVVTFwQJStrTbllYSkhHGdx7PsDbDHI79sMfLlr89majrrd9l7fvN1HTWn46nW6EuNEEy4O2i/Z+OlljdQUaRwKArtFCN5ufEJBvBvIxmdTSXrgJXLm7AVfmFLOiuDU4ZLbRJud6yva2FxNyEs9yguwcJ+O3MWXoVatd8pF5Xbpt3QLeEm959CgqxnVgU2M0zzl1WzLoe7j/8rQ/lENTXqk33MuvLqjL2qqK8eL/REgNYlkTrbITE9pbWTP+v3ivzS2+ZtwZpSwFWhpeHG9jRXOLjgbat7UgsbLl3i822mEBtMvJuSAcONpS0nAPAFS7c+/rkFZCSeB8+KjQoNTE7MdnitWD/bMddPo4/G91Dq6JiPiKaW5rewvA2wy0l/eyUdvYTLF+DzloWYjcB97Gb5OutoT0fd1p3l9hX/LK74dqJ0O9167a21n5XUeHFkpEVu4aZhzs8zE2Nb+LjiKtsdwTXg8uHwV3fgrFyAqMcYGvtCFEVOkV1Ahxzo5RZXb67QeaD4vs4S4QWp2kWjvUtL9JkonG/ySw+cxZ3hF1lG55VltW8XXQ2ddLe4ef+P1j26fstxYUQGezrPpncOyVDSFTDWVLHybsYMpNneJ380iiua6UJCr/e8it9GvZxe05neNJndIjswJtXvWnJNxDcTDvKJ6SEwrLwAsDoW46iOqSh9u+IP6Dd7W6F8Crl6qe0zORj1nlU/Mb8Asa3f9C1i6uLEIjGM2fQ5M8/kIzlWKfv+BruXwj9XuOqFpFMurkNXgYZGuqE/pY3cFk9W62qLEt8fm9nxvVx7a1QRnnLYNrfW6nkpM42t1nz7r4Gt7M3zyj0NRAU1dh6zgok8AqOiCHruhzy+mZTp4OL3AOeWMIVu+RJuv5Wjz6ppl4YNnh7UVTPuVHMz8t6P6/1eo36gfW546nPiOqYTXIDE9P7ylpyQzPhrfIg5jI+ubo3/xvUhus7Dii//gCSTL1emTTonY7k7V9+eYfjJfwjSzB4qcz37c3iJr1QDNYG1qhLJn8M/IMbevmwubW2wkYZwYUS+acfQymqhyrVrrdfTSCE8AuAUqUUAurYxK55imLWut3U5CbuCG3HW2WWnAZXuDnKljtyP+GZkjF0cBIHqZ/oepX1kUFW/7xRvZrw68NXYPRydMmSIpryQloGK+NsY907FRXzQdNB3NDcqkEe03GMw/FT1McAWJ4zkMbFJZpA5x2IT6fhNnGKik7zaHLTSUbqJ8q+IS7L1Q/qQYPKLhzg5Qc3vw1NejsK+k4mIfbDjoREUeo1mArq0y6oN8VetvdzvPEQp8Pj9zd+77BNBT5KdrTsqagw8AubgXvqrTIvjTDw0e2OdVw3eB33BrVidr1biazbyVpXVWX7qTgntbES6iQLsgQOsX2etHz12kkYe91PvavSadA7jbAHV9Dp9u/53XQVv5ReZ3c+6xlTwx3Pvq2FhL+q8HMfA8+MNqKYX1WZOzJo8Veti0tsnved2bm00lvRuj8MOk8M/WRHcZIUIctuPItpnM/vMRPw7+W63d6fm0P9SKuiocyIoVwgvbfBxcs70Ehm/pUyu5pZlwIsj6V2bu2HGki8c4+BlDBt++RBMgcawPQBsk1Ssm7h7bl65BoAom//isZeVmWWn4th7qDagE1KO4/qBdC094v81n8mfe9dyJSrp/B89+ct+1bEJzBUtfaB9haG+5tMxlQYQ37cg/DkPl7t+SoAz6ZlQJvbsJn0FukUlzdOBp+KuDy4+pJsY+vKUFSVPNXXSfnyCfAK4L1r3qOPjasvVSJsSZLElfWutCTZS2xk7Snt2/2KzjL3P2lgmW7NW6MsUfYsJODPM4n8lnBWs7R6MDbOk/va/H72QQMPTjBQUieIVc/0pWtjazYkH91E0eRBWJczvjTdRq+iqaQbnLtarnzqGr4c1pnhV2iWsHYR7WyUpI93Mitr2t7h+iL2oUW3fOy02OVRtp4Yda6JJLZnOg2vTyMlugIWz8c2wSMbNLdVcNsuGkdUYG11Cy6etZeflpm8oiF6Fb0Orq2ZtvXxhSZXO84HmveBIb/A+F3nVz08EMLt+iOfBo5hC7bZymtBxVuJ+W8Zb98tcyIavh8cRkB4XZ7pM4QJfe/DaDB6bKBSvAK4IjqHrpG5xEU6xpIHxhbikXKiHKF1UvdJNAtpxoTOEyzb7DPF3+Fk+Uaw9T66s8WdLLlrCc1CmxHRJpeNtxaTFSjxxlADRj8TMV0yLYk1l4/5mN/u/ZmoYA/7eoMX9H0Nrplo66VVDu5ClPTLVBpimtEstBmx3e9i6u2yZVUMgOIw63cSHlN54+LFwgUyjftv42/0B9V9eoUSFzJhmTuhl+zF63X7WJYB4cFlbq8ZWXojSkkIhUm3kEy4g8XOUjfdRDewbB4UbBXCH7++BQ3C/fEKqY8rnC43E9OBwW1u5/oGfRh/+XiHgR+gpPmNtC6czny/wfyZcJbPks9pGRoHfm4Tp6g/e3m61MZBmnb++kb9XJZpEhHAm53Gu9zvKZL9oGIesMvcmzsoBnraWXElSaL43M3kn3ocg+zFgt4+nK5jtfZ0ahDqcJ1Z/WfRLaab5fe2FhLxkUCdUsKduNUrqgLBdW2eW6nRMct4GaG+oUy68zfa9rVdj1NG61hHuMpYC4zL8NxlUT+fmZjmGEelePuDbCS4fiGBsUWaG26bW8m68TNSCLUpq49vyw10bH9nIyRbS7yOyYNl/rxCYnUHx2cRUaZUaNADJuy2JGS5u+XddI3uSueozsy5StNG77ii/BAPFWjcvhunJywpt2wZRnMVypt4lcc3N8o2ayjr+eAOmWIDfNnf+RDxki7OrapsJjuaS3x/o3vN9+5mMq8ON3Kbnd/va9e8i+Rtnsj7hSH7WyeZNhOcZ09Y/kwM6EAuzif/TmPrZBnqd9Um1XaEKCr/02VEt6dBQCvyTz6BKU+zat3V8i42Dl7PfY8f1hLeSC6EcICnD9lkB3ZKd7Orbp+Xne/31y1Q7Rtq+VMFlijdiVPqWOJAPbL26Ok0XFvDt4zyjnfjhaTnyz5f8tRoA1/2lzlwuVWZ56zdl3m8PNCrMQDjrm9uM6lvWlJKq7LwGbn8ac/1D02x+W0ySOT4SwwYbnWTvyqyE0ag352zLNsqK0ZoCdUk7uzsfByNCvbl5svqWtaItuehy8zZmet3cZpME4BHN0L/962/u9pa3RfcvoBnuj7D2MttQwjkIT8Q0qs9xgd+4VD7Rsy8VubVe2XN2jx6leub8gm0SfBEh3tcFvX3voBXyz0P4dAtkgSt+0O4FtpwPv2ou7WlAaL8zcqd27+EVgNoPO0HQu68kybzrUn1qus2PcbJ8nOesrOFzMRRRs5GaUGd+4O6ciRQU8J8d+N3dIvpxsz+M92eQ/Gvwwslo3i6+BFMfrZ9fOMbzhEQVU6yzpvfhRY3aP2hG+5tcy9/3P4H0QGu3bx9XbyMoa2Huq8DcDJGosXAZMJaWF3ao4J8aRLpOuGbU656Aq5zvmxhRencMNS2gT+mLX3H1U9bNo0bYyC6Syb5La31bNinHaFN84jt6Tyu/lJACOG1yAs9XmBwq8GaAKUqTjvhX3trE+UtrZz3siZ9EogK9KI+RJN3bBIlGZorYZHqOh5HMlv0yua1snkt2FIZZHPCjvaR7Z0eyx1f2Z4L4KGVENkcL4MXn1z/sWWJFnvevrMD427swPzHeiE/sAip2fUw6EeHcvpJtuJuAnjtJH64+SfevPJNnur6lMPu1mY/x0HtbqL+5SN5vqHzTKuVx+ymm5rOawFt+EyOpW9+AV8kOS5FBNCxQSjZgTLPPmRkRWfzp+rkHV9W5zKb3+/dJfPMQwZUF/JMWZuxTwpnV81yKes8ntMlS7MnwsYS7rp92muCh2U7ZrpXXAzSo65qgn2lfQyu3WDLMvy6us3dTWVmXmfgrlzHOpiCza7EVzxmk4H2lZ6vMP2m6RhkA79dLfPgEwZyQ11WwYLRIPHViK4Oiip3mUO9SqFjnY4UeybLuGRlJ4lfdNlyp9xj/ftYc5URzxicxsgDdL7xQ8vf4U68HewZlVm+MuZEBcLnzzQZBcAvA37h8z6f0yDY1sV7TAfNs+bmJjfbHhgQwWOdHqNeYD1mDnmVv5++DiYlwCTbNeUrNR/VxXK7swiUEeQbAt7mCYe9S7oeb38ILOfh3PwuPLEXurvInqyPS+w8Qst6PuADVFWlEB+uKf4I7vzK+bHlYTDCTTqh1VBObOeADzRX5QEfui0mSdoycKs6yqhl7ha3TXW7ZNart7XjyJs30zwqCBr2cF2wHML8HT8u1eRLuG7i/EX/n9gyfAdhjazZmN+7uwMhfl68MdBzDwuA3x/txT9PX0PvlhVd5kvDxiLrKpmml58WC+qCxiGNub/d/fgZ7RRTkS1g9EpN4ShL/NlT5kAjWbM21+vseSWvf8mSRdkBcxK9sjj+crnpHc+ve97UjHR6PldxJYR/3e9rroy90hpP2+leGDoLr4ZNiH1rMr5trHHVNtevoER+XQPN2yHMJ6xCx9lwHkK45RSoRAVZx35Zkmgd3prvb/yeDnXce0Y0DPdnX927SGx8B6UdmhBYz5xrxluxrsXubn7ZYwwMm+ugpFU9eJYh9t5Od37jtJx3eX1rBRneVlMYXBnreoWESuMXjnrvXBaOu4pZo6/ApoWVKWJ195McLlHU3JeP1bss26TgaOr+v737Dm+qbP8A/j1JdyktLZ2MllGgUAqlQAXKUEDKUpZMgSJbARmK4EJfFRAREDcCvqjwQ0FBRUERxRcUARFEoSBDNqXsQlu68vz+CE2TNkmTNsk5Sb6f6+oFyRm5kyc559znWa1vIjDaePdTV6Dg24+ub3CjwSUPTByAvmhn/j6JRr/ut9Q+sk9Ohn/dN2GJPGh/FKNuZOHDIMMmIHW6XcaNk34IaaVtbil5eWH4DDU0EvDL3VqFmgGGd/B10z80GwxRtz3wxd0pHLyqamuTLBDo54nH7q2vfRCcAsSkGF3PkoMcAKDTLIQAeLC+8T46a7M9kTv+Z1S525fbI7IZcGaT0XX11Q+qb3xBZAKQ+XvJ47sHcH8h0M87Esj+FwDQXq82XIKEXbPvQ8bNO2hUqilOk5CSC7vqhUW44mGYZf/x7xkc8fLC0BoRZk/o05O0NyDG3riJ3b4+6HE7G99WsfwuaXJEMg6f31WmFt8Yqc0UIGMjACCj+RQ02fO6+Q3MKJ2omzMsbhh+3vcOut68CqDkvQ2foUahGqifb3hX+1xoe0AcMnguuEoUcPW6NmlYq427oO9koH4rs6MKJ+XewT5fHwy4dRvQm+cyPiQeEg4YrKv21daWS+aasXZ9CfDwxqUtSxB+A/ijvoQnWj6BJu90xHFUfEAcAcMLryy9KexWZlzCS0kP4K+zxueWFTVaAPu0/2+Xewct7tzBHz7Gm7pNSZyCsV88gXQY/449laZGy+Ma3WwHlmjfWnsMMXXzr0fdHmgW1gyR/pF4/JThBcbEZhMxsdndab1MDGz8yuWrGFsrGpOtGUFXf8qZUhdr5TZb9fDWTvsiBLCyW9nl4SZucuq/dlBt08v1L96C62lHPQcgNnyr/Vf/fnxo2QGPLNJrCfDzAm1LJXOqxwLT/qrYa7QYAY3KsJY61MMflwuzUV2t/a15edx9L437AAM+BKKaA0utHOyuVHmFeEVjbN03DGqiJUkqc1EcXyMQ+5/rqu2TbgUfTzXqhlo3yrYlN3pKHzOtOYYaf9FKbO/hre0fu7fsVJ1ImQ6ENjQYydksb+tHJDdG7spfWzGVhLeJamNywLky+6jEh9Gnfh+E+oaicYh1A7oZBlD5JBzQjva+dVoHeKpVVv0OVSoJGx/Tnit2r96CWu2vQ1N4A+fqDADO3h1w1cZTYy3utBgfH/4YzyaX+k0kDMTlrtMRutXMzVkbGBA7AAnVE4xON1lpT/0LCYD5M5fh59km703dc14eKiDxYeDcXqBuJ9vHpxCsCVeKcg5A3U30ETFIQEvtQ5NXA6aUPpR4+AcBAKZfv4EWYYZ3t70DCxGemIXiG+QStFP5FHhKJi8E9Kd/UOlN2ySN3mIypooydWGRd6WTVftRA7oEHDCcRs6cjjU74rl7nsOaHmsMF/gGGz7WP4CbOOOF+IYgMtAXibXL3lH+qPtHKL5seD8jE8kRyQYjBnsCaJpfTpMpAD3ragfnSL6Thx2nz2H+5auYpjdPfEGY+dFeP7j/A/x85pxlc/Z2fUH3/9wQ62qHSqsdYDrJKB1JFa8qWHPHD6Nu3jLsbuslGUx9VKxAXTZBFAmDgGmHgVZjMOFxb0wbq0bjhC5mE3AA+CAjE9+fOY/kUs3dV/dcjcTh7QCVwMZ7JDw2UQ3JQxu58DD8rhm8n+TxQPJ4PDtc2zR3TScVmoc1hydK5oKvkFIfw8lI4M8YCduaSahbUIhXUl4x2e9cpde/UwVg5tUbBsv1x7cQEEC/5SbDeLbnbKxrr0aBh/kLnNQmJbV4ajNzxRarUaUGVJIKwt/62sXG+QXY0fRJwxulxugPHGNmBGaLLt2qx2qnfzGm3r3a2hELB5sqG4AEPHUaePKEQZ9FjbHfcJVQbZPmJ45Z9xotRwEz0oGwCibxFirdHH1Fr/9Dr+huWNH7/wwXSBIQ3894zfDQdQhrZrobjYdk+Hus5ueJYcll5wA3xtoE3BYsSchtwZZNlg1uTHl4AU36ar97lgbiqPbTDnodx39rDFXmBo1KUqF9zfYI8Q0pf+W7ynxnYyyco8yM4ptiseEBiLG2+TW030lJklCvfkMAgMpDoHb38md4MMfc59olugtWdV+FyCqRZZbl1ypEll6jlOIuiVYZt93sYkmS0DC4ITwt7CJUHvM3m40sK7W+p1qFJ7s1RK1gX6wek6ytMe/zjnZ6PhfFmnCluHsBZ6xG6b7sHMy9fBWbjdRWGjS7teJOoi8Mm2++OXkg8OthwLcakJtufCMj+7dkYJIQ3xD0i+0HlaRC1YrWshiRFJ6EfZf2oV9QPIBvyiyP9G6Ca9hu+Q5LnWxNNrEvRZIkDGxoyUFC/6LDsLn0a7V6488qgWVGvNXvpOCl9tLF2KCgAMu7mU5sAMvu8hfPZd7/VjYWB2sT/6zuS1H2lFBCkiQYHLLbTgYufml0Xf1krdyviolalja5uWiXcwddo7sCh743uk5cRFWg9Bh0ARFA5mGjn0PZMdPKrtUqKhkI1N7I+nbML7iVf6ukb50ZngAi7zbRvir0R7tXIbBeKAIGXMS26CjkqgSirmtvmki+ZgZMuftduVlFwk/NJCToJfc/JkgYuc3Uhlof3afCiB+NHxsu6d3rEZKEV4Zok8pJ/2ovkkz1O68bWBftarRDsAaQ/j1T5tPzEUDB3W2FEECzh+BZ6wMUnD1bZl8tmgzCY5pbePtA2RrU6KrROJ11Go+3eBwjGyeixSfa5/09Lb/AEoE1gdv/lr/i+B3AnRsAJODMb1BZcuL3rgLc8xhQlA9UKflulL7AtK4CxcQvt7IXIr5Blr6S6SbNCpDvCaBkwgLUCayDeZ0WmlzfqAb3IyTuNjL/ND7wj3+VIIPHeUXGx49QClPnYVsn581DOuD3rDXQ5Jmej9whbFRrauGLOfC1Kqa8PuEW7cOwPXrld2iNLi8ASaPKXc2UhR0XYvG+xVjUyXwXF0uFth6EnOtH4BmTDE+Zbo+0zb2D+a1UGPI/7Xdd1yXRmH4fAHsXACg5TuU2GQJfa6e7tKOSoTL1nzT8bA//JxWealVJC1g3wJpwpah3n7bJRUDZ2usG+QXwAFA/x7Dp28RqiYbNwMs5MVXT67vpUyrNigz0Bbq/qp3OxqSyB2ZLm4K/2PZFzGkzx6J1LbXi/hXYPnA7mviWXPx66w1EtvbhkeZ3EFA61TR8Lw2DG+LDbh/i7c4lycFTV6+jwvQPOC1GGDxOvW8unmr9lEHSCgAFwrC/d2XpmuGaofEJLncdA/e/bHKR/sWhUJXtzzRUo2158HiLxw0Hj9LTKTsXI7Numb3h0y3eyG2D3kuBuvcaPYWaO632vXUbK+5fgXsiS0ZR9vf0R4S/6f6UpjxVOA67ihpjVP7dliFCQKUCNp+9gJ9Pn4PnPY+VG0+x5bdVaJuTi/mXr1oVg7HxJD7sooKQJOR6Sxg3WY1RU03Mp24ksFrLX4QkSXivy3uYGz8BAKA2cmwoTgCS746eHf3fDw2mKdFfz1RtwRcPfIE1PdbgkfhH4KlW4dnkZzG00dAyrXXMsfhyMjJBO6tBnfba/q4WDOAFAEidC/Q0nwRalQw5cIQk2QdjAoBOTwOhjbStTup1NtpXXPItuVv0el8VrgYAbzxgn8uXjfdIUPn4AFGJGHh3bArd6OMKYskN8Eo3Py9lYts2aOe1FM8nlp2Nw57GpNQp9YywedNgwHEtCmxNU5luAkqQMs3oTUJLdYvphi39t1SuObw+lQp+3V+EZ1wPu3zPLKHReKPVHQv7QicM1Lb60ePrbZvabWuY+/14VjGen+h/cz0taOHmalgTrhRqD2DEl/D+fhxwcZfBouIvadPbvjjuV9Lc+NHgUheiZppDAsCmcxfwUkgwvGsl4/RlHwBlB57Svp6JA/rdJF8pJyq1Sl2m+dOKK7fxcqAPZl67jsigcqY9mbIfyLkGrB4AZB4G4geUWaVlREucvFEyorJXtboALEvEy14k6T32ND+NRbGq+YNw8WYVFGYVDypi+cm2eM350Q/iF7UGo5uONtn3J7/FWODqZitfwTqFfqFA8gRg93u652ZpAjCs/6eoFVALV7DEYP15mVew08/3bt/qu1RWzBsZVAsYsRGFa5qg9Lj5ZWpuPVXA3cHMQwuL0DqyteWvY8Y5EYohBfr9ve7OZgAAad9oR1kHLMrCk6PvQ/LvKw1Gt67oT3Fzq5KT3Y0qpndirIZF3SK15MHdGtNG+QXoGt0VW09v1W4HYPug7bhw+4KuRYlnjRo42yoP0b8Z1vqrJJXJL52X2stg4MFBjQaZe1tGPdnqSfx15S+MbFLOTTkbKtsn3JqtnfyC2lqdntL+AcDwL0ysVPIBZoYDEydpz3UfXrxkszBOhgM7m6iwqbWE2QAw5kc8W5iH8YWWtYBxB14eKrw35F6Hv+6s7o3QMyESKM79g6Jdrjl6pdjgksxw5hVlXOMpgv751oFelUahDT6rxB4cX4YLOy7Eo9sexdQWU8ssq9kpDxm/qVC9sfG8w125320HhXvunudQJ7AO/hNcMrJr8Skg8E7pwUhKnRxajAAimgIdZhrdtySA1y5fxcu1ekFVkbt7TnAyalaowboLGSannzLg6attbpz2DTB4DdDR+Oemfyxr3e8jg1o4q25IlO4T3vluy4A2pmtZVMIH+Ve6QJMfVrKdlXpWi8fc9nNRL6ieYXLQ4u7geR2exJ32Txnf2IYkSNrWFi/c1HsOqF21NiRJgtrL8HDUKzsH829rDCfPS5kOVK1h8jtu4oXLKF3DGxFcMjqpLZr2WSQmRTdKqAQJ6xJLuoj8WVcbxBX9cVm6vgR0mwdMqGC/YCtJklR+9uhTFZieDmnmvwZNASOKNAj2CTbbpUMjAXsaaPvgNahmoi+0DdQJrIOfB/1cMo2TA5Rpjm7Nxso/zDqcpNdCSL/VRUtLjvMW+raVCpuSVSXfeZUKkpevYhPwitwMt3gQU4XxUKu046SkfaudZs2hAzUp/zOzxSkrvob+CN3Kf88OUy1a+53rv8KhL5srGVYijTQzFSyAsi31JMend02qN8H2gdvRN7ZvmWVeVQVqd7wGv9BS4xaVU3no6piEK0ytqrXwVZ+v0LdKSY2lkIB8oUbtDnMNmluXSci8qwATdgL3aeer/fIx09MOmLu2Lt0kuuT1tK/t61lycFBLVtRM2osFFxaN88xcrPkFA416WjR/rafaE6u6r7IorHpBpQbyMfhchXZ6l2czgW6vmNyHTU6FNVsZf77nYm0/2E5PG76mnc6/NaoaG3Sn5IsYNGEm/CPuILxFSZKO+18GhqwFRv+gfRwQDkw7pPuOV5QGEnDfs0hVBSEAKvRoWzIfZp7KNiPvIrwpWsVom9Hqph4y8eFKEnCoRkk/53d7qLC6kwrPDdf7fXlXAdo8an4UbFvxDtT1u573kAqfttfr21/6kq9qlPY3BOCj2DS0v1OAJW1NdFHQe/sPP6HGwn7a/d5X+z4838bEHNc2YPKYZidWj45ugBfAZeh9fn3vaM9DCTZMwAFgRzxr/xypdUQFWhvFtNNOw2frJsLmjg/FA4bZcDwbW7NkkFSrRJofnNXttB5rOM2jFSraJUQq9Z2cYWYqWEA7I8yABgPwVvGUtx5mxpmxI5PnOlM/WZma+yuFe9+CUDTDL+ZD+XMwMiAMbXPv4Cf/4qbM5n/czQyaF92t4bu7ScPwAGw/etnods/d8xzGfD8G4xLGlVqi3bi6b3U8m/wsvNReNhtV0WZMnIw8wiwbZK08KivuWz0S/wgKigrQsVbHu88YGR291ABtpVXm3CqGfgb4RgIhJkb1VXto+8GidCW9BS+aPBHY/a5FcaTVfQVXcm6gZU0jTeH1mperkoag9sjVwOmd2icm/AKENyl7kDZ60LbuQK4BgA5PYoF4AkWiCB56d2OLLBwVv1zVorGsd0tsOngBvZsVTyVmIgkHUJgXAeAIACDbV8KXbcp/T9UsmKP7SiBwKgyIMTIdfeuI1tiTscfIVgIBXgF457638Cgm4UKwwKAdxUtMfz8S287AO22mW3RiXXMpA38VakealyQJDzV4CP/Z9Z9yt3MGlRqYzUlrK+2r5AOcXOiLZpcuWt5f0kJdIsZi66XlmJAwwab7tRfrbuwoxw8DfsDJmycNxtxwtLp+rSE8L6N5QFttAu5nZhwU3yDg6QuyJTWWUEkC5Z8JLPDYHm3XvHr32WJvVAllOjO2f8Ls+t5qb+24S0WBwIE1QAfz6ztc9wXAhvFAu8fljkRRmIQ7AZPDrVnZJEv/0u7xLrF4/38nja5XL6gefnzox5KTfJVw4PYlgykkKtI3024MLlpNXMB6ltM/3Az9C2prari81d6Y0mKK/sp6Sy270C6T8FgxKqzwCQTCGlm0rmHSYEFsZj7P2gG1cebWGd3jGe0fML0f/T7ekgTU7ViShEfY5saJsXdT3BxdkiR4SIaHwezaNroAkSRU8/fC8DYxesGY/mwLcxoAd0fzl4QPhFR+kvHW1cs4EB2G+NOm9yskCU89osYb7xUh4obhshXdVuDzfz7HC7teAADMzbyCBvkFgEpbvu1rdtDGU24keswlB3qL4vILcLlIAS1pFIdJeBn6U0cWFaBzTq6ZlStmUerjyMofhapexkdMJ9sI9w9HuH+4DfZU8d9Jn8hnMLJdjOUtZLysn+7KIYLrAddO2K73b2hD7R/JTio91WGdDpZtmDJV+6c0zQYD9bsC/pZPY+cO2BxdqRKH6Zqet8u9ozvIGpx2aiRZudOSH7WflwdiQkwPDmaQXI75Aej8PPDAUrN7L25O+kRLR9+BK/9kbKtRYkuftK3rl1eRPnxWb1IhBim4Ja9pJtGqG6St8bboAic6xfBxRd9wXC/tvwFR5tcrfhkzy0JrlB6J1/5UKgkavcNxyK2JCPEJwWsdXjO7XWxhAf4zRGUwn6gxQpLwyX3a/W9OMiy77nW66/7f8k4eGhYUlCyUJLyaWXrut4q7WVNbX5N/N/cWpX4TXzxgamAu59CgWgMEeAYgLsSw6apVY3CwJrwMqWbLkgf6szE8/LlN9v/iUO1vw5kScKUMkOqM1GqVw7uolCc0wHyrOKPG/w8YvwMaJ2wV4awtORxl8AOlKi9coe80E/AyXKBUXVRQbWwd8D3OvdkcTfPzIdkgiazwHoJqA+1nlLvaQw0eQreYbo6/kLHznKH6FzuVSsL1t63ohba57e57Fji4DsWT6Fpz48HXq6RGMti/7FRi1vDz8MPOwTvhaa5Z9+Q/gOM/AElppRZU8HMJbwJM/QvwN9/vvJjGIRewxl7DdHN0oXdR4lVYH1sG/mTZhYqFFzN7Gqow+nEJt0ol7PrfE2N76pGdg8bqfOyvEYY7XhLqeFX8+3EnWIOp49S44Q/svlh2eWy1WHSP6Y7NpzZX+DXktK73OhRpisp007Hu28YkvAz9bjtN+gAxJ7RTGlbyQn7MFDXCrwPHajIhcCdKLO2RbWPwz6Xb6BJnxUCA3lWAyAR371arbBU8nCcmJODAQ0NQZ88XOFwLiKvdxrZxkSIo61YgGagWUANN87UjCRYn4ZU51uqOBXeP2Pa41JOlJkE/MbVzLVKlah8q0hzdmrfT4UlgUkn/3uKBtSyh1mv65KG25D2amdZKCAR6B8LP3DRsIfWA5PFl+8RXpvyCahtvJm/kKCcCa1T8dSojYbD237Cy85lq9G7SaISwuKbguSvX8E+Nu+uqzd+QuuVXdsRzgzEAiudqjzFsoSBJwPPD1Zg7qHI1SALAhRAJOT5mvj9OnISqJJXRcTLYJ7xyyvwW/KvbZECfLH8Jx2pKaGrjQd5I2dQq5V36+niq8frAZujeNFLuUBxidPxoAMD90ffLHIl9FbcMrIiC6GiMmK7Gi8PUgAK/szbh5qc71oQ7mcp8X31KXdy1ignG6as58PZw9h93+X3CKzM1i35SUCYBsa6zrH5AFm0xM7Uh0j7ci5FtonXRlOfp5KdxMfsiGgVb1h9cG5mVF7RmLoA1pkcxKF8VYzXZlaMu3bcKcEzzPWOvUasV8PhBICCi1KqSQUzWfFsDNBos6alCrz0azKh2GSe/ta6/pVqvX77vwxuAI98CrfSm8xq1GUHZl4C92u4mtmzGWbo5uvY51zsrt4zWDvwUFWjJ4E6u9/4ry95Nr92lItGlfltq65tvP9KuDnYev4w+iZZ1W3IaTvgFTq2TioTQhLJTa7mYBtUa4J3O71R4HIQ73k5YuGQxJuEu7qV2L2HOL3Ow6NIl+JZK/Ob0bow61f3R09nvvFqQ0Fbm4kM/ga9cc3TrD6adGobhzzn3o6rP3Z9qs8HA7veAiAST2wxpNMTq17ElTWW6BySOAC4csOnorHlV/QHcNHhOozEdo+0uVE2Ud7XoMk9JEnBGLzHXWHnT6JafhP/rpMbT/1o/Rq6vhy9eaPMCikQRAsPjgfBSA+JFt0UggI+qx8BT5Wkwkry13PVyItDPE3+9cD+8PSwYiK7Pu8D6UUCXF+0fmDt74C3grwVyR1Fhbt+n9oGlwOqHtC3ALPR877ItkFyCk34Voqq42M0QE9rXbF/+SuSWmIQ7CQkCKfWrY/tv1m3Xp34f9AltBSzWP/loj9gBPp547N76tgtSNuUnLGXm7LaCflJpsz7hViR6gb56zVujEoHp6Sb6PjuS+eboFebhBTz4VsW3N2LXgKYovPILtjUviblStfWWsvIiOcfTB4O6v4gClRoRVnyEybnaUdRr+IUDOIPnhqvx0semk/Gk8CRk5mQatJTo36B/ua+TGJZoeVCVUKnvj4IF+Fg49V18P6BBN4eMyOzrqUZugU0mN3I+wY4fgJFsKLQhMPWg3FEog5Mm4WQeB190fUzCncTKKQ8isKoPRHQ74Mp+6zZ29TvmZvqE/1/P/8OXx7/EpMRJFd+9meboVtVGGE7GXeF4UNW+d48tqgk287691JUb2M3Wcqt646WhhjWQ0VXL1kbbnuXfjeI1s7y1iZc1iWiwRoNfT52Fz4xtwKFYHC1nkKlQ31Cs7LZSESf4WsFmxg1wZw6aEunT8ffgpU2HMbtHXPkruxqp5Jgg/y/Beo2DGyPUN9Sq5ry1A2rbMSLnp4RjIhG5DybhSjdmG5BzDYGRd2tyfQPljUeJmvQBtj6nrSXOPGKwKL56POKrV26+af2acNudpJVV22f9+zJc/+s+X2Pm/2Yivygf05Om2y4wGzD23mKqxjg+EDNK38zRWPn1COi3HKhielTduOA4pF9Lv7tvjWKm56kXWqX8lchuEmoGYd2EtnKHUa7GIZVsRlytDnD9X0B/xgYnvzntqfbE9wO+t+q3HBcShwUdFiDS38m7oJEBhRzOichK/OkqXc2WQAPXHj2y0oJqA0+d1t6wsHNyW7l5wvVUlWl0bjuJCYzBZ70/w8Y+Gys8AIm96NcUdandBQAwLG6YyfUr3Rw66G5tU5O+Fm9Sq5rhqO7W9glH0wEGD1d11n5PP+yi/TetSZpumaIGZzKSCCkqPpLV+t7rMav1LPSPLb+7hFkPfw406QeM217ynP6x3EmbpnuoPKy+oda9Tnc0D2tun4BIFlH3qaD2LkJEyxtyh0JkFXc/37Mm3C2UutB18hoAo3yD7LZrc33CrTb5D6DwDuAXXMmoZOZE36HJLSYjKz8Lvev1RruodsgpzLFq+jarTdgJXDkG1EiyeJOQKt74ZkoKei7dCaDys1R901qF7U0lZPsaGRm+MgPnVVKZt9VpVpl1Woa3xNbTWx0SDylbw+CGaBjcsPI7CqkHPPSh4XP6x3IPS0atd0LufX1rtdaRrfHrhV8R7qesG8nl8Q9VIbbPBWc6LRMRmIQ7ndigWGw/u13uMJTLDoM66Q/iVbrZsNUj1IZUfIA4ZXGes31Vr6p4tcOrusd2TcABwCdQ24LFSk2iSrqa2GJwMv0EXP97qpiBz56+CHiV7RM+sOFA+Hv6o0V4CxmCIrehdyOUfYEJAOa1n4dPj3yKB+s/KHco1pEkJuAuyB1Gj3f3Yy+TcCczNmEsAODeWvfKHIkb0ctZVC7ag8Ptp7vRo4TmUdb2CS+P/kB0DhkZ3gSDb5mRBBzQNrF1uotgcj7BdeWOwP54WLdKsE8wJjafKHcY1uP52yV1r9MdJ2+edNjMJHJQwvWWnJiEOxlfD19MaTFF7jAUzA414bZsjq5Q+ncj1ZIFcxnzpG9XtjwxvdbxNYOBrRRTE06kGC76m3DRt0Wl8XzsilSSCpMTJ8sdBtkRk3ByLY5uju4iJz8/Tz8Mbzwc+UX5CPWzZA5y13jfSmXLmvDUmNRS+5avJjzpTp5sr01kSufqzeUOgajiXLRygMjVMQknKoe5mkNXasY9s9VMy1d2nbetSPasrZazOXp8fj5WX8hARFSybDEQFZubeQW/+PliZC3OQEJOzIWuQ4jcCZNwonKYqzl0lZpwKqGEPkr2bDEud3P0hLx8QOKph+TXOzsHvbNzmMSQk+P3l8gZsQ2LOyhzgeHKB2zbJxhKSMqUx5W/Q/Kzep5wK8idhBMRkQ3xJhKRU2IS7g48vOWOwHHskGB4qbxMLnPbmnAXPulX864mdwgV7xPuV738fcvYHJ2IiGyMfcLJSbl7JRd/ue7Atxpw/ytyR+G04qvHo3fd3pjYzMjUJa6bi7qd+e3no1tMNwxpNETuUCpeW532jclF1X21Cboipjd04Zs4RESOxeMpkTNixzx30XYS8P0z2v/zAtgqkiRhbvu5xpe57cnP9d53z7o90bNuT7nDAFCJBh1hjUwuWt97Pf68/Cc61uxYwZ0TEZHi3DMR2DQVqN9F7kiIyApMwsnFOLZpiyuNjm4Vd33fdhbs74Vr2floVSe4/JWbDgT++szifYf4huC+2vdVIjoiF+UdIHcERBWXlAbUbAVUbyB3JERkBSbhRFQBTMLtYeOj7bD+j3NIaxsjdyhErq/XYuDmeSCiqdyREFWcJAER8XJHQWS1YXHD8PHhj5XRTU4GTMKJiBSidogfpnd14dqMmPbAqR1Ay9FyR0IEtHxE7giIiNzWtKRp6FSzExJCE+QORRYcmM0tuXAtpoOnX3LbPuFsjq5YH3f/WO4QTBu+AZj8BxDXS+5IiIiISEaeKk+0jmwNHw8fuUORBZNwcjFMwh3DXd+38jUPa45nkp+ROwzj1J5ASD25oyAiIiKSFZNwIiKnZPqGk/veHCKiQQ0HAQAeT3pc5kiIiMgU9gknqgSOjk5EREryTPIzGJcwDmF+YXKHQkREJrAmnIgqgEm4krntzSEigiRJTMCJiBSOSbg74gW6zbhts9/mQwGfICBhsNyRuC8HD0JIRERERLZh1yT82rVrGDZsGKpWrYqgoCCMHj0at2/fNrv+5MmT0bBhQ/j6+qJ27dqYMmUKbt68ac8w3UeVCO2/MSnyxuFC3LbG0S8YmHkS6Pe+3JGQEW77vSQiIiJyAnbtEz5s2DBcvHgRW7duRUFBAUaNGoVx48ZhzZo1Rte/cOECLly4gIULF6Jx48Y4ffo0JkyYgAsXLmD9+vX2DNU9TD0I5GdrEyiiylKp5Y6AiIiIiMjp2C0JT09Px5YtW7B37160bNkSAPDmm2+iR48eWLhwIaKiospsEx8fj88//1z3uF69enjllVfw8MMPo7CwEB4eHEeuUjy8tX9kM27bHJ2IiIiIiCrEbs3Rd+3ahaCgIF0CDgBdunSBSqXC7t27Ld7PzZs3UbVqVSbgpEhMwkmJ+L0kIiIiUi67ZbYZGRkICzMcndPDwwPBwcHIyMiwaB9XrlzBSy+9hHHjxplcJy8vD3l5ebrHWVlZFQuYqCKY65ACMQknIiIiUi6ra8JnzZoFSZLM/h05cqTSgWVlZaFnz55o3LgxXnjhBZPrzZs3D4GBgbq/WrVqVfq1iYiUz/To6CG+IQ6Mg4iIiIisYXVN+IwZM5CWlmZ2nbp16yIiIgKZmZkGzxcWFuLatWuIiIgwu/2tW7eQmpqKgIAAbNiwAZ6enibXnT17NqZPn657nJWVxUSciNxax5odkdYkDU1CmsgdChERERGVYnUSHhoaitDQ0HLXa9OmDW7cuIF9+/YhKSkJAPDjjz9Co9EgOTnZ5HZZWVno1q0bvL298dVXX8HHx8fs63h7e8Pbm4ONkTzY7JdkY2aecEmSMKPlDAcGQ0RERESWstvAbHFxcUhNTcXYsWOxZ88e/PLLL5g0aRIGDx6sGxn9/PnzaNSoEfbs2QNAm4Dff//9yM7OxooVK5CVlYWMjAxkZGSgqKjIXqESVRjnYyYiIiIiImvYdcjx1atXY9KkSejcuTNUKhX69++PpUuX6pYXFBTg6NGjyMnJAQD88ccfupHT69evb7Cvf//9FzExMfYMl8hizUOb48DlA+hbv6/coRARERERkROxaxIeHByMNWvWmFweExMDodekslOnTgaPiZTqva7v4UDmASRHmu5aQUREREREVBon3yaqAH9Pf7Sr0U7uMIiIiIiIyMnYrU84ERERERERERliEk5E5JTYdYeIiIjIGTEJJyIiIiIiInIQJuFEREREREREDsIknIjIGXEmCSIiIiKnxCSciIiIiIiIyEGYhBMRERERERE5CJNwIiIiIiIiIgdhEk5ERERERETkIEzCiYicEgdmIyIiInJGTMKJiIiIiIiIHIRJOBEREREREZGDMAknInJGnCeciIiIyCkxCSfXMvQzwNMfGPiR3JEQERERERGV4SF3AEQ21aAbMPscoOL9JSIiIiIiUh5mKuR6mIATEREREZFCMVshIiIiIiIichC3bY5eVFSEgoICucNQBE9PT6jVarnDICKrcGA2IiIiImfkdkm4EAIZGRm4ceOG3KEoSlBQECIiIiBJktyhEBERERERuSy3S8KLE/CwsDD4+fm5fdIphEBOTg4yMzMBAJGRkTJHRERERERE5LrcKgkvKirSJeAhISFyh6MYvr6+AIDMzEyEhYWxaTqRM+A84UREREROya0GZivuA+7n5ydzJMpT/JmwnzwREREREZH9uFUSXszdm6Abw8+EiIiIiIjI/twyCSciIiIiIiKSA5NwIiIiIiIiIgdhEk5ERERERETkIEzCiYiIiIiIiByESbiT6NSpEyZPnoypU6eiWrVqCA8PxwcffIDs7GyMGjUKAQEBqF+/PjZv3gwAuH79OoYNG4bQ0FD4+voiNjYWH374oczvgoiIiIiIyL251TzhxgghkFtQJMtr+3qqrRqVfNWqVZg5cyb27NmDTz/9FBMnTsSGDRvQt29fPP3001i8eDGGDx+OM2fO4LnnnsPhw4exefNmVK9eHcePH0dubq4d3w0RORTnCSciIiJySm6fhOcWFKHx89/J8tqH/9MNfl6WF0GzZs3w7LPPAgBmz56N+fPno3r16hg7diwA4Pnnn8e7776LgwcP4syZM0hMTETLli0BADExMTaPn4iIiIiIiKzD5uhOJCEhQfd/tVqNkJAQNG3aVPdceHg4ACAzMxMTJ07E2rVr0bx5c8ycORO//vqrw+MlIiIiIiIiQ25fE+7rqcbh/3ST7bWt4enpafBYkiSD54qbtms0GnTv3h2nT5/Gt99+i61bt6Jz58547LHHsHDhwsoHTkQKwOboRERERM7I7ZNwSZKsahLuTEJDQzFy5EiMHDkS7du3x5NPPskknIiIiIiISEaumX0Snn/+eSQlJaFJkybIy8vDpk2bEBcXJ3dYRGQzlg/qSERERETKwSTcRXl5eWH27Nk4deoUfH190b59e6xdu1busIjIZtgcnYiIiMgZMQl3Etu3by/z3KlTp8o8J+5OW9SnTx/dSOpERERERESkDBwdnYiIiIiIiMhBmIQTETkjweboRERERM6ISTgRERERERGRgzAJJyJySqwJJyIiInJGTMKJiIiIiIiIHIRJOBGRU+I84URERETOiEk4EZFTYnN0IiIiImfEJJyIiIiIiIjIQZiEExERERERETkIk3AiImfEecKJiIiInBKTcCIiIiIiIiIHYRJORERERERE5CB2TcKvXbuGYcOGoWrVqggKCsLo0aNx+/Zti7YVQqB79+6QJAkbN260Z5hOY8uWLUhJSUFQUBBCQkLQq1cvnDhxAgBw6tQpSJKEtWvXom3btvDx8UF8fDx+/vlnmaMmIvtgc3QiIiIiZ2TXJHzYsGE4dOgQtm7dik2bNuF///sfxo0bZ9G2S5YsgSQ5YB5cIYD8bHn+rOzTmZ2djenTp+P333/Htm3boFKp0LdvX2g0Gt06Tz75JGbMmIH9+/ejTZs26N27N65evWrrT42IiIiIiIgqwMNeO05PT8eWLVuwd+9etGzZEgDw5ptvokePHli4cCGioqJMbnvgwAG8/vrr+P333xEZGWmvELUKcoC5pmOxq6cvAF7+Fq/ev39/g8crV65EaGgoDh8+jCpVqgAAJk2apFvv3XffxZYtW7BixQrMnDnTdnETERERERFRhditJnzXrl0ICgrSJeAA0KVLF6hUKuzevdvkdjk5ORg6dCjefvttRERE2Cs8p3Ts2DEMGTIEdevWRdWqVRETEwMAOHPmjG6dNm3a6P7v4eGBli1bIj093dGhEhERERERkRF2qwnPyMhAWFiY4Yt5eCA4OBgZGRkmt5s2bRratm2LBx980KLXycvLQ15enu5xVlaWdYF6+mlrpOXg6WfV6r1790Z0dDQ++OADREVFQaPRID4+Hvn5+XYKkIiIiIiIiGzJ6prwWbNmQZIks39HjhypUDBfffUVfvzxRyxZssTibebNm4fAwEDdX61atax7UUnSNgmX48+KPu9Xr17F0aNH8eyzz6Jz586Ii4vD9evXy6z322+/6f5fWFiIffv2IS4uzrrPhIiUj/OEExERETklq2vCZ8yYgbS0NLPr1K1bFxEREcjMzDR4vrCwENeuXTPZzPzHH3/EiRMnEBQUZPB8//790b59e2zfvr3MNrNnz8b06dN1j7OysqxPxJ1AtWrVEBISgmXLliEyMhJnzpzBrFmzyqz39ttvIzY2FnFxcVi8eDGuX7+ORx55RIaIiYiIiIiIqDSrk/DQ0FCEhoaWu16bNm1w48YN7Nu3D0lJSQC0SbZGo0FycrLRbWbNmoUxY8YYPNe0aVMsXrwYvXv3NrqNt7c3vL29rXwXzkelUmHt2rWYMmUK4uPj0bBhQyxduhSdOnUyWG/+/PmYP38+Dhw4gPr16+Orr75C9erV5QmaiIiIiIiIDNitT3hcXBxSU1MxduxYvPfeeygoKMCkSZMwePBg3cjo58+fR+fOnfHRRx+hdevWiIiIMFpLXrt2bdSpU8deoTqNLl264PDhwwbPibtNUk+dOgVA+7mbG/iOiFwFm6MTEREROSO7zhO+evVqNGrUCJ07d0aPHj2QkpKCZcuW6ZYXFBTg6NGjyMnJsWcYRERERERERIpgt5pwAAgODsaaNWtMLo+JidHV5JpS3nIiIvdk+cCORERERKQcdk3CyXEsuaFBRK6Ev3ciIiIiZ2TX5uhEREREREREVIJJOBGRM2LLFyIiIiKnxCSciIiIiIiIyEGYhBMRERERERE5CJNwIiKnxOboRERERM6ISTgRERERERGRgzAJJyIiIiIiInIQJuFEREREREREDsIknIiIiIiIiMhBmIQ7CY1GgwULFqB+/frw9vZG7dq18corryA/Px+TJk1CZGQkfHx8EB0djXnz5skdLhERERERERnhIXcAchNCILcwV5bX9vXwhSRJFq07e/ZsfPDBB1i8eDFSUlJw8eJFHDlyBEuXLsVXX32Fzz77DLVr18bZs2dx9uxZO0dORLITHB2diIiIyBm5fRKeW5iL5DXJsrz27qG74efpV+56t27dwhtvvIG33noLI0eOBADUq1cPKSkpmDJlCmJjY5GSkgJJkhAdHW3vsImIiIiIiKiC2BzdCaSnpyMvLw+dO3cusywtLQ0HDhxAw4YNMWXKFHz//fcyREhEjseacCIiIiJn5PY14b4evtg9dLdsr23Rer6m12vRogX+/fdfbN68GT/88AMGDhyILl26YP369bYKk4iIiIiIiGzE7ZNwSZIsahIup9jYWPj6+mLbtm0YM2ZMmeVVq1bFoEGDMGjQIAwYMACpqam4du0agoODZYiWiIiIiIiITHH7JNwZ+Pj44KmnnsLMmTPh5eWFdu3a4fLlyzh06BBu3ryJyMhIJCYmQqVSYd26dYiIiEBQUJDcYRMREREREVEpTMKdxHPPPQcPDw88//zzuHDhAiIjIzFhwgRUr14dCxYswLFjx6BWq9GqVSt8++23UKnY3Z+IiIiIiEhpmIQ7CZVKhWeeeQbPPPNMmWVjx46VISIiIiIiIiKyFqtLiYicEecJJyIiInJKTMKJiIiIiIiIHIRJOBEREREREZGDMAknInJKbI5ORERE5IyYhBMRERERERE5CJNwIiIiIiIiIgdhEk5ERERERETkIEzCiYiIiIiIiByESbgLkyQJGzdulDsMIrIHzhNORERE5JSYhBMRERERERE5CJNwIiIiIiIiIgdhEu4kOnXqhClTpmDmzJkIDg5GREQEXnjhBd3yY8eOoUOHDvDx8UHjxo2xdetW+YIlIiIiIiIiozzkDkBuQgiI3FxZXlvy9YUkSRavv2rVKkyfPh27d+/Grl27kJaWhnbt2qFz587o168fwsPDsXv3bty8eRNTp061X+BERERERERUIUzCc3NxtEWSLK/d8I99kPz8LF4/ISEBc+bMAQDExsbirbfewrZt2yCEwJEjR/Ddd98hKioKADB37lx0797dLnETERERERFRxbA5uhNJSEgweBwZGYnMzEykp6ejVq1augQcANq0aePo8IiIiIiIiKgcbl8TLvn6ouEf+2R7bWt4enoabi9J0Gg0tgyJiIiIiIiI7IhJuCRZ1SRcieLi4nD27FlcvHgRkZGRAIDffvtN5qiIyK44TzgRERGRU2JzdBfQpUsXNGjQACNHjsSff/6JHTt24JlnnpE7LCIiIiIiIiqFSbgLUKlU2LBhA3Jzc9G6dWuMGTMGr7zyitxhERERERERUSlu3xzdWWzfvr3Mcxs3btT9v0GDBtixY4fBcsHmqkQujL9vIiIiImfEmnAiIiIiIiIiB2ESTkREREREROQgTMKJiJxRTIrcERARERFRBbBPOBGRM2o/A/APBep3kTsSIiIiIrICk3AiImfk4Q20Hit3FERERERkJbdsjs5Rw8viZ0JERERERGR/bpWEe3p6AgBycnJkjkR5ij+T4s+IiIiIiIiIbM+tmqOr1WoEBQUhMzMTAODn5wdJkmSOSl5CCOTk5CAzMxNBQUFQq9Vyh0REREREROSy3CoJB4CIiAgA0CXipBUUFKT7bIiIiIiIiMg+3C4JlyQJkZGRCAsLQ0FBgdzhKIKnpydrwImIiIiIiBzAbkn4tWvXMHnyZHz99ddQqVTo378/3njjDVSpUsXsdrt27cIzzzyD3bt3Q61Wo3nz5vjuu+/g6+tr0/jUajUTTyIiIiIiInIouw3MNmzYMBw6dAhbt27Fpk2b8L///Q/jxo0zu82uXbuQmpqK+++/H3v27MHevXsxadIkqFRuNX4cERERERERuShJ2GFuqvT0dDRu3Bh79+5Fy5YtAQBbtmxBjx49cO7cOURFRRnd7p577kHXrl3x0ksvVfi1s7KyEBgYiJs3b6Jq1aoV3g8RERERERGRJazJQ+1Sxbxr1y4EBQXpEnAA6NKlC1QqFXbv3m10m8zMTOzevRthYWFo27YtwsPD0bFjR+zcudMeIRIRERERERE5nF36hGdkZCAsLMzwhTw8EBwcjIyMDKPbnDx5EgDwwgsvYOHChWjevDk++ugjdO7cGX///TdiY2ONbpeXl4e8vDzd45s3bwLQ3okgIiIiIiIisrfi/NOShuZWJeGzZs3Cq6++anad9PR0a3apo9FoAADjx4/HqFGjAACJiYnYtm0bVq5ciXnz5hndbt68eXjxxRfLPF+rVq0KxUFERERERERUEbdu3UJgYKDZdaxKwmfMmIG0tDSz69StWxcRERFl5uEuLCzEtWvXTM5FHRkZCQBo3LixwfNxcXE4c+aMydebPXs2pk+frnus0Whw7do1hISEQJIks7FSxWRlZaFWrVo4e/Ys+90rDMtG2Vg+ysbyUTaWj7KxfJSN5aNsLB9ls7R8hBC4deuWyfHP9FmVhIeGhiI0NLTc9dq0aYMbN25g3759SEpKAgD8+OOP0Gg0SE5ONrpNTEwMoqKicPToUYPn//nnH3Tv3t3ka3l7e8Pb29vguaCgoHJjpMqrWrUqDxQKxbJRNpaPsrF8lI3lo2wsH2Vj+Sgby0fZLCmf8mrAi9llYLa4uDikpqZi7Nix2LNnD3755RdMmjQJgwcP1t0ZOH/+PBo1aoQ9e/YAACRJwpNPPomlS5di/fr1OH78OJ577jkcOXIEo0ePtkeYRERERERERA5ll4HZAGD16tWYNGkSOnfuDJVKhf79+2Pp0qW65QUFBTh69ChycnJ0z02dOhV37tzBtGnTcO3aNTRr1gxbt25FvXr17BUmERERERERkcPYLQkPDg7GmjVrTC6PiYkxOnLcrFmzMGvWLHuFRTbg7e2NOXPmlOkGQPJj2Sgby0fZWD7KxvJRNpaPsrF8lI3lo2z2KB9JWDKGOhERERERERFVml36hBMRERERERFRWUzCiYiIiIiIiByESTgRERERERGRgzAJJyIiIiIiInIQJuFEREREREREDsIknMiJnDt3DhcvXgQAo1P8kbxyc3PlDoFMOH36NM6dOwcAKCoqkjkaKu3y5cu4ceMGNBoNAOj+JWW4c+eO3CGQGceOHcPChQtx9OhRuUMhI3htoGxyXR8wCScAQEFBAT788ENs2LABR44ckTscKqWgoADjxo1DcnIyVq1aBQCQJEnmqKhYQUEBJk6ciH79+mHEiBH47bffeJNEQb788kvUqVMHkyZNAgCo1WqZI6JiBQUFmDBhAjp06IAePXrgkUceQVFREVQqXp4oQX5+PqZNm4Zhw4ZhxIgR2LFjh9whkZ6ioiI89thjaNq0KdLT03H58mW5QyI9vDZQPjmvD3iWI7z//vsIDw/HypUrMXXqVPTr1w+fffYZANZGKMHZs2fRrl07/P3331i3bh2GDh0KIQQP5AqRkZGB5ORkHDx4EL1798bBgwcxYcIEvPbaawD4G1KCPXv2IDk5GWfPnsXnn38OgLXhSnD8+HG0atUKR48exTvvvIMePXpg165dut8OyWvjxo2oX78+Dhw4gE6dOuHAgQOYPXu27jdE8lu0aBH+/PNP/Pzzz1ixYgVSUlIAsKWcEvDawDnIeX3AJNyNFRYWYsmSJXj77bfx1ltvYceOHfj666/RpUsXLFiwABqNhrURCvD9998jMDAQv/76K9q2bQuVSoXCwkLWhCvEL7/8gvz8fHz22Wd49NFH8fPPP6Nv376YM2cODh06BJVKxQsimRRf5Ny8eROtWrVCYmIi3njjDRQUFECtVrNcZLZ582ZUqVIFX3/9Ne69917MnDkT0dHRCAwMlDs0t3fixAl88skneOSRR/DTTz9h8uTJ2LZtG7y8vHDs2DG5w3N7QghkZ2djw4YNSEtLQ3JyMnbt2oVly5Zh586dyM7OljtEt8drA2VTwvUBMyw3JYRAQUEBbt++jQEDBmDw4MEAgISEBDRp0gRqtZrNmmSkX9P9+++/o1mzZrh+/ToGDhyIrl27onXr1hg3bhwyMjJkjtR9FR/AL1++jOvXr6NGjRoAgMDAQIwfPx4pKSkYP348AHYdkEvxRc7x48fx8MMPo2/fvrh69SreffddANqmguR4xb+dK1euICMjA1WqVAEAXLp0CdevX4e/vz+7Rcmk+LyTn5+PhIQEjBw5EoC2Zig0NBRqtRonTpyQM0SC9pxy4cIFnDx5EqmpqZgxYwb69++PVatWoX///ujbty+ysrLkDtMt8drAOSjh+oBJuJs5ceIENBoNJEmCj48Phg0bhueff97gjlxQUBCys7MRFhYmc7Tu58SJExBCQJIk3cH577//BgAsWbIEAPDWW29hwoQJ+PrrrzFnzhycP38eAJufOcKyZcuwZs0aHD9+XNdKRK1WIyIiwqCvZEREBGbNmoW9e/di69atAFg+9qZfNsWKioogSRLUajXy8vJwzz33oG/fvlixYgUefvhhLFq0CHl5eTJG7T6Ky+fYsWO6307z5s2Rm5uL1NRUPPzww6hXrx68vb2xZMkS3HfffVi5ciUA/nYcYc+ePQBKEoi4uDg8//zzqFOnDgDtcS4/Px85OTlo06aNbHG6q9LlAwA1a9ZESEgInn32WZw+fRrbtm3DV199hW3btmHfvn14+eWX+dtxkPXr1+OHH37AxYsXeW2gQPrlU0wR1weC3MKKFStE7dq1RVJSkkhOThYff/yx0Gg0uuVFRUW6/6elpYmHH35YCCFEfn6+w2N1R6XL55NPPhF5eXlCCCEWLlwo1Gq1aNCggdi7d69umw8//FA0adJEfP3113KF7Ta2bNkiQkNDRfPmzUV0dLSIjY0Vr7/+uhBCiIMHD4q4uDgxf/58XZkJIURGRoZ44IEHxPDhw+UK2y0YK5vFixfrll+9elVEREToymbatGnCx8dH+Pr6it9//12mqN2Hud9OUVGR2Ldvn/joo49EbGysWL9+vRBCiOvXr4tXXnlFhISEiIKCAjnDd3kbNmwQUVFRIiQkRPz7779CCCEKCwt1y/WvE27duiViY2PFb7/95ugw3Za58rl27ZoYPXq0CAgIEP369RNFRUW6a7nly5eLwMBAkZOTI1fobuGjjz4SYWFhonXr1iI0NFS0a9dOfP7550IIIf744w/RuHFjXhvIyFj5bNiwQbf82rVrsl4fsCbcDbzxxhuYN28eFixYgDfeeAOpqalIS0vDu+++q2tuIUkSioqKUFhYiD///BPt27cHAHh6eur2w0Ek7MNY+YwYMQLLly9HUVERunfvjvj4eOTn5yMqKkq3XVpaGm7cuKGbVoHsZ/ny5ejbty/279+PrVu3Yvz48XjiiSfw9ddfo2nTpujUqRM+//xz/Prrr7ptwsPD4enpyXEV7MxY2UyfPh3ffPON7pjWvn17fPHFF0hISMDHH3+MLl26IDo6WndM4yBt9mPqt7Np0yYAQIsWLXD9+nVUq1YN/fv3hxACQUFBaN++Pe7cuaOrASTbW716NebOnYsOHTogLi4O8+fPB2A4OrB+c9lffvkFt2/fRoMGDXTPXbp0yXEBu5nyyqdatWro3LkzvLy8dDMKiLu1qvHx8fDy8kJ6erps8buywsJC3bXb3LlzsWPHDmzcuBH16tXD8uXLkZubi8TERKSkpOCLL77gtYGDmSufZcuW6Wq4c3Nz0bFjR/muD+ye5pOssrOzRdeuXcWcOXOEECV3tTt06CCio6PFxo0bDZ6/ePGiqFmzpjhy5IgQQoj9+/eLkSNHOjxud2GufGrVqiU2bdokhBDi1VdfFWq1Wnz22We6bTMzM0XTpk3FJ5984vC43UFxWZw8eVIEBQWJLVu2GCwfOnSoiI2NFZcvXxaXLl0SiYmJYsiQIeLcuXO6dXr06CGmTZvm0LjdgSVl06hRI3H+/Hlx7tw5IUmS8PT0FI899pi4fv26OHTokEhNTRUpKSlyhO/yLCmfuLg4cfz4cSGE9vjWq1cvcfPmTd06c+fOFR06dBDZ2dmOC9xNFNek/vbbb2LWrFni9OnTYsGCBaJhw4bip59+MlhH3/jx48WQIUOEENpavk6dOom+ffsatKSjyrOkfIpr7m7fvi2mTp0qJEkSW7du1e1j4cKFomvXriwbO7lx44Z45plnxPz58w0+4/nz54t27dqJGzduCCG019S8NnC88srn1q1bQgghzpw5I+v1AZNwF5eXlyeCg4PFmjVrhBBC5ObmCiGEGDBggIiKihLDhw8XmZmZuvU//vhj0aFDB5GVlSUeeeQR4enpKR588EFRVFRk0CyNbKO88nn44YfF9evXxe3bt0Xfvn1FrVq1xJw5c8T+/fvF6NGjRWJiorhw4YKcb8Hl/PPPPwbf9dzcXBEWFiaWLVsmhCi5+Llx44bw8/MT8+bNE0II8emnn4r27duL6Oho8frrr4vhw4eLsLAwsWPHDse/CRdlTdn4+vrqymbNmjVi9+7dBvt67733xGuvvSY0Gg2PbTZi7W/n1VdfFUIIsWrVKtGqVSvRtWtXsX79evHII4+I0NBQ8d577zn+Tbiw0uUjhNA19//777/FAw88IHr06KFbVrrL2oMPPihee+01MWnSJKFSqcSIESPYZc2GrC2f4mT95MmTYsSIEcLf31/069dPDBkyRAQHB4v3339fCCF4fLOR0uWzf/9+XRkUJ3qrV68WzZs3N2h+vm7dOl4bOEBFy2ft2rWyXR8wCXchn332mRgzZoxYsmSJOHjwoO75IUOGiEaNGunuwn3yySfi3nvvFWPGjBENGjQQ+/fvF0JoD9SDBw8WarVaBAQEiJYtW4r09HQ53opLqkj5xMbG6sonPz9fTJkyRSQlJYmGDRuKjh076mqSqPI+/fRTERMTIxo2bChat24tVqxYIYTQ1jSMGDFCdOvWTXfgLr7wnD17tqhdu7ZuH+fOnRPjxo0Tffr0ET169NC1KKHKsUXZFCs+oRqr6aOKsUX5fPLJJ6JDhw4iJSWFvx0bM1U+QhgmaCtXrhSNGzcWK1euFEIYjhVTXGMkSZJo27atOHz4sOPegIuraPmUHi/hvffeE08++aQYNWoUfz82VLp8li9fbrBc/3cydOhQkZaWJoQQBokerw3sp6LlY+wGoqOvD5iEu4ArV66IAQMGiIiICDFhwgSRkpIiatSoIVatWiWE0N4dqlu3rqhbt66IiooSfn5+uoEjPDw8xDfffCOE0H5RBw8eLGJiYnTPUeXZqnyK3b59m8m3jX3//fciJiZGvP3222LLli1i+vTpwsPDQ1eD99///lckJibqahaKL3727t0rQkNDDQbME6KkRQNVXmXLhoOv2Vdly0e/BqKgoEBkZGQ4/k24MGPl4+npKZYtW6YbtKu4TM6dOydGjx4tWrVqpWuuWZxI/P3332LQoEEGTZ6p8ipbPmyJYF/myqf4PF9cW5qbmysSEhLExx9/bHJ/vDawLVuVj1w35ZmEu4B169aJ1q1bG/Q36d+/v6hTp45uFMCzZ8+K7777TqxatUp30M7MzBR169Y16Gf8zz//ODR2d1DZ8lm3bp0cYbuF4rueL774okhKSjK4oHn00UdFYmKi+O6770RWVpYYNmyYaNu2rW6EWiG0d2CjoqLEyZMnHR26y2PZKBvLR9nKK5+WLVuKL774osx2mzZtEi1bthRz5swRf/75p+jZs6c4c+aMw+J2F7Yqn169erF87KAi5XP+/HkRExOju47+559/2O/bTlylfDg0nwtYs2YNatasiRo1auD27dsAgAceeACnTp3Cm2++iczMTNSsWRNdunTBiBEjdCOe//TTT/Dy8tKNhA4AsbGxsrwHV1bZ8klJSZEzfJdWPPLv4cOHUa9ePXh6eupmDHj55Zfh7++PTz75BGq1Go899hhUKhUGDx6MX3/9FWfOnMG3336LpKQkREREyPk2XBLLRtlYPspWXvn4+Pjgyy+/REZGBoCSEYDvvfdetG7dGv/5z3+QlJSEwsJChIWFyfMmXJityqegoIDlYwfWlg8A/PDDD6hVqxYiIyPx+OOPo3Hjxjh9+jQKCgo4F7iNuUz5yHoLgKz2888/iy1bthj0BZo5c6Zo2LChwXqzZs0SnTt3Fm3bttU1CxRCW7uanp4u3nzzTREVFSWefvppUVBQwIE7bITlo2zff/+9mDx5sli8eLFBM9hly5aJgIAAXZOk4ruqy5YtE/Xr1xc7d+4UQghx5MgRXZ/88PBwkZiYyL5dNsKyUTaWj7JVpHwaNGggtm/frlv39u3bYvHixUKtVotOnToZjF1ClcPyUbaKlk/xaPUajUY89NBDolq1aiIkJEQ0adKkTDc1qjhXLR8m4U7i8uXLYsSIEUKSJNGsWTODZn0nTpwQoaGhokOHDmLBggWiTZs2ok6dOmLbtm2iWbNm4rnnntOtu2/fPtGnTx9Rp04ds/1WyDosH2W7cOGC6NWrlwgLCxPDhg0TTZs2FYGBgbqD+dGjR0WNGjV0ZaE/oEpERIRYtGiR7vGtW7fEv//+K3777TfHvgkXxbJRNpaPslW2fBYvXqx7fOjQIZGcnCw++ugjh74HV8byUTZblU92drbo1auXqFmzpli7dq3D34ercvXyYRLuBAoKCsQ777wjunXrJj799FPdtEh37tzRrbNz504xZswY0aJFCzFp0iRx+fJlIYQQw4cPF/379zfY3x9//OHQ+F0dy0fZsrOzxciRI8WgQYMM+p+2bt1aN0pmVlaWePnll4Wvr6+uf11x64OOHTuKMWPG6LZjqwTbYdkoG8tH2WxdPmRbLB9ls3X5cBBQ23KH8mGfcCfg4eGBFi1a4LHHHsPAgQPx1FNPYdGiRUhPT9et065dO3zwwQfYtWsX3nzzTVSvXh2ZmZnYv38/EhMTAQCFhYUAoHtMtsHyUTY/Pz94e3sjLS0NderU0X3OPXr0QHp6OoQQCAgIwNChQ9GiRQsMHDgQp0+fhiRJOHPmDDIzM9GnTx/d/or7IlHlsWyUjeWjbLYuH7Itlo+y2bp8kpKSZHonrskdykcSgqMFOAMhhMEFTI0aNdCrVy8sXLgQAQEBBsvv3LkDtVqN5cuX44MPPsCqVavQtGlTuUJ3CywfZSsoKNANeKfRaKBSqTBs2DD4+/tj2bJluvXOnz+PTp06obCwEC1btsSvv/6KRo0aYc2aNQgPD5crfJfGslE2lo+ysXyUjeWjbCwfZXP18mES7mTy8/Ph5eWFdevWYejQofj222/RtWtX3fLz58/jq6++wsqVK3Hy5Em89dZbGDJkiIwRuxeWj/NISUnB2LFjMXLkSGg0GgCASqXC8ePHsW/fPuzevRvNmjXDyJEjZY7U/bBslI3lo2wsH2Vj+Sgby0fZXKl8mIQ7sbZt28Lf3x+rV69GWFgYLl++jNDQUPzf//0fLly4gBkzZsgdoltj+SjXyZMn0bZtW3zzzTe6JkrFN1BIXiwbZWP5KBvLR9lYPsrG8lE2VysfD7kDIOsVFhbCw8MDH3zwAZo1a4a1a9fixIkT2LlzJ1atWsWaVZmxfJSruFvAzp07UaVKFd1B/MUXX0RGRgZefPFFzrkqE5aNsrF8lI3lo2wsH2Vj+Sibq5YPk3An5OGhLbYmTZqgRYsWmDp1KmrXro33338f8fHxMkdHLB/lKu6Xv2fPHvTv3x9bt27FuHHjkJOTg48//tgpD+KugmWjbCwfZWP5KBvLR9lYPsrmsuXjuIHYyZaOHz8u4uPjhZ+fn1i+fLnc4VApLB/lys3NFfXr1xeSJAlvb28xf/58uUOiu1g2ysbyUTaWj7KxfJSN5aNsrlg+rAl3Umq1Gv3798dTTz0FX19fucOhUlg+yuXj44OYmBh07doVixYtgo+Pj9wh0V0sG2Vj+Sgby0fZWD7KxvJRNlcsHw7MRkRup6ioCGq1Wu4wyAiWjbKxfJSN5aNsLB9lY/kom6uVD5NwIiIiIiIiIgdRyR0AERERERERkbtgEk5ERERERETkIEzCiYiIiIiIiByESTgRERERERGRgzAJJyIiIiIiInIQJuFEREREREREDsIknIiIiIiIiMhBmIQTERG5mLS0NEiSBEmS4OnpifDwcHTt2hUrV66ERqOxeD///e9/ERQUZL9AiYiI3BCTcCIiIheUmpqKixcv4tSpU9i8eTPuvfdePP744+jVqxcKCwvlDo+IiMhtMQknIiJyQd7e3oiIiECNGjXQokULPP300/jyyy+xefNm/Pe//wUALFq0CE2bNoW/vz9q1aqFRx99FLdv3wYAbN++HaNGjcLNmzd1teovvPACACAvLw9PPPEEatSoAX9/fyQnJ2P79u3yvFEiIiInwySciIjITdx3331o1qwZvvjiCwCASqXC0qVLcejQIaxatQo//vgjZs6cCQBo27YtlixZgqpVq+LixYu4ePEinnjiCQDApEmTsGvXLqxduxYHDx7EQw89hNTUVBw7dky290ZEROQsJCGEkDsIIiIisp20tDTcuHEDGzduLLNs8ODBOHjwIA4fPlxm2fr16zFhwgRcuXIFgLZP+NSpU3Hjxg3dOmfOnEHdunVx5swZREVF6Z7v0qULWrdujblz59r8/RAREbkSD7kDICIiIscRQkCSJADADz/8gHnz5uHIkSPIyspCYWEh7ty5g5ycHPj5+Rnd/q+//kJRUREaNGhg8HxeXh5CQkLsHj8REZGzYxJORETkRtLT01GnTh2cOnUKvXr1wsSJE/HKK68gODgYO3fuxOjRo5Gfn28yCb99+zbUajX27dsHtVptsKxKlSqOeAtEREROjUk4ERGRm/jxxx/x119/Ydq0adi3bx80Gg1ef/11qFTaIWI+++wzg/W9vLxQVFRk8FxiYiKKioqQmZmJ9u3bOyx2IiIiV8EknIiIyAXl5eUhIyMDRUVFuHTpErZs2YJ58+ahV69eGDFiBP7++28UFBTgzTffRO/evfHLL7/gvffeM9hHTEwMbt++jW3btqFZs2bw8/NDgwYNMGzYMIwYMQKvv/46EhMTcfnyZWzbtg0JCQno2bOnTO+YiIjIOXB0dCIiIhe0ZcsWREZGIiYmBqmpqfjpp5+wdOlSfPnll1Cr1WjWrBkWLVqEV199FfHx8Vi9ejXmzZtnsI+2bdtiwoQJGDRoEEJDQ7FgwQIAwIcffogRI0ZgxowZaNiwIfr06YO9e/eidu3acrxVIiIip8LR0YmIiIiIiIgchDXhRERERERERA7CJJyIiIiIiIjIQZiEExERERERETkIk3AiIiIiIiIiB2ESTkREREREROQgTMKJiIiIiIiIHIRJOBEREREREZGDMAknIiIiIiIichAm4UREREREREQOwiSciIiIiIiIyEGYhBMRERERERE5CJNwIiIiIiIiIgf5fwRX9zIbSl29AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = np.log(data).diff()\n",
    "df.dropna(inplace=True)\n",
    "df.plot(figsize=(12,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "536d4707-fce8-4473-956b-a59404e384c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18272/754266462.py:1: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`\n",
      "  df.corr().style.background_gradient(cmap='bone_r').set_precision(2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1af43_row0_col0, #T_1af43_row1_col1, #T_1af43_row2_col2, #T_1af43_row3_col3 {\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1af43_row0_col1 {\n",
       "  background-color: #fefefe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1af43_row0_col2 {\n",
       "  background-color: #b2cece;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1af43_row0_col3 {\n",
       "  background-color: #9ab5ba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1af43_row1_col0, #T_1af43_row1_col2, #T_1af43_row1_col3, #T_1af43_row2_col1 {\n",
       "  background-color: #ffffff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1af43_row2_col0, #T_1af43_row3_col1 {\n",
       "  background-color: #b4cfcf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1af43_row2_col3 {\n",
       "  background-color: #9cb8bc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1af43_row3_col0 {\n",
       "  background-color: #798799;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1af43_row3_col2 {\n",
       "  background-color: #7a8999;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1af43\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1af43_level0_col0\" class=\"col_heading level0 col0\" >ms</th>\n",
       "      <th id=\"T_1af43_level0_col1\" class=\"col_heading level0 col1\" >ap</th>\n",
       "      <th id=\"T_1af43_level0_col2\" class=\"col_heading level0 col2\" >cs</th>\n",
       "      <th id=\"T_1af43_level0_col3\" class=\"col_heading level0 col3\" >nd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1af43_level0_row0\" class=\"row_heading level0 row0\" >ms</th>\n",
       "      <td id=\"T_1af43_row0_col0\" class=\"data row0 col0\" >1.00</td>\n",
       "      <td id=\"T_1af43_row0_col1\" class=\"data row0 col1\" >0.43</td>\n",
       "      <td id=\"T_1af43_row0_col2\" class=\"data row0 col2\" >0.55</td>\n",
       "      <td id=\"T_1af43_row0_col3\" class=\"data row0 col3\" >0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af43_level0_row1\" class=\"row_heading level0 row1\" >ap</th>\n",
       "      <td id=\"T_1af43_row1_col0\" class=\"data row1 col0\" >0.43</td>\n",
       "      <td id=\"T_1af43_row1_col1\" class=\"data row1 col1\" >1.00</td>\n",
       "      <td id=\"T_1af43_row1_col2\" class=\"data row1 col2\" >0.42</td>\n",
       "      <td id=\"T_1af43_row1_col3\" class=\"data row1 col3\" >0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af43_level0_row2\" class=\"row_heading level0 row2\" >cs</th>\n",
       "      <td id=\"T_1af43_row2_col0\" class=\"data row2 col0\" >0.55</td>\n",
       "      <td id=\"T_1af43_row2_col1\" class=\"data row2 col1\" >0.42</td>\n",
       "      <td id=\"T_1af43_row2_col2\" class=\"data row2 col2\" >1.00</td>\n",
       "      <td id=\"T_1af43_row2_col3\" class=\"data row2 col3\" >0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af43_level0_row3\" class=\"row_heading level0 row3\" >nd</th>\n",
       "      <td id=\"T_1af43_row3_col0\" class=\"data row3 col0\" >0.69</td>\n",
       "      <td id=\"T_1af43_row3_col1\" class=\"data row3 col1\" >0.55</td>\n",
       "      <td id=\"T_1af43_row3_col2\" class=\"data row3 col2\" >0.69</td>\n",
       "      <td id=\"T_1af43_row3_col3\" class=\"data row3 col3\" >1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f6c902adc00>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr().style.background_gradient(cmap='bone_r').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "167bfcc4-faa3-4855-92a9-6c7c0f88190e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     ap   R-squared:                       0.307\n",
      "Model:                            OLS   Adj. R-squared:                  0.307\n",
      "Method:                 Least Squares   F-statistic:                     1815.\n",
      "Date:                Mon, 17 Oct 2022   Prob (F-statistic):               0.00\n",
      "Time:                        16:44:58   Log-Likelihood:                 19135.\n",
      "No. Observations:                8204   AIC:                        -3.826e+04\n",
      "Df Residuals:                    8201   BIC:                        -3.824e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.0002      0.000      0.953      0.341      -0.000       0.001\n",
      "ms             0.1282      0.018      7.129      0.000       0.093       0.163\n",
      "nd             0.8111      0.021     38.367      0.000       0.770       0.853\n",
      "==============================================================================\n",
      "Omnibus:                     4979.476   Durbin-Watson:                   2.100\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1129760.755\n",
      "Skew:                          -1.799   Prob(JB):                         0.00\n",
      "Kurtosis:                      60.376   Cond. No.                         98.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>mean_sq</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ms</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.191292</td>\n",
       "      <td>1.191292</td>\n",
       "      <td>2158.808611</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nd</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.812314</td>\n",
       "      <td>0.812314</td>\n",
       "      <td>1472.040482</td>\n",
       "      <td>2.308232e-296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>8201.0</td>\n",
       "      <td>4.525545</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              df    sum_sq   mean_sq            F         PR(>F)\n",
       "ms           1.0  1.191292  1.191292  2158.808611   0.000000e+00\n",
       "nd           1.0  0.812314  0.812314  1472.040482  2.308232e-296\n",
       "Residual  8201.0  4.525545  0.000552          NaN            NaN"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols('ap ~ ms + nd', data=df).fit()\n",
    "print(model.summary())\n",
    "sm.stats.anova_lm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ed81642b-1fb2-4a44-ba59-d24c96c13a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.000e+00, 1.000e+00, 3.000e+00, 9.000e+00, 1.200e+01, 3.100e+01,\n",
       "        8.300e+01, 3.240e+02, 1.143e+03, 3.227e+03, 2.327e+03, 7.630e+02,\n",
       "        1.950e+02, 6.900e+01, 1.800e+01, 1.200e+01, 6.000e+00, 2.000e+00,\n",
       "        1.000e+00, 1.000e+00]),\n",
       " array([-0.1562727 , -0.14028591, -0.12429912, -0.10831233, -0.09232554,\n",
       "        -0.07633876, -0.06035197, -0.04436518, -0.02837839, -0.0123916 ,\n",
       "         0.00359519,  0.01958197,  0.03556876,  0.05155555,  0.06754234,\n",
       "         0.08352913,  0.09951592,  0.1155027 ,  0.13148949,  0.14747628,\n",
       "         0.16346307]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApHElEQVR4nO3df3BU9b3/8VcI7ALCbgyQbHIJEKQSUH6rYW+VquQSMFq94FxRCtgiFBrsQAAh/VpAvNNwoRZtVRjr1ThTkR8zxSq5/AhBoMICkiHldwa4YQIXNlAwWaAQfuTz/aOTU7cEJCFL8sHnY+aM2fN5n89+Pp+J5DVnzzkbZYwxAgAAsEiThh4AAABAbRFgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWadrQA4iUqqoqHT9+XK1bt1ZUVFRDDwcAANwEY4zOnj2rxMRENWly/fMsd2yAOX78uJKSkhp6GAAAoA6OHj2q9u3bX7f9jg0wrVu3lvT3BfB4PA08GgAAcDNCoZCSkpKcv+PXc8cGmOqPjTweDwEGAADLfNvlH1zECwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGCdpg09AAB3rk4z8iLW95G5GRHrG0DjxxkYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArFOrALNw4UL17NlTHo9HHo9Hfr9fq1atctovXryozMxMtWnTRq1atdKwYcNUVlYW1kdpaakyMjLUsmVLxcXFadq0abpy5UpYzYYNG9S3b1+53W516dJFubm5dZ8hAAC449QqwLRv315z585VYWGhduzYoccff1xPP/209u7dK0maPHmyPv/8cy1fvlwbN27U8ePHNXToUOf4q1evKiMjQ5cuXdKWLVv00UcfKTc3VzNnznRqSkpKlJGRoccee0xFRUWaNGmSXnrpJa1Zs6aepgwAAGwXZYwxt9JBbGys5s+fr2effVbt2rXT4sWL9eyzz0qSDhw4oG7duikQCKh///5atWqVnnzySR0/flzx8fGSpEWLFmn69Ok6deqUXC6Xpk+frry8PO3Zs8d5j+HDh6u8vFyrV6++6XGFQiF5vV5VVFTI4/HcyhQB1FGnGXkR6/vI3IyI9Q2g4dzs3+86XwNz9epVLVmyROfPn5ff71dhYaEuX76stLQ0pyYlJUUdOnRQIBCQJAUCAfXo0cMJL5KUnp6uUCjknMUJBAJhfVTXVPdxPZWVlQqFQmEbAAC4M9U6wOzevVutWrWS2+3W+PHjtWLFCnXv3l3BYFAul0sxMTFh9fHx8QoGg5KkYDAYFl6q26vbblQTCoV04cKF644rJydHXq/X2ZKSkmo7NQAAYIlaB5iuXbuqqKhI27Zt04QJEzR69Gjt27cvEmOrlezsbFVUVDjb0aNHG3pIAAAgQprW9gCXy6UuXbpIkvr166evvvpKb731lp577jldunRJ5eXlYWdhysrK5PP5JEk+n0/bt28P66/6LqVv1vzznUtlZWXyeDxq0aLFdcfldrvldrtrOx0AAGChW34OTFVVlSorK9WvXz81a9ZMBQUFTltxcbFKS0vl9/slSX6/X7t379bJkyedmvz8fHk8HnXv3t2p+WYf1TXVfQAAANTqDEx2draGDBmiDh066OzZs1q8eLE2bNigNWvWyOv1asyYMcrKylJsbKw8Ho9efvll+f1+9e/fX5I0aNAgde/eXSNHjtS8efMUDAb16quvKjMz0zl7Mn78eL399tt65ZVX9JOf/ETr16/XsmXLlJcXubsZAACAXWoVYE6ePKlRo0bpxIkT8nq96tmzp9asWaN/+7d/kyQtWLBATZo00bBhw1RZWan09HS9++67zvHR0dFauXKlJkyYIL/fr7vuukujR4/WnDlznJrk5GTl5eVp8uTJeuutt9S+fXu9//77Sk9Pr6cpAwAA293yc2AaK54DAzQ8ngMDoLYi/hwYAACAhkKAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOvUKsDk5OTowQcfVOvWrRUXF6dnnnlGxcXFYTWPPvqooqKiwrbx48eH1ZSWliojI0MtW7ZUXFycpk2bpitXroTVbNiwQX379pXb7VaXLl2Um5tbtxkCAIA7Tq0CzMaNG5WZmamtW7cqPz9fly9f1qBBg3T+/PmwurFjx+rEiRPONm/ePKft6tWrysjI0KVLl7RlyxZ99NFHys3N1cyZM52akpISZWRk6LHHHlNRUZEmTZqkl156SWvWrLnF6QIAgDtB09oUr169Oux1bm6u4uLiVFhYqAEDBjj7W7ZsKZ/PV2Mfa9eu1b59+7Ru3TrFx8erd+/eev311zV9+nTNnj1bLpdLixYtUnJyst544w1JUrdu3fTll19qwYIFSk9Pr+0cAQDAHeaWroGpqKiQJMXGxobt//jjj9W2bVvdf//9ys7O1t/+9jenLRAIqEePHoqPj3f2paenKxQKae/evU5NWlpaWJ/p6ekKBAK3MlwAAHCHqNUZmG+qqqrSpEmT9P3vf1/333+/s/+FF15Qx44dlZiYqF27dmn69OkqLi7WH//4R0lSMBgMCy+SnNfBYPCGNaFQSBcuXFCLFi2uGU9lZaUqKyud16FQqK5TAwAAjVydA0xmZqb27NmjL7/8Mmz/uHHjnJ979OihhIQEDRw4UIcPH9Y999xT95F+i5ycHL322msR6x8AADQedfoIaeLEiVq5cqW++OILtW/f/oa1qampkqRDhw5Jknw+n8rKysJqql9XXzdzvRqPx1Pj2RdJys7OVkVFhbMdPXq09hMDAABWqFWAMcZo4sSJWrFihdavX6/k5ORvPaaoqEiSlJCQIEny+/3avXu3Tp486dTk5+fL4/Goe/fuTk1BQUFYP/n5+fL7/dd9H7fbLY/HE7YBAIA7U60CTGZmpv7whz9o8eLFat26tYLBoILBoC5cuCBJOnz4sF5//XUVFhbqyJEj+uyzzzRq1CgNGDBAPXv2lCQNGjRI3bt318iRI/WXv/xFa9as0auvvqrMzEy53W5J0vjx4/W///u/euWVV3TgwAG9++67WrZsmSZPnlzP0wcAADaqVYBZuHChKioq9OijjyohIcHZli5dKklyuVxat26dBg0apJSUFE2ZMkXDhg3T559/7vQRHR2tlStXKjo6Wn6/Xz/60Y80atQozZkzx6lJTk5WXl6e8vPz1atXL73xxht6//33uYUaAABIkqKMMaahBxEJoVBIXq9XFRUVfJwENJBOM/Ii1veRuRkR6xtAw7nZv998FxIAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1mna0AMAgLqI1BdF8iWRgB04AwMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsE6tAkxOTo4efPBBtW7dWnFxcXrmmWdUXFwcVnPx4kVlZmaqTZs2atWqlYYNG6aysrKwmtLSUmVkZKhly5aKi4vTtGnTdOXKlbCaDRs2qG/fvnK73erSpYtyc3PrNkMAAHDHqVWA2bhxozIzM7V161bl5+fr8uXLGjRokM6fP+/UTJ48WZ9//rmWL1+ujRs36vjx4xo6dKjTfvXqVWVkZOjSpUvasmWLPvroI+Xm5mrmzJlOTUlJiTIyMvTYY4+pqKhIkyZN0ksvvaQ1a9bUw5QBAIDtoowxpq4Hnzp1SnFxcdq4caMGDBigiooKtWvXTosXL9azzz4rSTpw4IC6deumQCCg/v37a9WqVXryySd1/PhxxcfHS5IWLVqk6dOn69SpU3K5XJo+fbry8vK0Z88e572GDx+u8vJyrV69+qbGFgqF5PV6VVFRIY/HU9cpArgFnWbkNfQQau3I3IyGHgLwnXazf79v6RqYiooKSVJsbKwkqbCwUJcvX1ZaWppTk5KSog4dOigQCEiSAoGAevTo4YQXSUpPT1coFNLevXudmm/2UV1T3UdNKisrFQqFwjYAAHBnqnOAqaqq0qRJk/T9739f999/vyQpGAzK5XIpJiYmrDY+Pl7BYNCp+WZ4qW6vbrtRTSgU0oULF2ocT05Ojrxer7MlJSXVdWoAAKCRq3OAyczM1J49e7RkyZL6HE+dZWdnq6KiwtmOHj3a0EMCAAAR0rQuB02cOFErV67Upk2b1L59e2e/z+fTpUuXVF5eHnYWpqysTD6fz6nZvn17WH/Vdyl9s+af71wqKyuTx+NRixYtahyT2+2W2+2uy3QAAIBlanUGxhijiRMnasWKFVq/fr2Sk5PD2vv166dmzZqpoKDA2VdcXKzS0lL5/X5Jkt/v1+7du3Xy5EmnJj8/Xx6PR927d3dqvtlHdU11HwAA4LutVmdgMjMztXjxYv3pT39S69atnWtWvF6vWrRoIa/XqzFjxigrK0uxsbHyeDx6+eWX5ff71b9/f0nSoEGD1L17d40cOVLz5s1TMBjUq6++qszMTOcMyvjx4/X222/rlVde0U9+8hOtX79ey5YtU16efXc0AACA+lerMzALFy5URUWFHn30USUkJDjb0qVLnZoFCxboySef1LBhwzRgwAD5fD798Y9/dNqjo6O1cuVKRUdHy+/360c/+pFGjRqlOXPmODXJycnKy8tTfn6+evXqpTfeeEPvv/++0tPT62HKAADAdrf0HJjGjOfAAA2P58AAqK3b8hwYAACAhkCAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOvUOsBs2rRJTz31lBITExUVFaVPP/00rP3FF19UVFRU2DZ48OCwmjNnzmjEiBHyeDyKiYnRmDFjdO7cubCaXbt26ZFHHlHz5s2VlJSkefPm1X52AADgjlTrAHP+/Hn16tVL77zzznVrBg8erBMnTjjbJ598EtY+YsQI7d27V/n5+Vq5cqU2bdqkcePGOe2hUEiDBg1Sx44dVVhYqPnz52v27Nl67733ajtcAABwB2pa2wOGDBmiIUOG3LDG7XbL5/PV2LZ//36tXr1aX331lR544AFJ0u9+9zs98cQT+vWvf63ExER9/PHHunTpkj744AO5XC7dd999Kioq0m9+85uwoAMAAL6bInINzIYNGxQXF6euXbtqwoQJOn36tNMWCAQUExPjhBdJSktLU5MmTbRt2zanZsCAAXK5XE5Nenq6iouL9fXXX0diyAAAwCK1PgPzbQYPHqyhQ4cqOTlZhw8f1i9+8QsNGTJEgUBA0dHRCgaDiouLCx9E06aKjY1VMBiUJAWDQSUnJ4fVxMfHO2133333Ne9bWVmpyspK53UoFKrvqQEAgEai3gPM8OHDnZ979Oihnj176p577tGGDRs0cODA+n47R05Ojl577bWI9Q8AABqPiN9G3blzZ7Vt21aHDh2SJPl8Pp08eTKs5sqVKzpz5oxz3YzP51NZWVlYTfXr611bk52drYqKCmc7evRofU8FAAA0EhEPMMeOHdPp06eVkJAgSfL7/SovL1dhYaFTs379elVVVSk1NdWp2bRpky5fvuzU5Ofnq2vXrjV+fCT9/cJhj8cTtgEAgDtTrQPMuXPnVFRUpKKiIklSSUmJioqKVFpaqnPnzmnatGnaunWrjhw5ooKCAj399NPq0qWL0tPTJUndunXT4MGDNXbsWG3fvl2bN2/WxIkTNXz4cCUmJkqSXnjhBblcLo0ZM0Z79+7V0qVL9dZbbykrK6v+Zg4AAKxV6wCzY8cO9enTR3369JEkZWVlqU+fPpo5c6aio6O1a9cu/fCHP9S9996rMWPGqF+/fvrzn/8st9vt9PHxxx8rJSVFAwcO1BNPPKGHH3447BkvXq9Xa9euVUlJifr166cpU6Zo5syZ3EINAAAkSVHGGNPQg4iEUCgkr9eriooKPk4CGkinGXkNPYRaOzI3o6GHAHyn3ezfb74LCQAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYp2lDDwBAw+s0I6+hhwAAtcIZGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwTq0DzKZNm/TUU08pMTFRUVFR+vTTT8PajTGaOXOmEhIS1KJFC6WlpengwYNhNWfOnNGIESPk8XgUExOjMWPG6Ny5c2E1u3bt0iOPPKLmzZsrKSlJ8+bNq/3sAADAHanWAeb8+fPq1auX3nnnnRrb582bp9/+9rdatGiRtm3bprvuukvp6em6ePGiUzNixAjt3btX+fn5WrlypTZt2qRx48Y57aFQSIMGDVLHjh1VWFio+fPna/bs2XrvvffqMEUAAHCniTLGmDofHBWlFStW6JlnnpH097MviYmJmjJliqZOnSpJqqioUHx8vHJzczV8+HDt379f3bt311dffaUHHnhAkrR69Wo98cQTOnbsmBITE7Vw4UL9v//3/xQMBuVyuSRJM2bM0KeffqoDBw7c1NhCoZC8Xq8qKirk8XjqOkXgO4Evc/yHI3MzGnoIwHfazf79rtdrYEpKShQMBpWWlubs83q9Sk1NVSAQkCQFAgHFxMQ44UWS0tLS1KRJE23bts2pGTBggBNeJCk9PV3FxcX6+uuva3zvyspKhUKhsA0AANyZ6jXABINBSVJ8fHzY/vj4eKctGAwqLi4urL1p06aKjY0Nq6mpj2++xz/LycmR1+t1tqSkpFufEAAAaJTumLuQsrOzVVFR4WxHjx5t6CEBAIAIqdcA4/P5JEllZWVh+8vKypw2n8+nkydPhrVfuXJFZ86cCaupqY9vvsc/c7vd8ng8YRsAALgz1WuASU5Ols/nU0FBgbMvFApp27Zt8vv9kiS/36/y8nIVFhY6NevXr1dVVZVSU1Odmk2bNuny5ctOTX5+vrp27aq77767PocMAAAsVOsAc+7cORUVFamoqEjS3y/cLSoqUmlpqaKiojRp0iT953/+pz777DPt3r1bo0aNUmJionOnUrdu3TR48GCNHTtW27dv1+bNmzVx4kQNHz5ciYmJkqQXXnhBLpdLY8aM0d69e7V06VK99dZbysrKqreJAwAAezWt7QE7duzQY4895ryuDhWjR49Wbm6uXnnlFZ0/f17jxo1TeXm5Hn74Ya1evVrNmzd3jvn44481ceJEDRw4UE2aNNGwYcP029/+1mn3er1au3atMjMz1a9fP7Vt21YzZ84Me1YMAAD47rql58A0ZjwHBrh5PAfmH3gODNCwGuQ5MAAAALcDAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACs07ShBwAAjUmnGXkR6/vI3IyI9Q1813AGBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsQ4ABAADWIcAAAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsE69B5jZs2crKioqbEtJSXHaL168qMzMTLVp00atWrXSsGHDVFZWFtZHaWmpMjIy1LJlS8XFxWnatGm6cuVKfQ8VAABYqmkkOr3vvvu0bt26f7xJ03+8zeTJk5WXl6fly5fL6/Vq4sSJGjp0qDZv3ixJunr1qjIyMuTz+bRlyxadOHFCo0aNUrNmzfSrX/0qEsMFAACWiUiAadq0qXw+3zX7Kyoq9N///d9avHixHn/8cUnShx9+qG7dumnr1q3q37+/1q5dq3379mndunWKj49X79699frrr2v69OmaPXu2XC5XJIYMAAAsEpFrYA4ePKjExER17txZI0aMUGlpqSSpsLBQly9fVlpamlObkpKiDh06KBAISJICgYB69Oih+Ph4pyY9PV2hUEh79+697ntWVlYqFAqFbQAA4M5U7wEmNTVVubm5Wr16tRYuXKiSkhI98sgjOnv2rILBoFwul2JiYsKOiY+PVzAYlCQFg8Gw8FLdXt12PTk5OfJ6vc6WlJRUvxMDAACNRr1/hDRkyBDn5549eyo1NVUdO3bUsmXL1KJFi/p+O0d2draysrKc16FQiBADAMAdKuK3UcfExOjee+/VoUOH5PP5dOnSJZWXl4fVlJWVOdfM+Hy+a+5Kqn5d03U11dxutzweT9gGAADuTBEPMOfOndPhw4eVkJCgfv36qVmzZiooKHDai4uLVVpaKr/fL0ny+/3avXu3Tp486dTk5+fL4/Goe/fukR4uAACwQL1/hDR16lQ99dRT6tixo44fP65Zs2YpOjpazz//vLxer8aMGaOsrCzFxsbK4/Ho5Zdflt/vV//+/SVJgwYNUvfu3TVy5EjNmzdPwWBQr776qjIzM+V2u+t7uAAAwEL1HmCOHTum559/XqdPn1a7du308MMPa+vWrWrXrp0kacGCBWrSpImGDRumyspKpaen691333WOj46O1sqVKzVhwgT5/X7dddddGj16tObMmVPfQwUAAJaKMsaYhh5EJIRCIXm9XlVUVHA9DPAtOs3Ia+ghfCccmZvR0EMAGr2b/fvNdyEBAADrEGAAAIB1CDAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYJ16/zZqAJHBFy4CwD9wBgYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdfg2agC4TSL1jeJH5mZEpF+gMeMMDAAAsA4BBgAAWIcAAwAArEOAAQAA1iHAAAAA6xBgAACAdQgwAADAOgQYAABgHQIMAACwDgEGAABYhwADAACsw3chAfUsUt93AwD4B87AAAAA63AGBgAsF8mzfnzTNRorzsAAAADrEGAAAIB1GnWAeeedd9SpUyc1b95cqamp2r59e0MPCQAANAKN9hqYpUuXKisrS4sWLVJqaqrefPNNpaenq7i4WHFxcQ09PFiOO4UAwG5RxhjT0IOoSWpqqh588EG9/fbbkqSqqiolJSXp5Zdf1owZM771+FAoJK/Xq4qKCnk8nkgPF5YhwAANjwuEUZOb/fvdKM/AXLp0SYWFhcrOznb2NWnSRGlpaQoEAjUeU1lZqcrKSud1RUWFpL8vBCLr/llrGnoIACzUYfLyiPS757X0iPSL26P67/a3nV9plAHmr3/9q65evar4+Piw/fHx8Tpw4ECNx+Tk5Oi11167Zn9SUlJExggAaJy8bzb0CFAfzp49K6/Xe932Rhlg6iI7O1tZWVnO66qqKp05c0Zt2rRRVFTUbR1LKBRSUlKSjh49ysdX/4S1qRnrcn2sTc1Yl+tjbWpmy7oYY3T27FklJibesK5RBpi2bdsqOjpaZWVlYfvLysrk8/lqPMbtdsvtdofti4mJidQQb4rH42nUvyQNibWpGetyfaxNzViX62NtambDutzozEu1RnkbtcvlUr9+/VRQUODsq6qqUkFBgfx+fwOODAAANAaN8gyMJGVlZWn06NF64IEH9NBDD+nNN9/U+fPn9eMf/7ihhwYAABpYow0wzz33nE6dOqWZM2cqGAyqd+/eWr169TUX9jZGbrdbs2bNuuYjLbA218O6XB9rUzPW5fpYm5rdaevSaJ8DAwAAcD2N8hoYAACAGyHAAAAA6xBgAACAdQgwAADAOgSYOjpz5oxGjBghj8ejmJgYjRkzRufOnbvhMe+9954effRReTweRUVFqby8/JqaTp06KSoqKmybO3duhGZR/yK1LnXpt7GpyxwuXryozMxMtWnTRq1atdKwYcOuecDjP/++REVFacmSJZGcyi1555131KlTJzVv3lypqanavn37DeuXL1+ulJQUNW/eXD169ND//M//hLUbYzRz5kwlJCSoRYsWSktL08GDByM5hYip77V58cUXr/ndGDx4cCSnEBG1WZe9e/dq2LBhzr+lb7755i332ZjV99rMnj37mt+ZlJSUCM7gFhjUyeDBg02vXr3M1q1bzZ///GfTpUsX8/zzz9/wmAULFpicnByTk5NjJJmvv/76mpqOHTuaOXPmmBMnTjjbuXPnIjSL+hepdalLv41NXeYwfvx4k5SUZAoKCsyOHTtM//79zb/+67+G1UgyH374YdjvzIULFyI5lTpbsmSJcblc5oMPPjB79+41Y8eONTExMaasrKzG+s2bN5vo6Ggzb948s2/fPvPqq6+aZs2amd27dzs1c+fONV6v13z66afmL3/5i/nhD39okpOTG+0aXE8k1mb06NFm8ODBYb8bZ86cuV1Tqhe1XZft27ebqVOnmk8++cT4fD6zYMGCW+6zsYrE2syaNcvcd999Yb8zp06divBM6oYAUwf79u0zksxXX33l7Fu1apWJiooy//d///etx3/xxRc3DDA1/VLZIFLrcqv9NgZ1mUN5eblp1qyZWb58ubNv//79RpIJBALOPklmxYoVERt7fXrooYdMZmam8/rq1asmMTHR5OTk1Fj/H//xHyYjIyNsX2pqqvnpT39qjDGmqqrK+Hw+M3/+fKe9vLzcuN1u88knn0RgBpFT32tjzN8DzNNPPx2R8d4utV2Xb7rev6e30mdjEom1mTVrlunVq1c9jjJy+AipDgKBgGJiYvTAAw84+9LS0tSkSRNt27btlvufO3eu2rRpoz59+mj+/Pm6cuXKLfd5O0RqXSK93rdDXeZQWFioy5cvKy0tzdmXkpKiDh06KBAIhNVmZmaqbdu2euihh/TBBx9869fQN4RLly6psLAwbD5NmjRRWlraNfOpFggEwuolKT093akvKSlRMBgMq/F6vUpNTb1un41RJNam2oYNGxQXF6euXbtqwoQJOn36dP1PIELqsi4N0WdDiOQ8Dh48qMTERHXu3FkjRoxQaWnprQ43Ihrtk3gbs2AwqLi4uLB9TZs2VWxsrILB4C31/fOf/1x9+/ZVbGystmzZouzsbJ04cUK/+c1vbqnf2yFS6xLJ9b5d6jKHYDAol8t1zZeSxsfHhx0zZ84cPf7442rZsqXWrl2rn/3sZzp37px+/vOf1/s8bsVf//pXXb169ZqnacfHx+vAgQM1HhMMBmusr55/9X9vVGODSKyNJA0ePFhDhw5VcnKyDh8+rF/84hcaMmSIAoGAoqOj638i9awu69IQfTaESM0jNTVVubm56tq1q06cOKHXXntNjzzyiPbs2aPWrVvf6rDrFQHmG2bMmKH/+q//umHN/v37IzqGrKws5+eePXvK5XLppz/9qXJychrs8c+NYV0aq8awNr/85S+dn/v06aPz589r/vz5jS7A4PYbPny483OPHj3Us2dP3XPPPdqwYYMGDhzYgCNDYzVkyBDn5549eyo1NVUdO3bUsmXLNGbMmAYc2bUIMN8wZcoUvfjiizes6dy5s3w+n06ePBm2/8qVKzpz5ox8Pl+9jik1NVVXrlzRkSNH1LVr13rt+2Y19LrczvWurUiujc/n06VLl1ReXh52FqasrOyG805NTdXrr7+uysrKRvWdJ23btlV0dPQ1d1HdaD4+n++G9dX/LSsrU0JCQlhN796963H0kRWJtalJ586d1bZtWx06dMiKAFOXdWmIPhvC7ZpHTEyM7r33Xh06dKje+qwvXAPzDe3atVNKSsoNN5fLJb/fr/LychUWFjrHrl+/XlVVVUpNTa3XMRUVFalJkybXfPxwOzX0utzO9a6tSK5Nv3791KxZMxUUFDj7iouLVVpaKr/ff90xFRUV6e67725U4UWSXC6X+vXrFzafqqoqFRQUXHc+fr8/rF6S8vPznfrk5GT5fL6wmlAopG3btt1wjRqbSKxNTY4dO6bTp0+Hhb3GrC7r0hB9NoTbNY9z587p8OHDjfN3pqGvIrbV4MGDTZ8+fcy2bdvMl19+ab73ve+F3RJ77Ngx07VrV7Nt2zZn34kTJ8zOnTvN73//eyPJbNq0yezcudOcPn3aGGPMli1bzIIFC0xRUZE5fPiw+cMf/mDatWtnRo0addvnV1eRWJeb6dcGdVmb8ePHmw4dOpj169ebHTt2GL/fb/x+v9P+2Wefmd///vdm9+7d5uDBg+bdd981LVu2NDNnzrytc7tZS5YsMW632+Tm5pp9+/aZcePGmZiYGBMMBo0xxowcOdLMmDHDqd+8ebNp2rSp+fWvf232799vZs2aVeNt1DExMeZPf/qT2bVrl3n66aetvY26Ptfm7NmzZurUqSYQCJiSkhKzbt0607dvX/O9733PXLx4sUHmWBe1XZfKykqzc+dOs3PnTpOQkGCmTp1qdu7caQ4ePHjTfdoiEmszZcoUs2HDBlNSUmI2b95s0tLSTNu2bc3Jkydv+/y+DQGmjk6fPm2ef/5506pVK+PxeMyPf/xjc/bsWae9pKTESDJffPGFs2/WrFlG0jXbhx9+aIwxprCw0KSmphqv12uaN29uunXrZn71q19Z9Y9NJNblZvq1QV3W5sKFC+ZnP/uZufvuu03Lli3Nv//7v5sTJ0447atWrTK9e/c2rVq1MnfddZfp1auXWbRokbl69ertnFqt/O53vzMdOnQwLpfLPPTQQ2br1q1O2w9+8AMzevTosPply5aZe++917hcLnPfffeZvLy8sPaqqirzy1/+0sTHxxu3220GDhxoiouLb8dU6l19rs3f/vY3M2jQINOuXTvTrFkz07FjRzN27Fjr/kgbU7t1qf7/6J+3H/zgBzfdp03qe22ee+45k5CQYFwul/mXf/kX89xzz5lDhw7dxhndvChjGuH9lgAAADfANTAAAMA6BBgAAGAdAgwAALAOAQYAAFiHAAMAAKxDgAEAANYhwAAAAOsQYAAAgHUIMAAAwDoEGAAAYB0CDAAAsA4BBgAAWOf/A6ecLhEGCWfXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log(data['ms']).diff(),bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11ce277-1516-430c-af88-7be1578ffa78",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "31e06dbf-0cad-4420-b645-5ad562ca2f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  target  \n",
       "0        -122.23   4.526  \n",
       "1        -122.22   3.585  \n",
       "2        -122.24   3.521  \n",
       "3        -122.25   3.413  \n",
       "4        -122.25   3.422  \n",
       "...          ...     ...  \n",
       "20635    -121.09   0.781  \n",
       "20636    -121.21   0.771  \n",
       "20637    -121.22   0.923  \n",
       "20638    -121.32   0.847  \n",
       "20639    -121.24   0.894  \n",
       "\n",
       "[20640 rows x 9 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data, target = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "data['target'] = target\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3294a338-2c82-43b6-8b18-a977d7d3e527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>target</td>      <th>  R-squared:         </th> <td>   0.606</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.606</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3970.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 17 Oct 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:51:29</td>     <th>  Log-Likelihood:    </th> <td> -22624.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 20640</td>      <th>  AIC:               </th> <td>4.527e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 20631</td>      <th>  BIC:               </th> <td>4.534e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>  -36.9419</td> <td>    0.659</td> <td>  -56.067</td> <td> 0.000</td> <td>  -38.233</td> <td>  -35.650</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HouseAge</th>   <td>    0.0094</td> <td>    0.000</td> <td>   21.143</td> <td> 0.000</td> <td>    0.009</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AveRooms</th>   <td>   -0.1073</td> <td>    0.006</td> <td>  -18.235</td> <td> 0.000</td> <td>   -0.119</td> <td>   -0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Population</th> <td>-3.976e-06</td> <td> 4.75e-06</td> <td>   -0.837</td> <td> 0.402</td> <td>-1.33e-05</td> <td> 5.33e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AveOccup</th>   <td>   -0.0038</td> <td>    0.000</td> <td>   -7.769</td> <td> 0.000</td> <td>   -0.005</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Longitude</th>  <td>   -0.4345</td> <td>    0.008</td> <td>  -57.682</td> <td> 0.000</td> <td>   -0.449</td> <td>   -0.420</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MedInc</th>     <td>    0.4367</td> <td>    0.004</td> <td>  104.054</td> <td> 0.000</td> <td>    0.428</td> <td>    0.445</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AveBedrms</th>  <td>    0.6451</td> <td>    0.028</td> <td>   22.928</td> <td> 0.000</td> <td>    0.590</td> <td>    0.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Latitude</th>   <td>   -0.4213</td> <td>    0.007</td> <td>  -58.541</td> <td> 0.000</td> <td>   -0.435</td> <td>   -0.407</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>4393.650</td> <th>  Durbin-Watson:     </th> <td>   0.885</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>14087.596</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.082</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 6.420</td>  <th>  Cond. No.          </th> <td>2.38e+05</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.38e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 target   R-squared:                       0.606\n",
       "Model:                            OLS   Adj. R-squared:                  0.606\n",
       "Method:                 Least Squares   F-statistic:                     3970.\n",
       "Date:                Mon, 17 Oct 2022   Prob (F-statistic):               0.00\n",
       "Time:                        16:51:29   Log-Likelihood:                -22624.\n",
       "No. Observations:               20640   AIC:                         4.527e+04\n",
       "Df Residuals:                   20631   BIC:                         4.534e+04\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    -36.9419      0.659    -56.067      0.000     -38.233     -35.650\n",
       "HouseAge       0.0094      0.000     21.143      0.000       0.009       0.010\n",
       "AveRooms      -0.1073      0.006    -18.235      0.000      -0.119      -0.096\n",
       "Population -3.976e-06   4.75e-06     -0.837      0.402   -1.33e-05    5.33e-06\n",
       "AveOccup      -0.0038      0.000     -7.769      0.000      -0.005      -0.003\n",
       "Longitude     -0.4345      0.008    -57.682      0.000      -0.449      -0.420\n",
       "MedInc         0.4367      0.004    104.054      0.000       0.428       0.445\n",
       "AveBedrms      0.6451      0.028     22.928      0.000       0.590       0.700\n",
       "Latitude      -0.4213      0.007    -58.541      0.000      -0.435      -0.407\n",
       "==============================================================================\n",
       "Omnibus:                     4393.650   Durbin-Watson:                   0.885\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            14087.596\n",
       "Skew:                           1.082   Prob(JB):                         0.00\n",
       "Kurtosis:                       6.420   Cond. No.                     2.38e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.38e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols('target ~  HouseAge + AveRooms +  Population + AveOccup + Longitude + MedInc + AveBedrms + Latitude', data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3d97b9f6-5d6a-4273-ae1e-ac5860d6c970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>mean_sq</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HouseAge</th>\n",
       "      <td>1.0</td>\n",
       "      <td>306.610949</td>\n",
       "      <td>306.610949</td>\n",
       "      <td>584.522192</td>\n",
       "      <td>2.297689e-127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveRooms</th>\n",
       "      <td>1.0</td>\n",
       "      <td>795.653469</td>\n",
       "      <td>795.653469</td>\n",
       "      <td>1516.831383</td>\n",
       "      <td>3.136329e-320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Population</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22.132566</td>\n",
       "      <td>22.132566</td>\n",
       "      <td>42.193457</td>\n",
       "      <td>8.456212e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveOccup</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19.925082</td>\n",
       "      <td>19.925082</td>\n",
       "      <td>37.985116</td>\n",
       "      <td>7.260819e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Longitude</th>\n",
       "      <td>1.0</td>\n",
       "      <td>23.288079</td>\n",
       "      <td>23.288079</td>\n",
       "      <td>44.396324</td>\n",
       "      <td>2.749560e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MedInc</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12979.269020</td>\n",
       "      <td>12979.269020</td>\n",
       "      <td>24743.639481</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AveBedrms</th>\n",
       "      <td>1.0</td>\n",
       "      <td>716.654012</td>\n",
       "      <td>716.654012</td>\n",
       "      <td>1366.227056</td>\n",
       "      <td>1.216909e-289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Latitude</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1797.679863</td>\n",
       "      <td>1797.679863</td>\n",
       "      <td>3427.091492</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>20631.0</td>\n",
       "      <td>10821.985155</td>\n",
       "      <td>0.524550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 df        sum_sq       mean_sq             F         PR(>F)\n",
       "HouseAge        1.0    306.610949    306.610949    584.522192  2.297689e-127\n",
       "AveRooms        1.0    795.653469    795.653469   1516.831383  3.136329e-320\n",
       "Population      1.0     22.132566     22.132566     42.193457   8.456212e-11\n",
       "AveOccup        1.0     19.925082     19.925082     37.985116   7.260819e-10\n",
       "Longitude       1.0     23.288079     23.288079     44.396324   2.749560e-11\n",
       "MedInc          1.0  12979.269020  12979.269020  24743.639481   0.000000e+00\n",
       "AveBedrms       1.0    716.654012    716.654012   1366.227056  1.216909e-289\n",
       "Latitude        1.0   1797.679863   1797.679863   3427.091492   0.000000e+00\n",
       "Residual    20631.0  10821.985155      0.524550           NaN            NaN"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.stats.anova_lm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bbf83d84-c435-4e4a-be94-f2990b10583e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18272/261834331.py:1: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`\n",
      "  data.corr().style.background_gradient(cmap='bone_r').set_precision(2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3ccd6_row0_col0, #T_3ccd6_row1_col1, #T_3ccd6_row2_col2, #T_3ccd6_row3_col3, #T_3ccd6_row4_col4, #T_3ccd6_row5_col5, #T_3ccd6_row6_col6, #T_3ccd6_row7_col7, #T_3ccd6_row8_col8 {\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ccd6_row0_col1 {\n",
       "  background-color: #d1e1e1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row0_col2 {\n",
       "  background-color: #8295a2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ccd6_row0_col3 {\n",
       "  background-color: #fbfcfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row0_col4 {\n",
       "  background-color: #aecbcb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row0_col5 {\n",
       "  background-color: #f1f6f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row0_col6 {\n",
       "  background-color: #7d8d9d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ccd6_row0_col7 {\n",
       "  background-color: #768496;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ccd6_row0_col8 {\n",
       "  background-color: #3c3c54;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ccd6_row1_col0, #T_3ccd6_row1_col2, #T_3ccd6_row1_col3, #T_3ccd6_row1_col4, #T_3ccd6_row4_col1, #T_3ccd6_row6_col7, #T_3ccd6_row6_col8, #T_3ccd6_row7_col6, #T_3ccd6_row8_col5 {\n",
       "  background-color: #ffffff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row1_col5 {\n",
       "  background-color: #f3f7f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row1_col6, #T_3ccd6_row3_col7 {\n",
       "  background-color: #737f92;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ccd6_row1_col7, #T_3ccd6_row4_col6 {\n",
       "  background-color: #8192a0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ccd6_row1_col8 {\n",
       "  background-color: #b4cfcf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row2_col0 {\n",
       "  background-color: #869aa6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ccd6_row2_col1, #T_3ccd6_row4_col0 {\n",
       "  background-color: #d9e6e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row2_col3 {\n",
       "  background-color: #201f2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ccd6_row2_col4 {\n",
       "  background-color: #c3d8d8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row2_col5, #T_3ccd6_row3_col5 {\n",
       "  background-color: #fafcfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row2_col6 {\n",
       "  background-color: #676f87;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ccd6_row2_col7 {\n",
       "  background-color: #778597;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ccd6_row2_col8 {\n",
       "  background-color: #a5c5c5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row3_col0 {\n",
       "  background-color: #edf4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row3_col1 {\n",
       "  background-color: #c4d9d9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row3_col2 {\n",
       "  background-color: #1d1d28;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ccd6_row3_col4 {\n",
       "  background-color: #c1d8d8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row3_col6 {\n",
       "  background-color: #6c758b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ccd6_row3_col8, #T_3ccd6_row7_col3, #T_3ccd6_row7_col8 {\n",
       "  background-color: #e2eded;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row4_col2 {\n",
       "  background-color: #e8f0f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row4_col3 {\n",
       "  background-color: #fcfdfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row4_col5, #T_3ccd6_row7_col0 {\n",
       "  background-color: #e0ebeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row4_col7 {\n",
       "  background-color: #687188;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ccd6_row4_col8, #T_3ccd6_row5_col8 {\n",
       "  background-color: #dbe8e8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row5_col0 {\n",
       "  background-color: #d5e4e4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row5_col1 {\n",
       "  background-color: #accaca;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row5_col2 {\n",
       "  background-color: #d3e3e3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row5_col3 {\n",
       "  background-color: #e9f1f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row5_col4 {\n",
       "  background-color: #a0bec0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row5_col6, #T_3ccd6_row5_col7 {\n",
       "  background-color: #738093;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ccd6_row6_col0 {\n",
       "  background-color: #f4f8f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row6_col1 {\n",
       "  background-color: #adcaca;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row6_col2 {\n",
       "  background-color: #b1cdcd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row6_col3 {\n",
       "  background-color: #cfe0e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row6_col4, #T_3ccd6_row7_col1 {\n",
       "  background-color: #ccdfdf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row6_col5, #T_3ccd6_row7_col5 {\n",
       "  background-color: #f7fafa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row7_col2 {\n",
       "  background-color: #dae7e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row7_col4 {\n",
       "  background-color: #9bb6bb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row8_col0 {\n",
       "  background-color: #3e3e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ccd6_row8_col1 {\n",
       "  background-color: #9ab5ba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row8_col2 {\n",
       "  background-color: #a4c4c4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row8_col3 {\n",
       "  background-color: #f5f9f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row8_col4 {\n",
       "  background-color: #b7d1d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ccd6_row8_col6 {\n",
       "  background-color: #8598a5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ccd6_row8_col7 {\n",
       "  background-color: #7a8999;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3ccd6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3ccd6_level0_col0\" class=\"col_heading level0 col0\" >MedInc</th>\n",
       "      <th id=\"T_3ccd6_level0_col1\" class=\"col_heading level0 col1\" >HouseAge</th>\n",
       "      <th id=\"T_3ccd6_level0_col2\" class=\"col_heading level0 col2\" >AveRooms</th>\n",
       "      <th id=\"T_3ccd6_level0_col3\" class=\"col_heading level0 col3\" >AveBedrms</th>\n",
       "      <th id=\"T_3ccd6_level0_col4\" class=\"col_heading level0 col4\" >Population</th>\n",
       "      <th id=\"T_3ccd6_level0_col5\" class=\"col_heading level0 col5\" >AveOccup</th>\n",
       "      <th id=\"T_3ccd6_level0_col6\" class=\"col_heading level0 col6\" >Latitude</th>\n",
       "      <th id=\"T_3ccd6_level0_col7\" class=\"col_heading level0 col7\" >Longitude</th>\n",
       "      <th id=\"T_3ccd6_level0_col8\" class=\"col_heading level0 col8\" >target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3ccd6_level0_row0\" class=\"row_heading level0 row0\" >MedInc</th>\n",
       "      <td id=\"T_3ccd6_row0_col0\" class=\"data row0 col0\" >1.00</td>\n",
       "      <td id=\"T_3ccd6_row0_col1\" class=\"data row0 col1\" >-0.12</td>\n",
       "      <td id=\"T_3ccd6_row0_col2\" class=\"data row0 col2\" >0.33</td>\n",
       "      <td id=\"T_3ccd6_row0_col3\" class=\"data row0 col3\" >-0.06</td>\n",
       "      <td id=\"T_3ccd6_row0_col4\" class=\"data row0 col4\" >0.00</td>\n",
       "      <td id=\"T_3ccd6_row0_col5\" class=\"data row0 col5\" >0.02</td>\n",
       "      <td id=\"T_3ccd6_row0_col6\" class=\"data row0 col6\" >-0.08</td>\n",
       "      <td id=\"T_3ccd6_row0_col7\" class=\"data row0 col7\" >-0.02</td>\n",
       "      <td id=\"T_3ccd6_row0_col8\" class=\"data row0 col8\" >0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ccd6_level0_row1\" class=\"row_heading level0 row1\" >HouseAge</th>\n",
       "      <td id=\"T_3ccd6_row1_col0\" class=\"data row1 col0\" >-0.12</td>\n",
       "      <td id=\"T_3ccd6_row1_col1\" class=\"data row1 col1\" >1.00</td>\n",
       "      <td id=\"T_3ccd6_row1_col2\" class=\"data row1 col2\" >-0.15</td>\n",
       "      <td id=\"T_3ccd6_row1_col3\" class=\"data row1 col3\" >-0.08</td>\n",
       "      <td id=\"T_3ccd6_row1_col4\" class=\"data row1 col4\" >-0.30</td>\n",
       "      <td id=\"T_3ccd6_row1_col5\" class=\"data row1 col5\" >0.01</td>\n",
       "      <td id=\"T_3ccd6_row1_col6\" class=\"data row1 col6\" >0.01</td>\n",
       "      <td id=\"T_3ccd6_row1_col7\" class=\"data row1 col7\" >-0.11</td>\n",
       "      <td id=\"T_3ccd6_row1_col8\" class=\"data row1 col8\" >0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ccd6_level0_row2\" class=\"row_heading level0 row2\" >AveRooms</th>\n",
       "      <td id=\"T_3ccd6_row2_col0\" class=\"data row2 col0\" >0.33</td>\n",
       "      <td id=\"T_3ccd6_row2_col1\" class=\"data row2 col1\" >-0.15</td>\n",
       "      <td id=\"T_3ccd6_row2_col2\" class=\"data row2 col2\" >1.00</td>\n",
       "      <td id=\"T_3ccd6_row2_col3\" class=\"data row2 col3\" >0.85</td>\n",
       "      <td id=\"T_3ccd6_row2_col4\" class=\"data row2 col4\" >-0.07</td>\n",
       "      <td id=\"T_3ccd6_row2_col5\" class=\"data row2 col5\" >-0.00</td>\n",
       "      <td id=\"T_3ccd6_row2_col6\" class=\"data row2 col6\" >0.11</td>\n",
       "      <td id=\"T_3ccd6_row2_col7\" class=\"data row2 col7\" >-0.03</td>\n",
       "      <td id=\"T_3ccd6_row2_col8\" class=\"data row2 col8\" >0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ccd6_level0_row3\" class=\"row_heading level0 row3\" >AveBedrms</th>\n",
       "      <td id=\"T_3ccd6_row3_col0\" class=\"data row3 col0\" >-0.06</td>\n",
       "      <td id=\"T_3ccd6_row3_col1\" class=\"data row3 col1\" >-0.08</td>\n",
       "      <td id=\"T_3ccd6_row3_col2\" class=\"data row3 col2\" >0.85</td>\n",
       "      <td id=\"T_3ccd6_row3_col3\" class=\"data row3 col3\" >1.00</td>\n",
       "      <td id=\"T_3ccd6_row3_col4\" class=\"data row3 col4\" >-0.07</td>\n",
       "      <td id=\"T_3ccd6_row3_col5\" class=\"data row3 col5\" >-0.01</td>\n",
       "      <td id=\"T_3ccd6_row3_col6\" class=\"data row3 col6\" >0.07</td>\n",
       "      <td id=\"T_3ccd6_row3_col7\" class=\"data row3 col7\" >0.01</td>\n",
       "      <td id=\"T_3ccd6_row3_col8\" class=\"data row3 col8\" >-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ccd6_level0_row4\" class=\"row_heading level0 row4\" >Population</th>\n",
       "      <td id=\"T_3ccd6_row4_col0\" class=\"data row4 col0\" >0.00</td>\n",
       "      <td id=\"T_3ccd6_row4_col1\" class=\"data row4 col1\" >-0.30</td>\n",
       "      <td id=\"T_3ccd6_row4_col2\" class=\"data row4 col2\" >-0.07</td>\n",
       "      <td id=\"T_3ccd6_row4_col3\" class=\"data row4 col3\" >-0.07</td>\n",
       "      <td id=\"T_3ccd6_row4_col4\" class=\"data row4 col4\" >1.00</td>\n",
       "      <td id=\"T_3ccd6_row4_col5\" class=\"data row4 col5\" >0.07</td>\n",
       "      <td id=\"T_3ccd6_row4_col6\" class=\"data row4 col6\" >-0.11</td>\n",
       "      <td id=\"T_3ccd6_row4_col7\" class=\"data row4 col7\" >0.10</td>\n",
       "      <td id=\"T_3ccd6_row4_col8\" class=\"data row4 col8\" >-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ccd6_level0_row5\" class=\"row_heading level0 row5\" >AveOccup</th>\n",
       "      <td id=\"T_3ccd6_row5_col0\" class=\"data row5 col0\" >0.02</td>\n",
       "      <td id=\"T_3ccd6_row5_col1\" class=\"data row5 col1\" >0.01</td>\n",
       "      <td id=\"T_3ccd6_row5_col2\" class=\"data row5 col2\" >-0.00</td>\n",
       "      <td id=\"T_3ccd6_row5_col3\" class=\"data row5 col3\" >-0.01</td>\n",
       "      <td id=\"T_3ccd6_row5_col4\" class=\"data row5 col4\" >0.07</td>\n",
       "      <td id=\"T_3ccd6_row5_col5\" class=\"data row5 col5\" >1.00</td>\n",
       "      <td id=\"T_3ccd6_row5_col6\" class=\"data row5 col6\" >0.00</td>\n",
       "      <td id=\"T_3ccd6_row5_col7\" class=\"data row5 col7\" >0.00</td>\n",
       "      <td id=\"T_3ccd6_row5_col8\" class=\"data row5 col8\" >-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ccd6_level0_row6\" class=\"row_heading level0 row6\" >Latitude</th>\n",
       "      <td id=\"T_3ccd6_row6_col0\" class=\"data row6 col0\" >-0.08</td>\n",
       "      <td id=\"T_3ccd6_row6_col1\" class=\"data row6 col1\" >0.01</td>\n",
       "      <td id=\"T_3ccd6_row6_col2\" class=\"data row6 col2\" >0.11</td>\n",
       "      <td id=\"T_3ccd6_row6_col3\" class=\"data row6 col3\" >0.07</td>\n",
       "      <td id=\"T_3ccd6_row6_col4\" class=\"data row6 col4\" >-0.11</td>\n",
       "      <td id=\"T_3ccd6_row6_col5\" class=\"data row6 col5\" >0.00</td>\n",
       "      <td id=\"T_3ccd6_row6_col6\" class=\"data row6 col6\" >1.00</td>\n",
       "      <td id=\"T_3ccd6_row6_col7\" class=\"data row6 col7\" >-0.92</td>\n",
       "      <td id=\"T_3ccd6_row6_col8\" class=\"data row6 col8\" >-0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ccd6_level0_row7\" class=\"row_heading level0 row7\" >Longitude</th>\n",
       "      <td id=\"T_3ccd6_row7_col0\" class=\"data row7 col0\" >-0.02</td>\n",
       "      <td id=\"T_3ccd6_row7_col1\" class=\"data row7 col1\" >-0.11</td>\n",
       "      <td id=\"T_3ccd6_row7_col2\" class=\"data row7 col2\" >-0.03</td>\n",
       "      <td id=\"T_3ccd6_row7_col3\" class=\"data row7 col3\" >0.01</td>\n",
       "      <td id=\"T_3ccd6_row7_col4\" class=\"data row7 col4\" >0.10</td>\n",
       "      <td id=\"T_3ccd6_row7_col5\" class=\"data row7 col5\" >0.00</td>\n",
       "      <td id=\"T_3ccd6_row7_col6\" class=\"data row7 col6\" >-0.92</td>\n",
       "      <td id=\"T_3ccd6_row7_col7\" class=\"data row7 col7\" >1.00</td>\n",
       "      <td id=\"T_3ccd6_row7_col8\" class=\"data row7 col8\" >-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ccd6_level0_row8\" class=\"row_heading level0 row8\" >target</th>\n",
       "      <td id=\"T_3ccd6_row8_col0\" class=\"data row8 col0\" >0.69</td>\n",
       "      <td id=\"T_3ccd6_row8_col1\" class=\"data row8 col1\" >0.11</td>\n",
       "      <td id=\"T_3ccd6_row8_col2\" class=\"data row8 col2\" >0.15</td>\n",
       "      <td id=\"T_3ccd6_row8_col3\" class=\"data row8 col3\" >-0.05</td>\n",
       "      <td id=\"T_3ccd6_row8_col4\" class=\"data row8 col4\" >-0.02</td>\n",
       "      <td id=\"T_3ccd6_row8_col5\" class=\"data row8 col5\" >-0.02</td>\n",
       "      <td id=\"T_3ccd6_row8_col6\" class=\"data row8 col6\" >-0.14</td>\n",
       "      <td id=\"T_3ccd6_row8_col7\" class=\"data row8 col7\" >-0.05</td>\n",
       "      <td id=\"T_3ccd6_row8_col8\" class=\"data row8 col8\" >1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f6c890177f0>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr().style.background_gradient(cmap='bone_r').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0c7a0f45-83d1-4927-9a15-c9cd29c23568",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = fetch_california_housing(as_frame=True, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b84fa162-f1de-4a87-acbe-4330303e9de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MedInc': 0.44, 'HouseAge': 0.01, 'AveRooms': -0.11, 'AveBedrms': 0.65, 'Population': -0.0, 'AveOccup': -0.0, 'Latitude': -0.42, 'Longitude': -0.43}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.606232685199805"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Ridge(alpha=0)\n",
    "model.fit(data,target)\n",
    "print(dict(list(zip(model.feature_names_in_,np.round(model.coef_,2)))))\n",
    "model.score(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "79651175-bb3f-44ac-a619-c9fa3e16277b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MedInc': 0.4, 'HouseAge': 0.01, 'AveRooms': -0.04, 'AveBedrms': 0.27, 'Population': -0.0, 'AveOccup': -0.0, 'Latitude': -0.41, 'Longitude': -0.42}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6024178576491683"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Lasso(alpha=1e-2)\n",
    "model.fit(data,target)\n",
    "print(dict(list(zip(model.feature_names_in_,np.round(model.coef_,2)))))\n",
    "model.score(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "04c1d7c6-1c27-48a9-9df9-5a598539d605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MedInc': 0.38, 'HouseAge': 0.01, 'AveRooms': -0.0, 'AveBedrms': 0.07, 'Population': 0.0, 'AveOccup': -0.0, 'Latitude': -0.32, 'Longitude': -0.32}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.590418124099799"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ElasticNet(alpha=0.1, l1_ratio=0.1)\n",
    "model.fit(data,target)\n",
    "print(dict(list(zip(model.feature_names_in_,np.round(model.coef_,2)))))\n",
    "model.score(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2f9c72a7-fe7a-485b-9ac9-04f855b0177a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.386e+03, tolerance: 2.235e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.288e+03, tolerance: 2.204e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.320e+03, tolerance: 2.206e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.354e+03, tolerance: 2.196e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.368e+03, tolerance: 2.197e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.253e+03, tolerance: 2.205e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.254e+03, tolerance: 2.188e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.301e+03, tolerance: 2.191e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.362e+03, tolerance: 2.182e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.372e+03, tolerance: 2.184e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.355e+03, tolerance: 2.196e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.289e+03, tolerance: 2.204e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.302e+03, tolerance: 2.191e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.369e+03, tolerance: 2.197e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.321e+03, tolerance: 2.206e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.255e+03, tolerance: 2.188e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.387e+03, tolerance: 2.235e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.254e+03, tolerance: 2.205e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.363e+03, tolerance: 2.182e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.373e+03, tolerance: 2.184e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.328e+03, tolerance: 2.206e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.309e+03, tolerance: 2.191e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.262e+03, tolerance: 2.205e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.370e+03, tolerance: 2.182e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.298e+03, tolerance: 2.204e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.376e+03, tolerance: 2.197e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.362e+03, tolerance: 2.196e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.380e+03, tolerance: 2.184e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.262e+03, tolerance: 2.188e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.394e+03, tolerance: 2.235e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.392e+03, tolerance: 2.206e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.368e+03, tolerance: 2.191e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.431e+03, tolerance: 2.182e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.374e+03, tolerance: 2.204e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.335e+03, tolerance: 2.205e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.422e+03, tolerance: 2.196e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.439e+03, tolerance: 2.184e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.437e+03, tolerance: 2.197e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.459e+03, tolerance: 2.235e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.326e+03, tolerance: 2.188e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.747e+03, tolerance: 2.191e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.740e+03, tolerance: 2.205e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.786e+03, tolerance: 2.206e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.785e+03, tolerance: 2.204e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.809e+03, tolerance: 2.182e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.714e+03, tolerance: 2.188e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.818e+03, tolerance: 2.197e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.854e+03, tolerance: 2.235e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.798e+03, tolerance: 2.196e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.814e+03, tolerance: 2.184e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.320e+03, tolerance: 2.206e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.253e+03, tolerance: 2.205e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.288e+03, tolerance: 2.204e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.301e+03, tolerance: 2.191e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.301e+03, tolerance: 2.191e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.362e+03, tolerance: 2.182e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.320e+03, tolerance: 2.206e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.288e+03, tolerance: 2.204e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.254e+03, tolerance: 2.188e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.386e+03, tolerance: 2.235e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.354e+03, tolerance: 2.196e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.368e+03, tolerance: 2.197e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.372e+03, tolerance: 2.184e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.386e+03, tolerance: 2.235e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.354e+03, tolerance: 2.196e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.368e+03, tolerance: 2.197e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.253e+03, tolerance: 2.205e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.362e+03, tolerance: 2.182e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.288e+03, tolerance: 2.204e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.301e+03, tolerance: 2.191e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.320e+03, tolerance: 2.206e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.320e+03, tolerance: 2.206e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.253e+03, tolerance: 2.205e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.362e+03, tolerance: 2.182e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.254e+03, tolerance: 2.188e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.372e+03, tolerance: 2.184e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.368e+03, tolerance: 2.197e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.354e+03, tolerance: 2.196e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.354e+03, tolerance: 2.196e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.386e+03, tolerance: 2.235e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.254e+03, tolerance: 2.188e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.372e+03, tolerance: 2.184e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.301e+03, tolerance: 2.191e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.288e+03, tolerance: 2.204e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.253e+03, tolerance: 2.205e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.362e+03, tolerance: 2.182e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.301e+03, tolerance: 2.191e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.288e+03, tolerance: 2.204e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.320e+03, tolerance: 2.206e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.368e+03, tolerance: 2.197e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.253e+03, tolerance: 2.205e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.386e+03, tolerance: 2.235e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.254e+03, tolerance: 2.188e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.372e+03, tolerance: 2.184e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.368e+03, tolerance: 2.197e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.362e+03, tolerance: 2.182e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.386e+03, tolerance: 2.235e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.354e+03, tolerance: 2.196e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.254e+03, tolerance: 2.188e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.320e+03, tolerance: 2.206e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.301e+03, tolerance: 2.191e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.288e+03, tolerance: 2.204e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.253e+03, tolerance: 2.205e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.372e+03, tolerance: 2.184e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.320e+03, tolerance: 2.206e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.354e+03, tolerance: 2.196e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.362e+03, tolerance: 2.182e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.354e+03, tolerance: 2.196e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.368e+03, tolerance: 2.197e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.386e+03, tolerance: 2.235e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.288e+03, tolerance: 2.204e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.368e+03, tolerance: 2.197e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.254e+03, tolerance: 2.188e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.301e+03, tolerance: 2.191e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.386e+03, tolerance: 2.235e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.372e+03, tolerance: 2.184e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.253e+03, tolerance: 2.205e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.362e+03, tolerance: 2.182e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.254e+03, tolerance: 2.188e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.372e+03, tolerance: 2.184e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.320e+03, tolerance: 2.206e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.354e+03, tolerance: 2.196e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.301e+03, tolerance: 2.191e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.368e+03, tolerance: 2.197e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.288e+03, tolerance: 2.204e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.386e+03, tolerance: 2.235e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.253e+03, tolerance: 2.205e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.254e+03, tolerance: 2.188e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.320e+03, tolerance: 2.206e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.362e+03, tolerance: 2.182e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.372e+03, tolerance: 2.184e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.354e+03, tolerance: 2.196e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.301e+03, tolerance: 2.191e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.368e+03, tolerance: 2.197e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.288e+03, tolerance: 2.204e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.253e+03, tolerance: 2.205e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.362e+03, tolerance: 2.182e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.254e+03, tolerance: 2.188e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.386e+03, tolerance: 2.235e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.372e+03, tolerance: 2.184e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.320e+03, tolerance: 2.206e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.354e+03, tolerance: 2.196e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.301e+03, tolerance: 2.191e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.368e+03, tolerance: 2.197e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.253e+03, tolerance: 2.205e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.386e+03, tolerance: 2.235e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.288e+03, tolerance: 2.204e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.254e+03, tolerance: 2.188e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.362e+03, tolerance: 2.182e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.372e+03, tolerance: 2.184e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.312e+03, tolerance: 2.206e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.295e+03, tolerance: 2.196e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.244e+03, tolerance: 2.191e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.296e+03, tolerance: 2.204e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.313e+03, tolerance: 2.197e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.382e+03, tolerance: 2.235e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.257e+03, tolerance: 2.205e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.228e+03, tolerance: 2.188e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.302e+03, tolerance: 2.182e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.289e+03, tolerance: 2.184e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.269e+03, tolerance: 2.182e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.343e+03, tolerance: 2.206e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.311e+03, tolerance: 2.204e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.300e+03, tolerance: 2.196e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.255e+03, tolerance: 2.184e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.074e+04, tolerance: 2.206e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+04, tolerance: 2.182e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.451e+03, tolerance: 2.235e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.255e+03, tolerance: 2.191e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+04, tolerance: 2.184e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.305e+03, tolerance: 2.197e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.290e+03, tolerance: 2.205e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+04, tolerance: 2.196e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.248e+03, tolerance: 2.188e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.066e+04, tolerance: 2.191e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+04, tolerance: 2.197e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.072e+04, tolerance: 2.204e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.088e+04, tolerance: 2.235e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.072e+04, tolerance: 2.205e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.065e+04, tolerance: 2.188e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:910: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.411e+03, tolerance: 2.748e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV,RepeatedKFold\n",
    "from numpy import arange\n",
    "\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=2, random_state=1)\n",
    "grid = {}\n",
    "grid['alpha'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.0, 1.0, 10.0, 100.0]\n",
    "grid['l1_ratio'] = arange(0, 1, 0.1)\n",
    "\n",
    "search = GridSearchCV(model, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "results = search.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b639cd94-60e4-4c58-98d2-676e0b0eee7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=RepeatedKFold(n_repeats=2, n_splits=5, random_state=1),\n",
       "             estimator=ElasticNet(alpha=0.1, l1_ratio=0.1), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [1e-05, 0.0001, 0.001, 0.01, 0.1, 0.0, 1.0,\n",
       "                                   10.0, 100.0],\n",
       "                         &#x27;l1_ratio&#x27;: array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=RepeatedKFold(n_repeats=2, n_splits=5, random_state=1),\n",
       "             estimator=ElasticNet(alpha=0.1, l1_ratio=0.1), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [1e-05, 0.0001, 0.001, 0.01, 0.1, 0.0, 1.0,\n",
       "                                   10.0, 100.0],\n",
       "                         &#x27;l1_ratio&#x27;: array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet(alpha=0.1, l1_ratio=0.1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet(alpha=0.1, l1_ratio=0.1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=RepeatedKFold(n_repeats=2, n_splits=5, random_state=1),\n",
       "             estimator=ElasticNet(alpha=0.1, l1_ratio=0.1), n_jobs=-1,\n",
       "             param_grid={'alpha': [1e-05, 0.0001, 0.001, 0.01, 0.1, 0.0, 1.0,\n",
       "                                   10.0, 100.0],\n",
       "                         'l1_ratio': array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "67281b78-3d9c-4d1d-be54-7f484955b119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0, 'l1_ratio': 0.0}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e02b15f-0792-49f9-88d2-06ba84cecdf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
