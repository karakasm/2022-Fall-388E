{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras as ks\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation   \n",
    "from keras.datasets import mnist, fashion_mnist\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, LSTM, Embedding\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,  classification_report\n",
    "from sklearn.datasets import load_iris, load_digits, fetch_20newsgroups_vectorized, fetch_olivetti_faces\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATH388E Lecture 11\n",
    "\n",
    "## Newton-Raphson Method\n",
    "\n",
    "\n",
    "The [Newton-Raphson algorithm](https://en.wikipedia.org/wiki/Newton%27s_method) is an iterative algorithm to find roots of a function. The main idea is to find successively better approximations to the roots. In order to find the roots, the algorithm starts with a random guess and then using the tangent line to the graph gets a better approximation. Then we repeat the procedure until we get a good-enough solution.\n",
    "\n",
    "Consider the following simple problem: assume we have a real valued function $f(x)$ and we would like to solve the equation \n",
    "\n",
    "$$ f(x) = c $$\n",
    "\n",
    "for some constant $c$.  Let us also assume that we made a guess $f(x_0) = c$.  Of course, unless we are extremely lucky, we are not going to hit the result. So, there will be an error:\n",
    "\n",
    "$$ f(x_0) = c + \\delta $$\n",
    "\n",
    "Now, using this error, let us improve our guess:\n",
    "\n",
    "$$ f(x_0) - \\delta = c $$\n",
    "\n",
    "But we want $\\delta$ to effect $x_0$.  Assuming we have a *local inverse* we get\n",
    "\n",
    "$$ f^{-1}(f(x_0) - \\delta) = f^{-1}(c) = a $$\n",
    "\n",
    "where $a$ is the solution we need to find.  Now, let us write the first order Taylor approximation for the left hand side:\n",
    "\n",
    "$$ x_0 - (f^{-1})'(x_0) \\cdot \\delta \\approx a $$\n",
    "\n",
    "and we know that $(f^{-1})'(x_0) = \\frac{1}{f'(x_0)}$\n",
    "\n",
    "So, our next best guess is going to be\n",
    "\n",
    "$$ x_1 = x_0 - \\frac{\\delta}{f'(x_0)} $$\n",
    "\n",
    "If we convert this formula into an iterative approximation, we get\n",
    "\n",
    "$$ x_{n+1} = x_n - \\frac{\\delta_n}{f'(x_n)} $$\n",
    "\n",
    "where $\\delta_n = f(x_n) - c$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Solve(f, c, x0, eta=1e-2, n=10000):\n",
    "    for i in range(n):\n",
    "        delta = f(x0) - c\n",
    "        der = (f(x0+eta/2) - f(x0-eta/2))/eta\n",
    "        x1 = x0-delta/(der+eta*np.random.rand())\n",
    "        if(abs(x0-x1)<eta):\n",
    "            break\n",
    "        else: \n",
    "            x0 = x1\n",
    "    return([i,x1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn(x):\n",
    "    y = x*x\n",
    "    return(1.0 + math.cos(y+0.2)+math.log(0.24+y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 1.7734318154171977, 1.24]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Solve(fn,1.24,1.0,1e-10)\n",
    "[x[0],x[1],fn(x[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The gradient descent\n",
    "\n",
    "Next, consider the following problem: we have a multivariable function $F(x_1,\\ldots,x_n)$ that we want to optimize, i.e. find the point at which $F$ attains its minimum or maximum. There is an iterative algorithm called [steepest descent algorithm](https://ocw.mit.edu/courses/mathematics/18-409-topics-in-theoretical-computer-science-an-algorithmists-toolkit-fall-2009/lecture-notes/MIT18_409F09_scribe21.pdf) similar to Newton-Raphson that we can use to find this point. The algorithm uses the [gradient](https://inst.eecs.berkeley.edu/~ee127/sp21/livebook/def_gradient.html) of the function. Recall that the gradient $\\nabla F$ at a point $x$ \n",
    "\n",
    "$$ \\nabla F = \\left(\\frac{\\partial F}{\\partial x_1},\\ldots,\\frac{\\partial F}{\\partial x_n}\\right) $$\n",
    "\n",
    "gives us the direction at which $F$ has the largest (in absolute value) derivative. The algorithm uses this information and iteratively pushes an initial guess into better and better approximations of the optimum point.\n",
    "\n",
    "Let us start with an initial guess $a^{(0)}$ for $F(a_1^{(0)},\\ldots,a_n^{(0)}) = c$, the update rule is going to be\n",
    "\n",
    "$$ a^{(m+1)} = a^{(m)} - \\eta \\left(\\nabla F\\right)(a_1^{(m)},\\ldots,a_n^{(m)}) $$\n",
    "\n",
    "where $\\eta$ is called *the learning rate*.\n",
    "\n",
    "![](./images/steepest_descent.png)\n",
    "\n",
    "(Image is taken from [\"Learning-Based Auditory Encoding for Robust Speech Recognition\" by Yu-Hsiang Bosco Chiu, Bhiksha Raj, and Richard M Stern](https://www.researchgate.net/figure/An-example-of-steepest-descent-optimization-steps_fig2_220655581)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(f,x,eta=1e-4):\n",
    "    def delta(i,j): \n",
    "        if(i==j): return(1) \n",
    "        else: return(0)\n",
    "    def der(i,eta=1e-4):\n",
    "        vec = np.array([delta(i,j) for j in range(len(x))])\n",
    "        x1 = x + vec*eta/2\n",
    "        x0 = x - vec*eta/2\n",
    "        return((f(x1) - f(x0) + eta*np.random.rand())/eta)\n",
    "    return(np.array([der(i,eta) for i in range(len(x))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSolve(f,c,x0,eta=1e-4,n=1000):\n",
    "    for i in range(n):\n",
    "        delta = f(x0) - c\n",
    "        x1 = x0 - delta*eta*grad(f,x0,eta)\n",
    "        err = np.linalg.norm(x1-x0)\n",
    "        if(err < eta):\n",
    "            break\n",
    "        else:\n",
    "            x0 = x1\n",
    "    return([i,x1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, array([0.00109836, 0.00101397])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def g(x):\n",
    "    y = x[0]*x[0]+x[1]*x[1]\n",
    "    return(1.0+math.atan(y)+math.log(1.0+y))\n",
    "\n",
    "MSolve(g,3.0,[0.0,0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The perceptron\n",
    "\n",
    "\n",
    "Perceptrons are the main building blocks of artificial neural networks. They are designed to solve binary classification problems. They take a collection of input values $x = (x_1,\\ldots,x_n)$ apply a linear combination \n",
    "\n",
    "$$\\alpha\\cdot x + \\beta = a_1 x_1 + \\cdots + a_n x_n + \\beta$$ \n",
    "\n",
    "using a collection of weights $\\alpha = (a_0,\\ldots,a_n)$ and $\\beta$ to be determined via an iterative approach. Then we apply an activation function $\\varphi(x)$ to get an output which is either 0 or 1.\n",
    "\n",
    "![Perceptron](./images/perceptron.gif)\n",
    "\n",
    "([Source: Multilayer perceptrons from \"Nonlinear Switching State-Space Models\" by Antti Honkela](https://users.ics.aalto.fi/ahonkela/dippa/node41.html))\n",
    "\n",
    "\n",
    "This is a generalization of the [logistic regression](https://en.wikipedia.org/wiki/Logistic_regression) algorithm we covered in [Lecture 6](./lecture-06.ipynb) and [Lecture 7](./lecture-07.ipynb).  In the logistic regression case $\\varphi(x) = \\frac{1}{1+e^{-x}}$.  So, if we have a collection of data points $(x^{(i)},y^{(i)})$ that we assume satisfy a relationship of the form\n",
    "\n",
    "$$ y^{(i)} - \\varphi(\\alpha\\cdot x^{(i)} + \\beta) \\sim N(0,\\sigma) $$\n",
    "\n",
    "where $\\varphi\\colon\\mathbb{R}\\to\\mathbb{R}$ is a real valued function of a single variable, $\\alpha$ and $x^{(i)}$ are vectors in an inner product space and $\\beta$ is a scalar.  Our task is to find the best fitting pair $(\\alpha,\\beta)$ such that \n",
    "\n",
    "$$ \\sum_i (y^{(i)} - \\varphi(\\alpha\\cdot x^{(i)} + \\beta))^2 $$\n",
    "\n",
    "is minimized. So, we proceed by an iterative update:\n",
    "\n",
    "$$ \\alpha^{(n+1)} = \\alpha^{(n)} - \\frac{\\eta \\delta^{(n)}}{\\varphi'(\\alpha^{(n)}\\cdot x^{(n)}+\\beta^{(n)})} x^{(n)} $$\n",
    "\n",
    "where $\\delta^{(n)} = \\varphi(\\alpha^{(n)}\\cdot x^{(n)} + \\beta^{(n)}) - y^{(n)}$\n",
    "\n",
    "### Feed-forward and back-probagation\n",
    "\n",
    "In the feed-forward stage of the computation we calculate the output $\\varphi(\\alpha^{(n)}\\cdot x + \\beta^{(n)})$. In the back-probagation phase, we calculate the error $y - \\varphi(\\alpha^{(n)}\\cdot x + \\beta^{(n)})$ and adjust the weights as described above to obtain the next iteration of weights $(\\alpha^{(n+1)},\\beta^{(n+1)})$.\n",
    "\n",
    "### An example\n",
    "\n",
    "For this example, we are going to use a [toy dataset](http://archive.ics.uci.edu/ml/datasets/connectionist+bench+(sonar,+mines+vs.+rocks)) from UCI: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0956</td>\n",
       "      <td>0.1321</td>\n",
       "      <td>0.1408</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.3513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0548</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.1158</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.2838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.0962</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "5  0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
       "6  0.0317  0.0956  0.1321  0.1408  0.1674  0.1710  0.0731  0.1401  0.2083   \n",
       "7  0.0519  0.0548  0.0842  0.0319  0.1158  0.0922  0.1027  0.0613  0.1465   \n",
       "8  0.0223  0.0375  0.0484  0.0475  0.0647  0.0591  0.0753  0.0098  0.0684   \n",
       "9  0.0164  0.0173  0.0347  0.0070  0.0187  0.0671  0.1056  0.0697  0.0962   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "5  0.3039  ...  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057  0.0027   \n",
       "6  0.3513  ...  0.0201  0.0248  0.0131  0.0070  0.0138  0.0092  0.0143   \n",
       "7  0.2838  ...  0.0081  0.0120  0.0045  0.0121  0.0097  0.0085  0.0047   \n",
       "8  0.1487  ...  0.0145  0.0128  0.0145  0.0058  0.0049  0.0065  0.0093   \n",
       "9  0.0251  ...  0.0090  0.0223  0.0179  0.0084  0.0068  0.0032  0.0035   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "5  0.0051  0.0062   R  \n",
       "6  0.0036  0.0103   R  \n",
       "7  0.0048  0.0053   R  \n",
       "8  0.0059  0.0022   R  \n",
       "9  0.0056  0.0040   R  \n",
       "\n",
       "[10 rows x 61 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\",\n",
    "                    sep=\",\",\n",
    "                    header=None)\n",
    "sonar.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = sonar.iloc[:,0:60]\n",
    "ys = sonar.iloc[:,60].replace({'R': 0, 'M': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff(f,x,eta):\n",
    "    return((f(x+eta/2)-f(x-eta/2))/eta)\n",
    "\n",
    "def sigmoid(x): return(1.0/(1.0+math.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(xs, ys, f, epochs, batches, eta, tol):\n",
    "    n = len(xs.iloc[0,:])\n",
    "    num = len(xs)\n",
    "    w = np.random.rand(n+1)\n",
    "    err = []\n",
    "    temp = 0.0\n",
    "    for i in range(epochs):\n",
    "        j = np.random.randint(num)\n",
    "        x = xs.iloc[j,:]\n",
    "        y = ys[j]\n",
    "        x0 = np.append([1],x)\n",
    "        x1 = np.dot(w,x0)\n",
    "        delta = f(x1) - y\n",
    "        if(i%batches == batches-1):\n",
    "            err.append(temp)\n",
    "            temp = 0.0\n",
    "        elif(abs(delta) > tol):\n",
    "            temp = temp + 1.0/batches\n",
    "        der = diff(f,x1,eta)+eta*np.random.rand()\n",
    "        w = w - (der*delta*eta)*x0\n",
    "    return(ys,err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2ed53d4820>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_predict,errors = train(xs,ys,sigmoid,int(1e5),500,5e-1,0.45)\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 97,   0],\n",
       "       [  0, 111]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def helper(x,th=0.5):\n",
    "    if x>=th:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "tmp = np.vectorize(helper)(y_predict)\n",
    "confusion_matrix(ys,tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks\n",
    "\n",
    "While perceptrons are limited in their ability to learn complex non-linear relationships, they can be combined into more sophisticated architectures called [neural networks](https://en.wikipedia.org/wiki/Artificial_neural_network). Another way of saying would be a neural network is a directed computation graph of perceptrons:\n",
    "\n",
    "![](./images/neural-net.png)\n",
    "\n",
    "(Source: [Wikipedia](https://en.wikipedia.org/wiki/Artificial_neural_network))\n",
    "\n",
    "Neural networks are composed of multiple layers of interconnected perceptrons. Thus their weights form a sequence of matrices (a tensor) $(w^i_{j,k})$.  In the feedforward phase of the network,  where the input $(x^i_j)$ at some layer $i$ is processed by the network as\n",
    "\n",
    "$$ x^{i+1}_k = \\sum_j f^i_k(x^i_j w^i_{j,k}) $$\n",
    "\n",
    "where $f^i_k$ is the activation function at the neuron $k$ at level $i$. Again, as in the case of perceptron, when we get the output from the output layer, we calculate the error and then propagate the error back updating weights iteratively. This procedure is a variation of gradient descent algorithm we outlined above.\n",
    "\n",
    "There is a [very large number](http://www.asimovinstitute.org/neural-network-zoo/) of different types of neural networks. Unlike the perceptrons, it is neither practical nor recommended that you implement neural networks by hand. \n",
    "\n",
    "![](images/meme.jpg)\n",
    "\n",
    " I would suggest Use one of the following libraries or frameworks: \n",
    "\n",
    "1. [TensorFlow](https://www.tensorflow.org/)\n",
    "2. [Keras](https://keras.io/)\n",
    "3. [scikit-learn Neural Network](https://github.com/aigamedev/scikit-neuralnetwork)\n",
    "4. [The Microsoft Cognitive Toolkit](https://learn.microsoft.com/en-us/cognitive-toolkit/)\n",
    "5. [Theano](https://github.com/Theano/Theano)\n",
    "6. [MXNet](https://mxnet.apache.org/versions/1.9.1/)\n",
    "\n",
    "Tensorflow has a very nice [playground](https://playground.tensorflow.org/) where you can experiment with different architectures, activations functions etc. I highly recommend it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example \n",
    "\n",
    "All of todays examples are going to use the keras library. Let us start with the first example we used today, the sonar dataset. Let us construct a simple neural-net for binary classification, i.e. a perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid', input_dim=60))\n",
    "model.compile(optimizer='RMSprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6779 - binary_accuracy: 0.5517\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6700 - binary_accuracy: 0.5517\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6658 - binary_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6626 - binary_accuracy: 0.6207\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6603 - binary_accuracy: 0.6621\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6582 - binary_accuracy: 0.6690\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6572 - binary_accuracy: 0.6828\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6550 - binary_accuracy: 0.6828\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6538 - binary_accuracy: 0.6897\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6530 - binary_accuracy: 0.6621\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6514 - binary_accuracy: 0.6828\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6505 - binary_accuracy: 0.6897\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6499 - binary_accuracy: 0.6897\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6487 - binary_accuracy: 0.6759\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6478 - binary_accuracy: 0.6759\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6471 - binary_accuracy: 0.6897\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6461 - binary_accuracy: 0.7034\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6455 - binary_accuracy: 0.7034\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6445 - binary_accuracy: 0.7034\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6445 - binary_accuracy: 0.7172\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6438 - binary_accuracy: 0.7172\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6424 - binary_accuracy: 0.7103\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6418 - binary_accuracy: 0.7103\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6411 - binary_accuracy: 0.7172\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6414 - binary_accuracy: 0.7103\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6400 - binary_accuracy: 0.7103\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6394 - binary_accuracy: 0.7241\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6385 - binary_accuracy: 0.7103\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6381 - binary_accuracy: 0.7103\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6371 - binary_accuracy: 0.7103\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6364 - binary_accuracy: 0.7103\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6358 - binary_accuracy: 0.7103\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6351 - binary_accuracy: 0.7103\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6348 - binary_accuracy: 0.7172\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6337 - binary_accuracy: 0.7172\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6331 - binary_accuracy: 0.7172\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6323 - binary_accuracy: 0.7172\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6322 - binary_accuracy: 0.7034\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6310 - binary_accuracy: 0.7172\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6303 - binary_accuracy: 0.7103\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6297 - binary_accuracy: 0.7241\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6295 - binary_accuracy: 0.7034\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6283 - binary_accuracy: 0.7172\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6284 - binary_accuracy: 0.7241\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6275 - binary_accuracy: 0.7034\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6264 - binary_accuracy: 0.7103\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6258 - binary_accuracy: 0.7241\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6251 - binary_accuracy: 0.7103\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6246 - binary_accuracy: 0.7241\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6238 - binary_accuracy: 0.7241\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6232 - binary_accuracy: 0.7310\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6226 - binary_accuracy: 0.7172\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6219 - binary_accuracy: 0.7103\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6211 - binary_accuracy: 0.7241\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6208 - binary_accuracy: 0.7103\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6198 - binary_accuracy: 0.7241\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6192 - binary_accuracy: 0.7310\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6189 - binary_accuracy: 0.7241\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6181 - binary_accuracy: 0.7034\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6172 - binary_accuracy: 0.7448\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6164 - binary_accuracy: 0.7379\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6157 - binary_accuracy: 0.7379\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6153 - binary_accuracy: 0.7379\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6150 - binary_accuracy: 0.7379\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6138 - binary_accuracy: 0.7379\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6134 - binary_accuracy: 0.7310\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6125 - binary_accuracy: 0.7379\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6124 - binary_accuracy: 0.7379\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6115 - binary_accuracy: 0.7310\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6108 - binary_accuracy: 0.7448\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6100 - binary_accuracy: 0.7448\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6095 - binary_accuracy: 0.7448\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6087 - binary_accuracy: 0.7448\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6085 - binary_accuracy: 0.7448\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6077 - binary_accuracy: 0.7517\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6074 - binary_accuracy: 0.7448\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6063 - binary_accuracy: 0.7448\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6056 - binary_accuracy: 0.7448\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_accuracy: 0.7517\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6045 - binary_accuracy: 0.7517\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6039 - binary_accuracy: 0.7448\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6032 - binary_accuracy: 0.7448\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6025 - binary_accuracy: 0.7586\n",
      "Epoch 84/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6022 - binary_accuracy: 0.7379\n",
      "Epoch 85/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6016 - binary_accuracy: 0.7517\n",
      "Epoch 86/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6009 - binary_accuracy: 0.7586\n",
      "Epoch 87/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6010 - binary_accuracy: 0.7655\n",
      "Epoch 88/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5994 - binary_accuracy: 0.7655\n",
      "Epoch 89/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5989 - binary_accuracy: 0.7655\n",
      "Epoch 90/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5982 - binary_accuracy: 0.7655\n",
      "Epoch 91/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5985 - binary_accuracy: 0.7655\n",
      "Epoch 92/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5972 - binary_accuracy: 0.7655\n",
      "Epoch 93/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5976 - binary_accuracy: 0.7517\n",
      "Epoch 94/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5961 - binary_accuracy: 0.7655\n",
      "Epoch 95/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5958 - binary_accuracy: 0.7655\n",
      "Epoch 96/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5950 - binary_accuracy: 0.7655\n",
      "Epoch 97/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5959 - binary_accuracy: 0.7379\n",
      "Epoch 98/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5946 - binary_accuracy: 0.7586\n",
      "Epoch 99/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5938 - binary_accuracy: 0.7586\n",
      "Epoch 100/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5947 - binary_accuracy: 0.7655\n",
      "Epoch 101/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5927 - binary_accuracy: 0.7655\n",
      "Epoch 102/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5923 - binary_accuracy: 0.7586\n",
      "Epoch 103/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5919 - binary_accuracy: 0.7655\n",
      "Epoch 104/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5913 - binary_accuracy: 0.7586\n",
      "Epoch 105/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5909 - binary_accuracy: 0.7517\n",
      "Epoch 106/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5904 - binary_accuracy: 0.7586\n",
      "Epoch 107/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5900 - binary_accuracy: 0.7517\n",
      "Epoch 108/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5893 - binary_accuracy: 0.7586\n",
      "Epoch 109/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5891 - binary_accuracy: 0.7586\n",
      "Epoch 110/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5883 - binary_accuracy: 0.7586\n",
      "Epoch 111/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5877 - binary_accuracy: 0.7586\n",
      "Epoch 112/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5871 - binary_accuracy: 0.7586\n",
      "Epoch 113/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5866 - binary_accuracy: 0.7517\n",
      "Epoch 114/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5860 - binary_accuracy: 0.7586\n",
      "Epoch 115/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5853 - binary_accuracy: 0.7586\n",
      "Epoch 116/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5848 - binary_accuracy: 0.7586\n",
      "Epoch 117/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5843 - binary_accuracy: 0.7586\n",
      "Epoch 118/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5838 - binary_accuracy: 0.7517\n",
      "Epoch 119/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5829 - binary_accuracy: 0.7586\n",
      "Epoch 120/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5824 - binary_accuracy: 0.7586\n",
      "Epoch 121/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5817 - binary_accuracy: 0.7517\n",
      "Epoch 122/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5823 - binary_accuracy: 0.7586\n",
      "Epoch 123/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5809 - binary_accuracy: 0.7517\n",
      "Epoch 124/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5801 - binary_accuracy: 0.7586\n",
      "Epoch 125/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5796 - binary_accuracy: 0.7586\n",
      "Epoch 126/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5793 - binary_accuracy: 0.7517\n",
      "Epoch 127/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5786 - binary_accuracy: 0.7655\n",
      "Epoch 128/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5782 - binary_accuracy: 0.7586\n",
      "Epoch 129/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5774 - binary_accuracy: 0.7586\n",
      "Epoch 130/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5768 - binary_accuracy: 0.7655\n",
      "Epoch 131/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5765 - binary_accuracy: 0.7586\n",
      "Epoch 132/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5759 - binary_accuracy: 0.7517\n",
      "Epoch 133/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5753 - binary_accuracy: 0.7586\n",
      "Epoch 134/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5747 - binary_accuracy: 0.7655\n",
      "Epoch 135/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5741 - binary_accuracy: 0.7586\n",
      "Epoch 136/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5737 - binary_accuracy: 0.7517\n",
      "Epoch 137/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5730 - binary_accuracy: 0.7586\n",
      "Epoch 138/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5724 - binary_accuracy: 0.7586\n",
      "Epoch 139/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5717 - binary_accuracy: 0.7517\n",
      "Epoch 140/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5712 - binary_accuracy: 0.7586\n",
      "Epoch 141/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5707 - binary_accuracy: 0.7517\n",
      "Epoch 142/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5700 - binary_accuracy: 0.7586\n",
      "Epoch 143/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5694 - binary_accuracy: 0.7517\n",
      "Epoch 144/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5692 - binary_accuracy: 0.7655\n",
      "Epoch 145/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5683 - binary_accuracy: 0.7655\n",
      "Epoch 146/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5677 - binary_accuracy: 0.7655\n",
      "Epoch 147/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5673 - binary_accuracy: 0.7655\n",
      "Epoch 148/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5670 - binary_accuracy: 0.7586\n",
      "Epoch 149/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5663 - binary_accuracy: 0.7655\n",
      "Epoch 150/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5661 - binary_accuracy: 0.7586\n",
      "Epoch 151/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5651 - binary_accuracy: 0.7793\n",
      "Epoch 152/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5648 - binary_accuracy: 0.7793\n",
      "Epoch 153/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5644 - binary_accuracy: 0.7586\n",
      "Epoch 154/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5642 - binary_accuracy: 0.7793\n",
      "Epoch 155/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5632 - binary_accuracy: 0.7724\n",
      "Epoch 156/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5634 - binary_accuracy: 0.7586\n",
      "Epoch 157/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5626 - binary_accuracy: 0.7793\n",
      "Epoch 158/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5623 - binary_accuracy: 0.7724\n",
      "Epoch 159/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5614 - binary_accuracy: 0.7724\n",
      "Epoch 160/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5611 - binary_accuracy: 0.7724\n",
      "Epoch 161/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5605 - binary_accuracy: 0.7724\n",
      "Epoch 162/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5609 - binary_accuracy: 0.7655\n",
      "Epoch 163/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5597 - binary_accuracy: 0.7724\n",
      "Epoch 164/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5598 - binary_accuracy: 0.7724\n",
      "Epoch 165/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5588 - binary_accuracy: 0.7724\n",
      "Epoch 166/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5588 - binary_accuracy: 0.7655\n",
      "Epoch 167/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5579 - binary_accuracy: 0.7724\n",
      "Epoch 168/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5584 - binary_accuracy: 0.7724\n",
      "Epoch 169/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5573 - binary_accuracy: 0.7724\n",
      "Epoch 170/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5570 - binary_accuracy: 0.7793\n",
      "Epoch 171/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5565 - binary_accuracy: 0.7724\n",
      "Epoch 172/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5558 - binary_accuracy: 0.7724\n",
      "Epoch 173/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5554 - binary_accuracy: 0.7724\n",
      "Epoch 174/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5549 - binary_accuracy: 0.7655\n",
      "Epoch 175/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5551 - binary_accuracy: 0.7724\n",
      "Epoch 176/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5541 - binary_accuracy: 0.7655\n",
      "Epoch 177/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5536 - binary_accuracy: 0.7655\n",
      "Epoch 178/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5531 - binary_accuracy: 0.7655\n",
      "Epoch 179/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5526 - binary_accuracy: 0.7655\n",
      "Epoch 180/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5523 - binary_accuracy: 0.7724\n",
      "Epoch 181/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5521 - binary_accuracy: 0.7724\n",
      "Epoch 182/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5513 - binary_accuracy: 0.7655\n",
      "Epoch 183/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5507 - binary_accuracy: 0.7655\n",
      "Epoch 184/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5502 - binary_accuracy: 0.7655\n",
      "Epoch 185/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5498 - binary_accuracy: 0.7655\n",
      "Epoch 186/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5492 - binary_accuracy: 0.7655\n",
      "Epoch 187/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5491 - binary_accuracy: 0.7655\n",
      "Epoch 188/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5482 - binary_accuracy: 0.7655\n",
      "Epoch 189/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5479 - binary_accuracy: 0.7724\n",
      "Epoch 190/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5476 - binary_accuracy: 0.7655\n",
      "Epoch 191/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5468 - binary_accuracy: 0.7655\n",
      "Epoch 192/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5467 - binary_accuracy: 0.7724\n",
      "Epoch 193/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5460 - binary_accuracy: 0.7655\n",
      "Epoch 194/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5467 - binary_accuracy: 0.7655\n",
      "Epoch 195/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5451 - binary_accuracy: 0.7655\n",
      "Epoch 196/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5468 - binary_accuracy: 0.7586\n",
      "Epoch 197/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5444 - binary_accuracy: 0.7655\n",
      "Epoch 198/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5445 - binary_accuracy: 0.7655\n",
      "Epoch 199/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5438 - binary_accuracy: 0.7655\n",
      "Epoch 200/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5433 - binary_accuracy: 0.7655\n",
      "Epoch 201/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5429 - binary_accuracy: 0.7655\n",
      "Epoch 202/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5427 - binary_accuracy: 0.7655\n",
      "Epoch 203/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5424 - binary_accuracy: 0.7655\n",
      "Epoch 204/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5418 - binary_accuracy: 0.7655\n",
      "Epoch 205/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5413 - binary_accuracy: 0.7655\n",
      "Epoch 206/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5420 - binary_accuracy: 0.7724\n",
      "Epoch 207/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5406 - binary_accuracy: 0.7724\n",
      "Epoch 208/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5401 - binary_accuracy: 0.7724\n",
      "Epoch 209/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5405 - binary_accuracy: 0.7724\n",
      "Epoch 210/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5398 - binary_accuracy: 0.7724\n",
      "Epoch 211/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5390 - binary_accuracy: 0.7724\n",
      "Epoch 212/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5386 - binary_accuracy: 0.7655\n",
      "Epoch 213/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5382 - binary_accuracy: 0.7724\n",
      "Epoch 214/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5379 - binary_accuracy: 0.7724\n",
      "Epoch 215/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5380 - binary_accuracy: 0.7724\n",
      "Epoch 216/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5370 - binary_accuracy: 0.7793\n",
      "Epoch 217/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5366 - binary_accuracy: 0.7655\n",
      "Epoch 218/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5363 - binary_accuracy: 0.7793\n",
      "Epoch 219/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5363 - binary_accuracy: 0.7655\n",
      "Epoch 220/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5357 - binary_accuracy: 0.7793\n",
      "Epoch 221/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5363 - binary_accuracy: 0.7655\n",
      "Epoch 222/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5348 - binary_accuracy: 0.7724\n",
      "Epoch 223/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5343 - binary_accuracy: 0.7724\n",
      "Epoch 224/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5341 - binary_accuracy: 0.7862\n",
      "Epoch 225/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5338 - binary_accuracy: 0.7724\n",
      "Epoch 226/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5333 - binary_accuracy: 0.7724\n",
      "Epoch 227/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5329 - binary_accuracy: 0.7724\n",
      "Epoch 228/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5326 - binary_accuracy: 0.7793\n",
      "Epoch 229/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5322 - binary_accuracy: 0.7724\n",
      "Epoch 230/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5332 - binary_accuracy: 0.7862\n",
      "Epoch 231/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5313 - binary_accuracy: 0.7724\n",
      "Epoch 232/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5310 - binary_accuracy: 0.7724\n",
      "Epoch 233/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5306 - binary_accuracy: 0.7724\n",
      "Epoch 234/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5303 - binary_accuracy: 0.7724\n",
      "Epoch 235/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5301 - binary_accuracy: 0.7724\n",
      "Epoch 236/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5296 - binary_accuracy: 0.7724\n",
      "Epoch 237/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5307 - binary_accuracy: 0.7655\n",
      "Epoch 238/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5288 - binary_accuracy: 0.7724\n",
      "Epoch 239/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5289 - binary_accuracy: 0.7724\n",
      "Epoch 240/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5282 - binary_accuracy: 0.7724\n",
      "Epoch 241/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5278 - binary_accuracy: 0.7724\n",
      "Epoch 242/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5274 - binary_accuracy: 0.7724\n",
      "Epoch 243/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5270 - binary_accuracy: 0.7724\n",
      "Epoch 244/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5268 - binary_accuracy: 0.7724\n",
      "Epoch 245/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5273 - binary_accuracy: 0.7793\n",
      "Epoch 246/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5259 - binary_accuracy: 0.7724\n",
      "Epoch 247/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5261 - binary_accuracy: 0.7793\n",
      "Epoch 248/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5258 - binary_accuracy: 0.7793\n",
      "Epoch 249/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5250 - binary_accuracy: 0.7724\n",
      "Epoch 250/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5248 - binary_accuracy: 0.7724\n",
      "Epoch 251/1000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5243 - binary_accuracy: 0.7724\n",
      "Epoch 252/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5239 - binary_accuracy: 0.7724\n",
      "Epoch 253/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5235 - binary_accuracy: 0.7724\n",
      "Epoch 254/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5232 - binary_accuracy: 0.7724\n",
      "Epoch 255/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5231 - binary_accuracy: 0.7793\n",
      "Epoch 256/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5223 - binary_accuracy: 0.7724\n",
      "Epoch 257/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5222 - binary_accuracy: 0.7724\n",
      "Epoch 258/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5215 - binary_accuracy: 0.7724\n",
      "Epoch 259/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5217 - binary_accuracy: 0.7724\n",
      "Epoch 260/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5208 - binary_accuracy: 0.7724\n",
      "Epoch 261/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5209 - binary_accuracy: 0.7862\n",
      "Epoch 262/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5202 - binary_accuracy: 0.7724\n",
      "Epoch 263/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5205 - binary_accuracy: 0.7793\n",
      "Epoch 264/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5193 - binary_accuracy: 0.7724\n",
      "Epoch 265/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5208 - binary_accuracy: 0.7793\n",
      "Epoch 266/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5188 - binary_accuracy: 0.7724\n",
      "Epoch 267/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5188 - binary_accuracy: 0.7724\n",
      "Epoch 268/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5183 - binary_accuracy: 0.7724\n",
      "Epoch 269/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5182 - binary_accuracy: 0.7724\n",
      "Epoch 270/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5175 - binary_accuracy: 0.7724\n",
      "Epoch 271/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5173 - binary_accuracy: 0.7724\n",
      "Epoch 272/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5170 - binary_accuracy: 0.7724\n",
      "Epoch 273/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5171 - binary_accuracy: 0.7724\n",
      "Epoch 274/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5163 - binary_accuracy: 0.7724\n",
      "Epoch 275/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5159 - binary_accuracy: 0.7724\n",
      "Epoch 276/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5156 - binary_accuracy: 0.7724\n",
      "Epoch 277/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5153 - binary_accuracy: 0.7724\n",
      "Epoch 278/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5151 - binary_accuracy: 0.7793\n",
      "Epoch 279/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5144 - binary_accuracy: 0.7724\n",
      "Epoch 280/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5140 - binary_accuracy: 0.7724\n",
      "Epoch 281/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5137 - binary_accuracy: 0.7724\n",
      "Epoch 282/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5163 - binary_accuracy: 0.7793\n",
      "Epoch 283/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5131 - binary_accuracy: 0.7724\n",
      "Epoch 284/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5130 - binary_accuracy: 0.7724\n",
      "Epoch 285/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5128 - binary_accuracy: 0.7724\n",
      "Epoch 286/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5123 - binary_accuracy: 0.7724\n",
      "Epoch 287/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5120 - binary_accuracy: 0.7724\n",
      "Epoch 288/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5122 - binary_accuracy: 0.7862\n",
      "Epoch 289/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5121 - binary_accuracy: 0.7724\n",
      "Epoch 290/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5111 - binary_accuracy: 0.7724\n",
      "Epoch 291/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5111 - binary_accuracy: 0.7793\n",
      "Epoch 292/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5107 - binary_accuracy: 0.7724\n",
      "Epoch 293/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5103 - binary_accuracy: 0.7724\n",
      "Epoch 294/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5099 - binary_accuracy: 0.7724\n",
      "Epoch 295/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5096 - binary_accuracy: 0.7724\n",
      "Epoch 296/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5098 - binary_accuracy: 0.7862\n",
      "Epoch 297/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5091 - binary_accuracy: 0.7793\n",
      "Epoch 298/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5087 - binary_accuracy: 0.7724\n",
      "Epoch 299/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5083 - binary_accuracy: 0.7724\n",
      "Epoch 300/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5084 - binary_accuracy: 0.7724\n",
      "Epoch 301/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5081 - binary_accuracy: 0.7724\n",
      "Epoch 302/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5073 - binary_accuracy: 0.7724\n",
      "Epoch 303/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5071 - binary_accuracy: 0.7724\n",
      "Epoch 304/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5067 - binary_accuracy: 0.7862\n",
      "Epoch 305/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5064 - binary_accuracy: 0.7793\n",
      "Epoch 306/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5060 - binary_accuracy: 0.7724\n",
      "Epoch 307/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5058 - binary_accuracy: 0.7724\n",
      "Epoch 308/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5057 - binary_accuracy: 0.7793\n",
      "Epoch 309/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5050 - binary_accuracy: 0.7862\n",
      "Epoch 310/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5052 - binary_accuracy: 0.7793\n",
      "Epoch 311/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5044 - binary_accuracy: 0.7793\n",
      "Epoch 312/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5054 - binary_accuracy: 0.7862\n",
      "Epoch 313/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5040 - binary_accuracy: 0.7793\n",
      "Epoch 314/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5035 - binary_accuracy: 0.7724\n",
      "Epoch 315/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5038 - binary_accuracy: 0.7655\n",
      "Epoch 316/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5035 - binary_accuracy: 0.7724\n",
      "Epoch 317/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5030 - binary_accuracy: 0.7724\n",
      "Epoch 318/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5026 - binary_accuracy: 0.7793\n",
      "Epoch 319/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5025 - binary_accuracy: 0.7724\n",
      "Epoch 320/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5021 - binary_accuracy: 0.7724\n",
      "Epoch 321/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5018 - binary_accuracy: 0.7862\n",
      "Epoch 322/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5015 - binary_accuracy: 0.7724\n",
      "Epoch 323/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5018 - binary_accuracy: 0.7862\n",
      "Epoch 324/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5008 - binary_accuracy: 0.7793\n",
      "Epoch 325/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5007 - binary_accuracy: 0.7862\n",
      "Epoch 326/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5003 - binary_accuracy: 0.7862\n",
      "Epoch 327/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5000 - binary_accuracy: 0.7862\n",
      "Epoch 328/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4998 - binary_accuracy: 0.7862\n",
      "Epoch 329/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4996 - binary_accuracy: 0.7793\n",
      "Epoch 330/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4993 - binary_accuracy: 0.7931\n",
      "Epoch 331/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4991 - binary_accuracy: 0.7793\n",
      "Epoch 332/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4986 - binary_accuracy: 0.7793\n",
      "Epoch 333/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4985 - binary_accuracy: 0.7793\n",
      "Epoch 334/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4979 - binary_accuracy: 0.7862\n",
      "Epoch 335/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4978 - binary_accuracy: 0.7793\n",
      "Epoch 336/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4973 - binary_accuracy: 0.7862\n",
      "Epoch 337/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4969 - binary_accuracy: 0.7862\n",
      "Epoch 338/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4967 - binary_accuracy: 0.7931\n",
      "Epoch 339/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4964 - binary_accuracy: 0.8000\n",
      "Epoch 340/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4966 - binary_accuracy: 0.7862\n",
      "Epoch 341/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4958 - binary_accuracy: 0.7931\n",
      "Epoch 342/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4954 - binary_accuracy: 0.8000\n",
      "Epoch 343/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4950 - binary_accuracy: 0.8000\n",
      "Epoch 344/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4958 - binary_accuracy: 0.7724\n",
      "Epoch 345/1000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4945 - binary_accuracy: 0.8000\n",
      "Epoch 346/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4942 - binary_accuracy: 0.7931\n",
      "Epoch 347/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4940 - binary_accuracy: 0.7931\n",
      "Epoch 348/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4943 - binary_accuracy: 0.7931\n",
      "Epoch 349/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4935 - binary_accuracy: 0.8000\n",
      "Epoch 350/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4932 - binary_accuracy: 0.7931\n",
      "Epoch 351/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4928 - binary_accuracy: 0.7862\n",
      "Epoch 352/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4925 - binary_accuracy: 0.8000\n",
      "Epoch 353/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4922 - binary_accuracy: 0.7931\n",
      "Epoch 354/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4919 - binary_accuracy: 0.7931\n",
      "Epoch 355/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4916 - binary_accuracy: 0.8000\n",
      "Epoch 356/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4915 - binary_accuracy: 0.7931\n",
      "Epoch 357/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4910 - binary_accuracy: 0.7931\n",
      "Epoch 358/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4914 - binary_accuracy: 0.7931\n",
      "Epoch 359/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4904 - binary_accuracy: 0.7931\n",
      "Epoch 360/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4900 - binary_accuracy: 0.8000\n",
      "Epoch 361/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4898 - binary_accuracy: 0.7793\n",
      "Epoch 362/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4904 - binary_accuracy: 0.7862\n",
      "Epoch 363/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4892 - binary_accuracy: 0.7931\n",
      "Epoch 364/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4889 - binary_accuracy: 0.8000\n",
      "Epoch 365/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4886 - binary_accuracy: 0.7931\n",
      "Epoch 366/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4883 - binary_accuracy: 0.7931\n",
      "Epoch 367/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4880 - binary_accuracy: 0.7931\n",
      "Epoch 368/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4878 - binary_accuracy: 0.7931\n",
      "Epoch 369/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4882 - binary_accuracy: 0.7931\n",
      "Epoch 370/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4876 - binary_accuracy: 0.8000\n",
      "Epoch 371/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4869 - binary_accuracy: 0.7862\n",
      "Epoch 372/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4869 - binary_accuracy: 0.7793\n",
      "Epoch 373/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4868 - binary_accuracy: 0.7793\n",
      "Epoch 374/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4861 - binary_accuracy: 0.8000\n",
      "Epoch 375/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4859 - binary_accuracy: 0.7862\n",
      "Epoch 376/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4855 - binary_accuracy: 0.7931\n",
      "Epoch 377/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4859 - binary_accuracy: 0.8000\n",
      "Epoch 378/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4850 - binary_accuracy: 0.7862\n",
      "Epoch 379/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4853 - binary_accuracy: 0.7931\n",
      "Epoch 380/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4849 - binary_accuracy: 0.7862\n",
      "Epoch 381/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4843 - binary_accuracy: 0.8000\n",
      "Epoch 382/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4846 - binary_accuracy: 0.8000\n",
      "Epoch 383/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4839 - binary_accuracy: 0.8000\n",
      "Epoch 384/1000\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4835 - binary_accuracy: 0.7931\n",
      "Epoch 385/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4833 - binary_accuracy: 0.8000\n",
      "Epoch 386/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4831 - binary_accuracy: 0.8000\n",
      "Epoch 387/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4828 - binary_accuracy: 0.7931\n",
      "Epoch 388/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4827 - binary_accuracy: 0.7931\n",
      "Epoch 389/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4825 - binary_accuracy: 0.7931\n",
      "Epoch 390/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4820 - binary_accuracy: 0.8000\n",
      "Epoch 391/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4816 - binary_accuracy: 0.8000\n",
      "Epoch 392/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4818 - binary_accuracy: 0.7931\n",
      "Epoch 393/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4814 - binary_accuracy: 0.8069\n",
      "Epoch 394/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4810 - binary_accuracy: 0.8000\n",
      "Epoch 395/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4809 - binary_accuracy: 0.8000\n",
      "Epoch 396/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4807 - binary_accuracy: 0.8000\n",
      "Epoch 397/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4801 - binary_accuracy: 0.8000\n",
      "Epoch 398/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4800 - binary_accuracy: 0.7931\n",
      "Epoch 399/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4796 - binary_accuracy: 0.8000\n",
      "Epoch 400/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4796 - binary_accuracy: 0.7931\n",
      "Epoch 401/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4791 - binary_accuracy: 0.8000\n",
      "Epoch 402/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4797 - binary_accuracy: 0.8069\n",
      "Epoch 403/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4791 - binary_accuracy: 0.7931\n",
      "Epoch 404/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4783 - binary_accuracy: 0.8000\n",
      "Epoch 405/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4780 - binary_accuracy: 0.8000\n",
      "Epoch 406/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4778 - binary_accuracy: 0.8000\n",
      "Epoch 407/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4776 - binary_accuracy: 0.8000\n",
      "Epoch 408/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4786 - binary_accuracy: 0.7931\n",
      "Epoch 409/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4776 - binary_accuracy: 0.8000\n",
      "Epoch 410/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4769 - binary_accuracy: 0.8000\n",
      "Epoch 411/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4768 - binary_accuracy: 0.8000\n",
      "Epoch 412/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4766 - binary_accuracy: 0.8000\n",
      "Epoch 413/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4765 - binary_accuracy: 0.8069\n",
      "Epoch 414/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4760 - binary_accuracy: 0.8000\n",
      "Epoch 415/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4758 - binary_accuracy: 0.8000\n",
      "Epoch 416/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4762 - binary_accuracy: 0.8000\n",
      "Epoch 417/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4754 - binary_accuracy: 0.8000\n",
      "Epoch 418/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4754 - binary_accuracy: 0.8000\n",
      "Epoch 419/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4748 - binary_accuracy: 0.8000\n",
      "Epoch 420/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4749 - binary_accuracy: 0.8000\n",
      "Epoch 421/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4745 - binary_accuracy: 0.8000\n",
      "Epoch 422/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4743 - binary_accuracy: 0.8069\n",
      "Epoch 423/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4740 - binary_accuracy: 0.8069\n",
      "Epoch 424/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4741 - binary_accuracy: 0.8069\n",
      "Epoch 425/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4737 - binary_accuracy: 0.8069\n",
      "Epoch 426/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4735 - binary_accuracy: 0.8069\n",
      "Epoch 427/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4730 - binary_accuracy: 0.8069\n",
      "Epoch 428/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4728 - binary_accuracy: 0.8069\n",
      "Epoch 429/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4726 - binary_accuracy: 0.8069\n",
      "Epoch 430/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4726 - binary_accuracy: 0.8069\n",
      "Epoch 431/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4721 - binary_accuracy: 0.8069\n",
      "Epoch 432/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4718 - binary_accuracy: 0.8069\n",
      "Epoch 433/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4718 - binary_accuracy: 0.8069\n",
      "Epoch 434/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4721 - binary_accuracy: 0.8069\n",
      "Epoch 435/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4712 - binary_accuracy: 0.8069\n",
      "Epoch 436/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4710 - binary_accuracy: 0.8069\n",
      "Epoch 437/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4708 - binary_accuracy: 0.8069\n",
      "Epoch 438/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4705 - binary_accuracy: 0.8069\n",
      "Epoch 439/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4720 - binary_accuracy: 0.8138\n",
      "Epoch 440/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4702 - binary_accuracy: 0.8069\n",
      "Epoch 441/1000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4700 - binary_accuracy: 0.8069\n",
      "Epoch 442/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4700 - binary_accuracy: 0.8069\n",
      "Epoch 443/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4695 - binary_accuracy: 0.8069\n",
      "Epoch 444/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4694 - binary_accuracy: 0.8069\n",
      "Epoch 445/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4691 - binary_accuracy: 0.8069\n",
      "Epoch 446/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4689 - binary_accuracy: 0.8069\n",
      "Epoch 447/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4686 - binary_accuracy: 0.8069\n",
      "Epoch 448/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4691 - binary_accuracy: 0.8069\n",
      "Epoch 449/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4682 - binary_accuracy: 0.8069\n",
      "Epoch 450/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4679 - binary_accuracy: 0.8069\n",
      "Epoch 451/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4677 - binary_accuracy: 0.8069\n",
      "Epoch 452/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4679 - binary_accuracy: 0.8069\n",
      "Epoch 453/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4673 - binary_accuracy: 0.8069\n",
      "Epoch 454/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4670 - binary_accuracy: 0.8069\n",
      "Epoch 455/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4669 - binary_accuracy: 0.8069\n",
      "Epoch 456/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4665 - binary_accuracy: 0.8069\n",
      "Epoch 457/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4670 - binary_accuracy: 0.8069\n",
      "Epoch 458/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4661 - binary_accuracy: 0.8069\n",
      "Epoch 459/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4660 - binary_accuracy: 0.8069\n",
      "Epoch 460/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4659 - binary_accuracy: 0.8069\n",
      "Epoch 461/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4658 - binary_accuracy: 0.8069\n",
      "Epoch 462/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4653 - binary_accuracy: 0.8069\n",
      "Epoch 463/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4650 - binary_accuracy: 0.8069\n",
      "Epoch 464/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4653 - binary_accuracy: 0.8069\n",
      "Epoch 465/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4648 - binary_accuracy: 0.8069\n",
      "Epoch 466/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4645 - binary_accuracy: 0.8069\n",
      "Epoch 467/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4646 - binary_accuracy: 0.8069\n",
      "Epoch 468/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4640 - binary_accuracy: 0.8069\n",
      "Epoch 469/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4638 - binary_accuracy: 0.8069\n",
      "Epoch 470/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4636 - binary_accuracy: 0.8069\n",
      "Epoch 471/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4636 - binary_accuracy: 0.8069\n",
      "Epoch 472/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4631 - binary_accuracy: 0.8069\n",
      "Epoch 473/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4629 - binary_accuracy: 0.8069\n",
      "Epoch 474/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4627 - binary_accuracy: 0.8000\n",
      "Epoch 475/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4629 - binary_accuracy: 0.8000\n",
      "Epoch 476/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4622 - binary_accuracy: 0.8069\n",
      "Epoch 477/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4620 - binary_accuracy: 0.8069\n",
      "Epoch 478/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4619 - binary_accuracy: 0.8069\n",
      "Epoch 479/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4616 - binary_accuracy: 0.8000\n",
      "Epoch 480/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4613 - binary_accuracy: 0.8069\n",
      "Epoch 481/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4612 - binary_accuracy: 0.8069\n",
      "Epoch 482/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4615 - binary_accuracy: 0.8138\n",
      "Epoch 483/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4610 - binary_accuracy: 0.8069\n",
      "Epoch 484/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4609 - binary_accuracy: 0.8000\n",
      "Epoch 485/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4603 - binary_accuracy: 0.8069\n",
      "Epoch 486/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4600 - binary_accuracy: 0.8069\n",
      "Epoch 487/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4599 - binary_accuracy: 0.8000\n",
      "Epoch 488/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4598 - binary_accuracy: 0.8000\n",
      "Epoch 489/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4594 - binary_accuracy: 0.8069\n",
      "Epoch 490/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4598 - binary_accuracy: 0.8000\n",
      "Epoch 491/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4590 - binary_accuracy: 0.8000\n",
      "Epoch 492/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4592 - binary_accuracy: 0.8000\n",
      "Epoch 493/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4589 - binary_accuracy: 0.8000\n",
      "Epoch 494/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4584 - binary_accuracy: 0.8000\n",
      "Epoch 495/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4585 - binary_accuracy: 0.8069\n",
      "Epoch 496/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4580 - binary_accuracy: 0.8000\n",
      "Epoch 497/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4578 - binary_accuracy: 0.8000\n",
      "Epoch 498/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4577 - binary_accuracy: 0.8000\n",
      "Epoch 499/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4574 - binary_accuracy: 0.8000\n",
      "Epoch 500/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4572 - binary_accuracy: 0.8000\n",
      "Epoch 501/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4574 - binary_accuracy: 0.8069\n",
      "Epoch 502/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4567 - binary_accuracy: 0.8000\n",
      "Epoch 503/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4569 - binary_accuracy: 0.8000\n",
      "Epoch 504/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4565 - binary_accuracy: 0.8000\n",
      "Epoch 505/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4561 - binary_accuracy: 0.8000\n",
      "Epoch 506/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4559 - binary_accuracy: 0.8000\n",
      "Epoch 507/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4557 - binary_accuracy: 0.8000\n",
      "Epoch 508/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4560 - binary_accuracy: 0.7931\n",
      "Epoch 509/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4553 - binary_accuracy: 0.8000\n",
      "Epoch 510/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4553 - binary_accuracy: 0.8000\n",
      "Epoch 511/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4554 - binary_accuracy: 0.8000\n",
      "Epoch 512/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4551 - binary_accuracy: 0.8000\n",
      "Epoch 513/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4555 - binary_accuracy: 0.8000\n",
      "Epoch 514/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4543 - binary_accuracy: 0.8000\n",
      "Epoch 515/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4541 - binary_accuracy: 0.8000\n",
      "Epoch 516/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4540 - binary_accuracy: 0.8000\n",
      "Epoch 517/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4538 - binary_accuracy: 0.8000\n",
      "Epoch 518/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4537 - binary_accuracy: 0.8000\n",
      "Epoch 519/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4534 - binary_accuracy: 0.8000\n",
      "Epoch 520/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4533 - binary_accuracy: 0.8000\n",
      "Epoch 521/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4531 - binary_accuracy: 0.8000\n",
      "Epoch 522/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4533 - binary_accuracy: 0.8069\n",
      "Epoch 523/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4526 - binary_accuracy: 0.8000\n",
      "Epoch 524/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4531 - binary_accuracy: 0.8000\n",
      "Epoch 525/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4527 - binary_accuracy: 0.8000\n",
      "Epoch 526/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4523 - binary_accuracy: 0.8000\n",
      "Epoch 527/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4519 - binary_accuracy: 0.8000\n",
      "Epoch 528/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4528 - binary_accuracy: 0.7931\n",
      "Epoch 529/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4515 - binary_accuracy: 0.8000\n",
      "Epoch 530/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4515 - binary_accuracy: 0.8000\n",
      "Epoch 531/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4512 - binary_accuracy: 0.8000\n",
      "Epoch 532/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4520 - binary_accuracy: 0.8069\n",
      "Epoch 533/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4509 - binary_accuracy: 0.8000\n",
      "Epoch 534/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4508 - binary_accuracy: 0.8000\n",
      "Epoch 535/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4507 - binary_accuracy: 0.7931\n",
      "Epoch 536/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4504 - binary_accuracy: 0.8000\n",
      "Epoch 537/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4502 - binary_accuracy: 0.8000\n",
      "Epoch 538/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4501 - binary_accuracy: 0.8000\n",
      "Epoch 539/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4503 - binary_accuracy: 0.8000\n",
      "Epoch 540/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4497 - binary_accuracy: 0.8000\n",
      "Epoch 541/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4495 - binary_accuracy: 0.8000\n",
      "Epoch 542/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4496 - binary_accuracy: 0.8000\n",
      "Epoch 543/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4491 - binary_accuracy: 0.8000\n",
      "Epoch 544/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4489 - binary_accuracy: 0.8000\n",
      "Epoch 545/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4496 - binary_accuracy: 0.7931\n",
      "Epoch 546/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4486 - binary_accuracy: 0.8000\n",
      "Epoch 547/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4484 - binary_accuracy: 0.7931\n",
      "Epoch 548/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4483 - binary_accuracy: 0.8000\n",
      "Epoch 549/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4480 - binary_accuracy: 0.7931\n",
      "Epoch 550/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4480 - binary_accuracy: 0.8000\n",
      "Epoch 551/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4476 - binary_accuracy: 0.8000\n",
      "Epoch 552/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4486 - binary_accuracy: 0.7931\n",
      "Epoch 553/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4473 - binary_accuracy: 0.8000\n",
      "Epoch 554/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4471 - binary_accuracy: 0.8000\n",
      "Epoch 555/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4470 - binary_accuracy: 0.8000\n",
      "Epoch 556/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4468 - binary_accuracy: 0.8000\n",
      "Epoch 557/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4467 - binary_accuracy: 0.7931\n",
      "Epoch 558/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4465 - binary_accuracy: 0.7931\n",
      "Epoch 559/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4466 - binary_accuracy: 0.8000\n",
      "Epoch 560/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4461 - binary_accuracy: 0.8000\n",
      "Epoch 561/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4459 - binary_accuracy: 0.8000\n",
      "Epoch 562/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4457 - binary_accuracy: 0.7931\n",
      "Epoch 563/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4457 - binary_accuracy: 0.8000\n",
      "Epoch 564/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4453 - binary_accuracy: 0.7931\n",
      "Epoch 565/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4451 - binary_accuracy: 0.7931\n",
      "Epoch 566/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4449 - binary_accuracy: 0.7931\n",
      "Epoch 567/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4457 - binary_accuracy: 0.8000\n",
      "Epoch 568/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4446 - binary_accuracy: 0.8000\n",
      "Epoch 569/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4446 - binary_accuracy: 0.8000\n",
      "Epoch 570/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4442 - binary_accuracy: 0.8000\n",
      "Epoch 571/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4440 - binary_accuracy: 0.8000\n",
      "Epoch 572/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4440 - binary_accuracy: 0.8000\n",
      "Epoch 573/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4439 - binary_accuracy: 0.8000\n",
      "Epoch 574/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4437 - binary_accuracy: 0.8000\n",
      "Epoch 575/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4434 - binary_accuracy: 0.8000\n",
      "Epoch 576/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4433 - binary_accuracy: 0.8000\n",
      "Epoch 577/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4430 - binary_accuracy: 0.8000\n",
      "Epoch 578/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4435 - binary_accuracy: 0.8000\n",
      "Epoch 579/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4426 - binary_accuracy: 0.8000\n",
      "Epoch 580/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4424 - binary_accuracy: 0.8000\n",
      "Epoch 581/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4427 - binary_accuracy: 0.7931\n",
      "Epoch 582/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4425 - binary_accuracy: 0.7931\n",
      "Epoch 583/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4419 - binary_accuracy: 0.8000\n",
      "Epoch 584/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4419 - binary_accuracy: 0.8000\n",
      "Epoch 585/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4420 - binary_accuracy: 0.8000\n",
      "Epoch 586/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4415 - binary_accuracy: 0.8000\n",
      "Epoch 587/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4413 - binary_accuracy: 0.8000\n",
      "Epoch 588/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4411 - binary_accuracy: 0.8000\n",
      "Epoch 589/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4412 - binary_accuracy: 0.8000\n",
      "Epoch 590/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4415 - binary_accuracy: 0.7931\n",
      "Epoch 591/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4407 - binary_accuracy: 0.8000\n",
      "Epoch 592/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4405 - binary_accuracy: 0.8000\n",
      "Epoch 593/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4403 - binary_accuracy: 0.8000\n",
      "Epoch 594/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4404 - binary_accuracy: 0.8000\n",
      "Epoch 595/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4402 - binary_accuracy: 0.8000\n",
      "Epoch 596/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4403 - binary_accuracy: 0.7862\n",
      "Epoch 597/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4400 - binary_accuracy: 0.8000\n",
      "Epoch 598/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4403 - binary_accuracy: 0.7931\n",
      "Epoch 599/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4394 - binary_accuracy: 0.8000\n",
      "Epoch 600/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4396 - binary_accuracy: 0.8000\n",
      "Epoch 601/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4393 - binary_accuracy: 0.8000\n",
      "Epoch 602/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4393 - binary_accuracy: 0.8000\n",
      "Epoch 603/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4389 - binary_accuracy: 0.8000\n",
      "Epoch 604/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4393 - binary_accuracy: 0.8000\n",
      "Epoch 605/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4386 - binary_accuracy: 0.8000\n",
      "Epoch 606/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4385 - binary_accuracy: 0.8000\n",
      "Epoch 607/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4383 - binary_accuracy: 0.8000\n",
      "Epoch 608/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4389 - binary_accuracy: 0.8000\n",
      "Epoch 609/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4380 - binary_accuracy: 0.8000\n",
      "Epoch 610/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4379 - binary_accuracy: 0.8000\n",
      "Epoch 611/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4382 - binary_accuracy: 0.8000\n",
      "Epoch 612/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4379 - binary_accuracy: 0.8000\n",
      "Epoch 613/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4377 - binary_accuracy: 0.8000\n",
      "Epoch 614/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4373 - binary_accuracy: 0.8000\n",
      "Epoch 615/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4371 - binary_accuracy: 0.8000\n",
      "Epoch 616/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4373 - binary_accuracy: 0.8000\n",
      "Epoch 617/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4375 - binary_accuracy: 0.8000\n",
      "Epoch 618/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4367 - binary_accuracy: 0.8000\n",
      "Epoch 619/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4371 - binary_accuracy: 0.8000\n",
      "Epoch 620/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4364 - binary_accuracy: 0.8000\n",
      "Epoch 621/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4374 - binary_accuracy: 0.7862\n",
      "Epoch 622/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4362 - binary_accuracy: 0.8000\n",
      "Epoch 623/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4373 - binary_accuracy: 0.7862\n",
      "Epoch 624/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4365 - binary_accuracy: 0.7931\n",
      "Epoch 625/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4359 - binary_accuracy: 0.8000\n",
      "Epoch 626/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4358 - binary_accuracy: 0.8000\n",
      "Epoch 627/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4357 - binary_accuracy: 0.8000\n",
      "Epoch 628/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4359 - binary_accuracy: 0.8000\n",
      "Epoch 629/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4354 - binary_accuracy: 0.8000\n",
      "Epoch 630/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4356 - binary_accuracy: 0.8000\n",
      "Epoch 631/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4353 - binary_accuracy: 0.8000\n",
      "Epoch 632/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4350 - binary_accuracy: 0.8000\n",
      "Epoch 633/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4355 - binary_accuracy: 0.7931\n",
      "Epoch 634/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4348 - binary_accuracy: 0.8000\n",
      "Epoch 635/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4360 - binary_accuracy: 0.7931\n",
      "Epoch 636/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4345 - binary_accuracy: 0.8000\n",
      "Epoch 637/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4346 - binary_accuracy: 0.8000\n",
      "Epoch 638/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4344 - binary_accuracy: 0.8000\n",
      "Epoch 639/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4342 - binary_accuracy: 0.8000\n",
      "Epoch 640/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4340 - binary_accuracy: 0.8000\n",
      "Epoch 641/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4341 - binary_accuracy: 0.8000\n",
      "Epoch 642/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4349 - binary_accuracy: 0.8000\n",
      "Epoch 643/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4345 - binary_accuracy: 0.8000\n",
      "Epoch 644/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4336 - binary_accuracy: 0.8000\n",
      "Epoch 645/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4335 - binary_accuracy: 0.8000\n",
      "Epoch 646/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4337 - binary_accuracy: 0.8000\n",
      "Epoch 647/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4338 - binary_accuracy: 0.8000\n",
      "Epoch 648/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4338 - binary_accuracy: 0.7931\n",
      "Epoch 649/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4330 - binary_accuracy: 0.8000\n",
      "Epoch 650/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4335 - binary_accuracy: 0.8000\n",
      "Epoch 651/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4330 - binary_accuracy: 0.8000\n",
      "Epoch 652/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4327 - binary_accuracy: 0.8000\n",
      "Epoch 653/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4326 - binary_accuracy: 0.8000\n",
      "Epoch 654/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4328 - binary_accuracy: 0.8000\n",
      "Epoch 655/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4324 - binary_accuracy: 0.8000\n",
      "Epoch 656/1000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4326 - binary_accuracy: 0.8000\n",
      "Epoch 657/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4324 - binary_accuracy: 0.8000\n",
      "Epoch 658/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4321 - binary_accuracy: 0.8000\n",
      "Epoch 659/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4319 - binary_accuracy: 0.8000\n",
      "Epoch 660/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4318 - binary_accuracy: 0.8000\n",
      "Epoch 661/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4316 - binary_accuracy: 0.8000\n",
      "Epoch 662/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4316 - binary_accuracy: 0.8000\n",
      "Epoch 663/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4315 - binary_accuracy: 0.8000\n",
      "Epoch 664/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4312 - binary_accuracy: 0.8000\n",
      "Epoch 665/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4311 - binary_accuracy: 0.8000\n",
      "Epoch 666/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4308 - binary_accuracy: 0.8000\n",
      "Epoch 667/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4307 - binary_accuracy: 0.8000\n",
      "Epoch 668/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4313 - binary_accuracy: 0.8000\n",
      "Epoch 669/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4304 - binary_accuracy: 0.8000\n",
      "Epoch 670/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4302 - binary_accuracy: 0.8000\n",
      "Epoch 671/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4304 - binary_accuracy: 0.8000\n",
      "Epoch 672/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4299 - binary_accuracy: 0.8000\n",
      "Epoch 673/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4298 - binary_accuracy: 0.8000\n",
      "Epoch 674/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4296 - binary_accuracy: 0.8000\n",
      "Epoch 675/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4297 - binary_accuracy: 0.8000\n",
      "Epoch 676/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4293 - binary_accuracy: 0.8000\n",
      "Epoch 677/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4292 - binary_accuracy: 0.8069\n",
      "Epoch 678/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4290 - binary_accuracy: 0.8000\n",
      "Epoch 679/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4288 - binary_accuracy: 0.8000\n",
      "Epoch 680/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4309 - binary_accuracy: 0.8000\n",
      "Epoch 681/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4287 - binary_accuracy: 0.8000\n",
      "Epoch 682/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4286 - binary_accuracy: 0.8069\n",
      "Epoch 683/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4285 - binary_accuracy: 0.8000\n",
      "Epoch 684/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4284 - binary_accuracy: 0.8000\n",
      "Epoch 685/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4284 - binary_accuracy: 0.8069\n",
      "Epoch 686/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4284 - binary_accuracy: 0.8000\n",
      "Epoch 687/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4280 - binary_accuracy: 0.8000\n",
      "Epoch 688/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4286 - binary_accuracy: 0.7931\n",
      "Epoch 689/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4279 - binary_accuracy: 0.8000\n",
      "Epoch 690/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4276 - binary_accuracy: 0.8069\n",
      "Epoch 691/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4279 - binary_accuracy: 0.8000\n",
      "Epoch 692/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4274 - binary_accuracy: 0.8000\n",
      "Epoch 693/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4276 - binary_accuracy: 0.8069\n",
      "Epoch 694/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4274 - binary_accuracy: 0.8000\n",
      "Epoch 695/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4271 - binary_accuracy: 0.8069\n",
      "Epoch 696/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4273 - binary_accuracy: 0.8000\n",
      "Epoch 697/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4271 - binary_accuracy: 0.8000\n",
      "Epoch 698/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4267 - binary_accuracy: 0.8069\n",
      "Epoch 699/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4266 - binary_accuracy: 0.8069\n",
      "Epoch 700/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4270 - binary_accuracy: 0.8069\n",
      "Epoch 701/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4263 - binary_accuracy: 0.8069\n",
      "Epoch 702/1000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4263 - binary_accuracy: 0.8069\n",
      "Epoch 703/1000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4263 - binary_accuracy: 0.8069\n",
      "Epoch 704/1000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4260 - binary_accuracy: 0.8069\n",
      "Epoch 705/1000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4259 - binary_accuracy: 0.8069\n",
      "Epoch 706/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4267 - binary_accuracy: 0.8138\n",
      "Epoch 707/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4256 - binary_accuracy: 0.8069\n",
      "Epoch 708/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4264 - binary_accuracy: 0.8138\n",
      "Epoch 709/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4256 - binary_accuracy: 0.8069\n",
      "Epoch 710/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4253 - binary_accuracy: 0.8069\n",
      "Epoch 711/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4252 - binary_accuracy: 0.8069\n",
      "Epoch 712/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4270 - binary_accuracy: 0.8069\n",
      "Epoch 713/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4252 - binary_accuracy: 0.8069\n",
      "Epoch 714/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4249 - binary_accuracy: 0.8069\n",
      "Epoch 715/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4250 - binary_accuracy: 0.8069\n",
      "Epoch 716/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4255 - binary_accuracy: 0.8138\n",
      "Epoch 717/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4248 - binary_accuracy: 0.8069\n",
      "Epoch 718/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4246 - binary_accuracy: 0.8069\n",
      "Epoch 719/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4248 - binary_accuracy: 0.8000\n",
      "Epoch 720/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4246 - binary_accuracy: 0.8069\n",
      "Epoch 721/1000\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4248 - binary_accuracy: 0.8000\n",
      "Epoch 722/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4241 - binary_accuracy: 0.8069\n",
      "Epoch 723/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4241 - binary_accuracy: 0.8069\n",
      "Epoch 724/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4241 - binary_accuracy: 0.8069\n",
      "Epoch 725/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4241 - binary_accuracy: 0.8069\n",
      "Epoch 726/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4237 - binary_accuracy: 0.8069\n",
      "Epoch 727/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4237 - binary_accuracy: 0.8069\n",
      "Epoch 728/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4237 - binary_accuracy: 0.8069\n",
      "Epoch 729/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4237 - binary_accuracy: 0.8069\n",
      "Epoch 730/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4238 - binary_accuracy: 0.8069\n",
      "Epoch 731/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4232 - binary_accuracy: 0.8069\n",
      "Epoch 732/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4230 - binary_accuracy: 0.8069\n",
      "Epoch 733/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4230 - binary_accuracy: 0.8069\n",
      "Epoch 734/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4228 - binary_accuracy: 0.8069\n",
      "Epoch 735/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4229 - binary_accuracy: 0.8069\n",
      "Epoch 736/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4225 - binary_accuracy: 0.8069\n",
      "Epoch 737/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4230 - binary_accuracy: 0.8000\n",
      "Epoch 738/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4223 - binary_accuracy: 0.8069\n",
      "Epoch 739/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4224 - binary_accuracy: 0.8069\n",
      "Epoch 740/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4228 - binary_accuracy: 0.8000\n",
      "Epoch 741/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4220 - binary_accuracy: 0.8069\n",
      "Epoch 742/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4223 - binary_accuracy: 0.8069\n",
      "Epoch 743/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4218 - binary_accuracy: 0.8069\n",
      "Epoch 744/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4224 - binary_accuracy: 0.8069\n",
      "Epoch 745/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4218 - binary_accuracy: 0.8069\n",
      "Epoch 746/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4219 - binary_accuracy: 0.8138\n",
      "Epoch 747/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4218 - binary_accuracy: 0.8138\n",
      "Epoch 748/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4213 - binary_accuracy: 0.8069\n",
      "Epoch 749/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4211 - binary_accuracy: 0.8069\n",
      "Epoch 750/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4210 - binary_accuracy: 0.8069\n",
      "Epoch 751/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4213 - binary_accuracy: 0.8069\n",
      "Epoch 752/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4215 - binary_accuracy: 0.8000\n",
      "Epoch 753/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4212 - binary_accuracy: 0.8069\n",
      "Epoch 754/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4207 - binary_accuracy: 0.8069\n",
      "Epoch 755/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4210 - binary_accuracy: 0.8138\n",
      "Epoch 756/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4205 - binary_accuracy: 0.8069\n",
      "Epoch 757/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4205 - binary_accuracy: 0.8069\n",
      "Epoch 758/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4203 - binary_accuracy: 0.8069\n",
      "Epoch 759/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4202 - binary_accuracy: 0.8069\n",
      "Epoch 760/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4205 - binary_accuracy: 0.8138\n",
      "Epoch 761/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4199 - binary_accuracy: 0.8069\n",
      "Epoch 762/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4198 - binary_accuracy: 0.8069\n",
      "Epoch 763/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4197 - binary_accuracy: 0.8069\n",
      "Epoch 764/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4212 - binary_accuracy: 0.8069\n",
      "Epoch 765/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4201 - binary_accuracy: 0.8138\n",
      "Epoch 766/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4195 - binary_accuracy: 0.8069\n",
      "Epoch 767/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4199 - binary_accuracy: 0.8069\n",
      "Epoch 768/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4198 - binary_accuracy: 0.8069\n",
      "Epoch 769/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4192 - binary_accuracy: 0.8069\n",
      "Epoch 770/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4197 - binary_accuracy: 0.8000\n",
      "Epoch 771/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4194 - binary_accuracy: 0.8138\n",
      "Epoch 772/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4189 - binary_accuracy: 0.8069\n",
      "Epoch 773/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4188 - binary_accuracy: 0.8069\n",
      "Epoch 774/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4188 - binary_accuracy: 0.8069\n",
      "Epoch 775/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4192 - binary_accuracy: 0.8069\n",
      "Epoch 776/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4185 - binary_accuracy: 0.8069\n",
      "Epoch 777/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4185 - binary_accuracy: 0.8069\n",
      "Epoch 778/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4190 - binary_accuracy: 0.8069\n",
      "Epoch 779/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4183 - binary_accuracy: 0.8069\n",
      "Epoch 780/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4183 - binary_accuracy: 0.8069\n",
      "Epoch 781/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4183 - binary_accuracy: 0.8069\n",
      "Epoch 782/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4180 - binary_accuracy: 0.8069\n",
      "Epoch 783/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4181 - binary_accuracy: 0.8138\n",
      "Epoch 784/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4181 - binary_accuracy: 0.8069\n",
      "Epoch 785/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4177 - binary_accuracy: 0.8138\n",
      "Epoch 786/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4181 - binary_accuracy: 0.8069\n",
      "Epoch 787/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4175 - binary_accuracy: 0.8069\n",
      "Epoch 788/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4173 - binary_accuracy: 0.8138\n",
      "Epoch 789/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4173 - binary_accuracy: 0.8069\n",
      "Epoch 790/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4173 - binary_accuracy: 0.8069\n",
      "Epoch 791/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4173 - binary_accuracy: 0.8138\n",
      "Epoch 792/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4175 - binary_accuracy: 0.8069\n",
      "Epoch 793/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4173 - binary_accuracy: 0.8138\n",
      "Epoch 794/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4171 - binary_accuracy: 0.8138\n",
      "Epoch 795/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4167 - binary_accuracy: 0.8069\n",
      "Epoch 796/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4166 - binary_accuracy: 0.8138\n",
      "Epoch 797/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4164 - binary_accuracy: 0.8069\n",
      "Epoch 798/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4163 - binary_accuracy: 0.8069\n",
      "Epoch 799/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4162 - binary_accuracy: 0.8069\n",
      "Epoch 800/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4161 - binary_accuracy: 0.8069\n",
      "Epoch 801/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4162 - binary_accuracy: 0.8138\n",
      "Epoch 802/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4168 - binary_accuracy: 0.8069\n",
      "Epoch 803/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4164 - binary_accuracy: 0.8069\n",
      "Epoch 804/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4158 - binary_accuracy: 0.8069\n",
      "Epoch 805/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4157 - binary_accuracy: 0.8069\n",
      "Epoch 806/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4159 - binary_accuracy: 0.8138\n",
      "Epoch 807/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4155 - binary_accuracy: 0.8138\n",
      "Epoch 808/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4154 - binary_accuracy: 0.8138\n",
      "Epoch 809/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4154 - binary_accuracy: 0.8138\n",
      "Epoch 810/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4155 - binary_accuracy: 0.8138\n",
      "Epoch 811/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4153 - binary_accuracy: 0.8138\n",
      "Epoch 812/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4150 - binary_accuracy: 0.8138\n",
      "Epoch 813/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4151 - binary_accuracy: 0.8138\n",
      "Epoch 814/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4150 - binary_accuracy: 0.8138\n",
      "Epoch 815/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4147 - binary_accuracy: 0.8069\n",
      "Epoch 816/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4150 - binary_accuracy: 0.8069\n",
      "Epoch 817/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4150 - binary_accuracy: 0.8069\n",
      "Epoch 818/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4143 - binary_accuracy: 0.8069\n",
      "Epoch 819/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4151 - binary_accuracy: 0.8069\n",
      "Epoch 820/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4142 - binary_accuracy: 0.8138\n",
      "Epoch 821/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4141 - binary_accuracy: 0.8069\n",
      "Epoch 822/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4140 - binary_accuracy: 0.8138\n",
      "Epoch 823/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4139 - binary_accuracy: 0.8069\n",
      "Epoch 824/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4138 - binary_accuracy: 0.8138\n",
      "Epoch 825/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4138 - binary_accuracy: 0.8138\n",
      "Epoch 826/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4136 - binary_accuracy: 0.8069\n",
      "Epoch 827/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4134 - binary_accuracy: 0.8069\n",
      "Epoch 828/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4136 - binary_accuracy: 0.8138\n",
      "Epoch 829/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4132 - binary_accuracy: 0.8138\n",
      "Epoch 830/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4131 - binary_accuracy: 0.8138\n",
      "Epoch 831/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4130 - binary_accuracy: 0.8069\n",
      "Epoch 832/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4129 - binary_accuracy: 0.8138\n",
      "Epoch 833/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4129 - binary_accuracy: 0.8069\n",
      "Epoch 834/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4127 - binary_accuracy: 0.8069\n",
      "Epoch 835/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4128 - binary_accuracy: 0.8138\n",
      "Epoch 836/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4125 - binary_accuracy: 0.8069\n",
      "Epoch 837/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4123 - binary_accuracy: 0.8138\n",
      "Epoch 838/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4138 - binary_accuracy: 0.8069\n",
      "Epoch 839/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4123 - binary_accuracy: 0.8069\n",
      "Epoch 840/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4124 - binary_accuracy: 0.8069\n",
      "Epoch 841/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4119 - binary_accuracy: 0.8138\n",
      "Epoch 842/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4118 - binary_accuracy: 0.8138\n",
      "Epoch 843/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4120 - binary_accuracy: 0.8138\n",
      "Epoch 844/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4116 - binary_accuracy: 0.8138\n",
      "Epoch 845/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4116 - binary_accuracy: 0.8138\n",
      "Epoch 846/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4116 - binary_accuracy: 0.8138\n",
      "Epoch 847/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4116 - binary_accuracy: 0.8069\n",
      "Epoch 848/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4113 - binary_accuracy: 0.8138\n",
      "Epoch 849/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4111 - binary_accuracy: 0.8138\n",
      "Epoch 850/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4115 - binary_accuracy: 0.8069\n",
      "Epoch 851/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4111 - binary_accuracy: 0.8069\n",
      "Epoch 852/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4111 - binary_accuracy: 0.8138\n",
      "Epoch 853/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4109 - binary_accuracy: 0.8138\n",
      "Epoch 854/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4106 - binary_accuracy: 0.8138\n",
      "Epoch 855/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4105 - binary_accuracy: 0.8138\n",
      "Epoch 856/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4107 - binary_accuracy: 0.8069\n",
      "Epoch 857/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4104 - binary_accuracy: 0.8069\n",
      "Epoch 858/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4107 - binary_accuracy: 0.8069\n",
      "Epoch 859/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4100 - binary_accuracy: 0.8138\n",
      "Epoch 860/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4100 - binary_accuracy: 0.8138\n",
      "Epoch 861/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4101 - binary_accuracy: 0.8138\n",
      "Epoch 862/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4099 - binary_accuracy: 0.8138\n",
      "Epoch 863/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4108 - binary_accuracy: 0.8207\n",
      "Epoch 864/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4103 - binary_accuracy: 0.8207\n",
      "Epoch 865/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4096 - binary_accuracy: 0.8138\n",
      "Epoch 866/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4094 - binary_accuracy: 0.8138\n",
      "Epoch 867/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4098 - binary_accuracy: 0.8138\n",
      "Epoch 868/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4094 - binary_accuracy: 0.8138\n",
      "Epoch 869/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4096 - binary_accuracy: 0.8207\n",
      "Epoch 870/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4091 - binary_accuracy: 0.8138\n",
      "Epoch 871/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4098 - binary_accuracy: 0.8138\n",
      "Epoch 872/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4094 - binary_accuracy: 0.8069\n",
      "Epoch 873/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4092 - binary_accuracy: 0.8069\n",
      "Epoch 874/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4103 - binary_accuracy: 0.8069\n",
      "Epoch 875/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4087 - binary_accuracy: 0.8138\n",
      "Epoch 876/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4087 - binary_accuracy: 0.8138\n",
      "Epoch 877/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4087 - binary_accuracy: 0.8138\n",
      "Epoch 878/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4086 - binary_accuracy: 0.8138\n",
      "Epoch 879/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4085 - binary_accuracy: 0.8138\n",
      "Epoch 880/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4086 - binary_accuracy: 0.8138\n",
      "Epoch 881/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4083 - binary_accuracy: 0.8138\n",
      "Epoch 882/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4086 - binary_accuracy: 0.8138\n",
      "Epoch 883/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4082 - binary_accuracy: 0.8138\n",
      "Epoch 884/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4083 - binary_accuracy: 0.8138\n",
      "Epoch 885/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4079 - binary_accuracy: 0.8138\n",
      "Epoch 886/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4079 - binary_accuracy: 0.8138\n",
      "Epoch 887/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4079 - binary_accuracy: 0.8207\n",
      "Epoch 888/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4080 - binary_accuracy: 0.8138\n",
      "Epoch 889/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4087 - binary_accuracy: 0.8069\n",
      "Epoch 890/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4076 - binary_accuracy: 0.8138\n",
      "Epoch 891/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4076 - binary_accuracy: 0.8138\n",
      "Epoch 892/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4075 - binary_accuracy: 0.8069\n",
      "Epoch 893/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4076 - binary_accuracy: 0.8138\n",
      "Epoch 894/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4074 - binary_accuracy: 0.8069\n",
      "Epoch 895/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4076 - binary_accuracy: 0.8138\n",
      "Epoch 896/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4071 - binary_accuracy: 0.8138\n",
      "Epoch 897/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4069 - binary_accuracy: 0.8138\n",
      "Epoch 898/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4071 - binary_accuracy: 0.8138\n",
      "Epoch 899/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4072 - binary_accuracy: 0.8207\n",
      "Epoch 900/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4070 - binary_accuracy: 0.8138\n",
      "Epoch 901/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4069 - binary_accuracy: 0.8138\n",
      "Epoch 902/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4080 - binary_accuracy: 0.8000\n",
      "Epoch 903/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4065 - binary_accuracy: 0.8138\n",
      "Epoch 904/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4065 - binary_accuracy: 0.8207\n",
      "Epoch 905/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4069 - binary_accuracy: 0.8207\n",
      "Epoch 906/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4066 - binary_accuracy: 0.8138\n",
      "Epoch 907/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4062 - binary_accuracy: 0.8138\n",
      "Epoch 908/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4061 - binary_accuracy: 0.8138\n",
      "Epoch 909/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4063 - binary_accuracy: 0.8207\n",
      "Epoch 910/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4060 - binary_accuracy: 0.8138\n",
      "Epoch 911/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4059 - binary_accuracy: 0.8138\n",
      "Epoch 912/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4062 - binary_accuracy: 0.8207\n",
      "Epoch 913/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4059 - binary_accuracy: 0.8138\n",
      "Epoch 914/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4078 - binary_accuracy: 0.8138\n",
      "Epoch 915/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4056 - binary_accuracy: 0.8138\n",
      "Epoch 916/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4056 - binary_accuracy: 0.8207\n",
      "Epoch 917/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4057 - binary_accuracy: 0.8207\n",
      "Epoch 918/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4055 - binary_accuracy: 0.8138\n",
      "Epoch 919/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4058 - binary_accuracy: 0.8138\n",
      "Epoch 920/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4064 - binary_accuracy: 0.8138\n",
      "Epoch 921/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4054 - binary_accuracy: 0.8207\n",
      "Epoch 922/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4052 - binary_accuracy: 0.8207\n",
      "Epoch 923/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4053 - binary_accuracy: 0.8138\n",
      "Epoch 924/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4051 - binary_accuracy: 0.8138\n",
      "Epoch 925/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4049 - binary_accuracy: 0.8207\n",
      "Epoch 926/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4049 - binary_accuracy: 0.8207\n",
      "Epoch 927/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4049 - binary_accuracy: 0.8138\n",
      "Epoch 928/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4047 - binary_accuracy: 0.8207\n",
      "Epoch 929/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4047 - binary_accuracy: 0.8276\n",
      "Epoch 930/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4046 - binary_accuracy: 0.8276\n",
      "Epoch 931/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4047 - binary_accuracy: 0.8207\n",
      "Epoch 932/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4045 - binary_accuracy: 0.8207\n",
      "Epoch 933/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4045 - binary_accuracy: 0.8207\n",
      "Epoch 934/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4044 - binary_accuracy: 0.8207\n",
      "Epoch 935/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4042 - binary_accuracy: 0.8276\n",
      "Epoch 936/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4039 - binary_accuracy: 0.8276\n",
      "Epoch 937/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4039 - binary_accuracy: 0.8276\n",
      "Epoch 938/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4039 - binary_accuracy: 0.8207\n",
      "Epoch 939/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4038 - binary_accuracy: 0.8207\n",
      "Epoch 940/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4035 - binary_accuracy: 0.8276\n",
      "Epoch 941/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4037 - binary_accuracy: 0.8207\n",
      "Epoch 942/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4038 - binary_accuracy: 0.8207\n",
      "Epoch 943/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4033 - binary_accuracy: 0.8276\n",
      "Epoch 944/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4042 - binary_accuracy: 0.8207\n",
      "Epoch 945/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4031 - binary_accuracy: 0.8276\n",
      "Epoch 946/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4035 - binary_accuracy: 0.8138\n",
      "Epoch 947/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4036 - binary_accuracy: 0.8276\n",
      "Epoch 948/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4031 - binary_accuracy: 0.8276\n",
      "Epoch 949/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4028 - binary_accuracy: 0.8276\n",
      "Epoch 950/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4029 - binary_accuracy: 0.8276\n",
      "Epoch 951/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4029 - binary_accuracy: 0.8207\n",
      "Epoch 952/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4026 - binary_accuracy: 0.8276\n",
      "Epoch 953/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4027 - binary_accuracy: 0.8276\n",
      "Epoch 954/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4025 - binary_accuracy: 0.8276\n",
      "Epoch 955/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4024 - binary_accuracy: 0.8207\n",
      "Epoch 956/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4024 - binary_accuracy: 0.8276\n",
      "Epoch 957/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4023 - binary_accuracy: 0.8276\n",
      "Epoch 958/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4021 - binary_accuracy: 0.8276\n",
      "Epoch 959/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4022 - binary_accuracy: 0.8276\n",
      "Epoch 960/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4019 - binary_accuracy: 0.8276\n",
      "Epoch 961/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4021 - binary_accuracy: 0.8276\n",
      "Epoch 962/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4018 - binary_accuracy: 0.8276\n",
      "Epoch 963/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4016 - binary_accuracy: 0.8276\n",
      "Epoch 964/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4023 - binary_accuracy: 0.8207\n",
      "Epoch 965/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4025 - binary_accuracy: 0.8276\n",
      "Epoch 966/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4014 - binary_accuracy: 0.8276\n",
      "Epoch 967/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4016 - binary_accuracy: 0.8276\n",
      "Epoch 968/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4013 - binary_accuracy: 0.8276\n",
      "Epoch 969/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4015 - binary_accuracy: 0.8276\n",
      "Epoch 970/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4012 - binary_accuracy: 0.8276\n",
      "Epoch 971/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4017 - binary_accuracy: 0.8276\n",
      "Epoch 972/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4010 - binary_accuracy: 0.8276\n",
      "Epoch 973/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4015 - binary_accuracy: 0.8207\n",
      "Epoch 974/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4011 - binary_accuracy: 0.8276\n",
      "Epoch 975/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4012 - binary_accuracy: 0.8345\n",
      "Epoch 976/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4015 - binary_accuracy: 0.8276\n",
      "Epoch 977/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4007 - binary_accuracy: 0.8276\n",
      "Epoch 978/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4006 - binary_accuracy: 0.8276\n",
      "Epoch 979/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4010 - binary_accuracy: 0.8276\n",
      "Epoch 980/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4010 - binary_accuracy: 0.8276\n",
      "Epoch 981/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4004 - binary_accuracy: 0.8276\n",
      "Epoch 982/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4006 - binary_accuracy: 0.8276\n",
      "Epoch 983/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4005 - binary_accuracy: 0.8276\n",
      "Epoch 984/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4007 - binary_accuracy: 0.8276\n",
      "Epoch 985/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4002 - binary_accuracy: 0.8276\n",
      "Epoch 986/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4002 - binary_accuracy: 0.8276\n",
      "Epoch 987/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4000 - binary_accuracy: 0.8276\n",
      "Epoch 988/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4002 - binary_accuracy: 0.8276\n",
      "Epoch 989/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3999 - binary_accuracy: 0.8276\n",
      "Epoch 990/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3998 - binary_accuracy: 0.8276\n",
      "Epoch 991/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3997 - binary_accuracy: 0.8276\n",
      "Epoch 992/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3996 - binary_accuracy: 0.8276\n",
      "Epoch 993/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3996 - binary_accuracy: 0.8276\n",
      "Epoch 994/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3994 - binary_accuracy: 0.8276\n",
      "Epoch 995/1000\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.3993 - binary_accuracy: 0.8276\n",
      "Epoch 996/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3992 - binary_accuracy: 0.8276\n",
      "Epoch 997/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3992 - binary_accuracy: 0.8276\n",
      "Epoch 998/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4001 - binary_accuracy: 0.8207\n",
      "Epoch 999/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3991 - binary_accuracy: 0.8276\n",
      "Epoch 1000/1000\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3989 - binary_accuracy: 0.8276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2e182f4760>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xs,ys,train_size=0.7)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=1000, batch_size=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[26,  3],\n",
       "       [16, 18]])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model.predict(X_test)\n",
    "tmp = np.vectorize(lambda x: helper(x,th=0.75))(y_predict.reshape(y_predict.shape[0]))\n",
    "confusion_matrix(y_test,tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another standard small example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "x_iris = iris['data']\n",
    "y_iris = iris['target']\n",
    "\n",
    "labeler = LabelBinarizer()\n",
    "y = labeler.fit_transform(y_iris)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_iris, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.6780 - binary_accuracy: 0.5000\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6543 - binary_accuracy: 0.5595\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6390 - binary_accuracy: 0.5595\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6271 - binary_accuracy: 0.5565\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6175 - binary_accuracy: 0.6220\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6100 - binary_accuracy: 0.6667\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6061 - binary_accuracy: 0.6667\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6018 - binary_accuracy: 0.6667\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5964 - binary_accuracy: 0.6667\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5898 - binary_accuracy: 0.6667\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5832 - binary_accuracy: 0.6667\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5772 - binary_accuracy: 0.6667\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5717 - binary_accuracy: 0.6667\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5662 - binary_accuracy: 0.6667\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5605 - binary_accuracy: 0.6667\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5548 - binary_accuracy: 0.6667\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5494 - binary_accuracy: 0.6726\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5442 - binary_accuracy: 0.6994\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5393 - binary_accuracy: 0.7232\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5345 - binary_accuracy: 0.7351\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5295 - binary_accuracy: 0.7381\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5245 - binary_accuracy: 0.7440\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5193 - binary_accuracy: 0.7560\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5141 - binary_accuracy: 0.7649\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5092 - binary_accuracy: 0.7738\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5045 - binary_accuracy: 0.7708\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4998 - binary_accuracy: 0.7708\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4949 - binary_accuracy: 0.7708\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4899 - binary_accuracy: 0.7708\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4847 - binary_accuracy: 0.7798\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4793 - binary_accuracy: 0.8095\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4738 - binary_accuracy: 0.8393\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4684 - binary_accuracy: 0.8571\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4630 - binary_accuracy: 0.8571\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4577 - binary_accuracy: 0.8601\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4527 - binary_accuracy: 0.8601\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4477 - binary_accuracy: 0.8661\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4424 - binary_accuracy: 0.8690\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4370 - binary_accuracy: 0.8720\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4315 - binary_accuracy: 0.8720\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4260 - binary_accuracy: 0.8810\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4204 - binary_accuracy: 0.8839\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4148 - binary_accuracy: 0.8869\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4091 - binary_accuracy: 0.8899\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4031 - binary_accuracy: 0.8899\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3970 - binary_accuracy: 0.8869\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3909 - binary_accuracy: 0.8869\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3847 - binary_accuracy: 0.8869\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3787 - binary_accuracy: 0.8869\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3720 - binary_accuracy: 0.8899\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3656 - binary_accuracy: 0.8899\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3592 - binary_accuracy: 0.8929\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3527 - binary_accuracy: 0.9048\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3463 - binary_accuracy: 0.9107\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3398 - binary_accuracy: 0.9107\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3334 - binary_accuracy: 0.9107\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3271 - binary_accuracy: 0.9137\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3208 - binary_accuracy: 0.9286\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3146 - binary_accuracy: 0.9286\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3085 - binary_accuracy: 0.9286\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3024 - binary_accuracy: 0.9286\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2964 - binary_accuracy: 0.9286\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2905 - binary_accuracy: 0.9315\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2846 - binary_accuracy: 0.9405\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2788 - binary_accuracy: 0.9464\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2730 - binary_accuracy: 0.9464\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2671 - binary_accuracy: 0.9524\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2611 - binary_accuracy: 0.9524\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2551 - binary_accuracy: 0.9524\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2495 - binary_accuracy: 0.9524\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2441 - binary_accuracy: 0.9524\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2389 - binary_accuracy: 0.9524\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2339 - binary_accuracy: 0.9524\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2289 - binary_accuracy: 0.9583\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2240 - binary_accuracy: 0.9613\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2192 - binary_accuracy: 0.9613\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2145 - binary_accuracy: 0.9643\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2099 - binary_accuracy: 0.9702\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2053 - binary_accuracy: 0.9702\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2008 - binary_accuracy: 0.9702\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1964 - binary_accuracy: 0.9762\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1921 - binary_accuracy: 0.9792\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1879 - binary_accuracy: 0.9792\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1837 - binary_accuracy: 0.9792\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1796 - binary_accuracy: 0.9792\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1755 - binary_accuracy: 0.9792\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1715 - binary_accuracy: 0.9792\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1676 - binary_accuracy: 0.9792\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1638 - binary_accuracy: 0.9792\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1600 - binary_accuracy: 0.9792\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1564 - binary_accuracy: 0.9792\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1527 - binary_accuracy: 0.9792\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1492 - binary_accuracy: 0.9792\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1457 - binary_accuracy: 0.9792\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1423 - binary_accuracy: 0.9792\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1390 - binary_accuracy: 0.9792\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1357 - binary_accuracy: 0.9792\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1325 - binary_accuracy: 0.9792\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1294 - binary_accuracy: 0.9792\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1264 - binary_accuracy: 0.9792\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1235 - binary_accuracy: 0.9792\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1207 - binary_accuracy: 0.9792\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1180 - binary_accuracy: 0.9792\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1154 - binary_accuracy: 0.9792\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1128 - binary_accuracy: 0.9792\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1102 - binary_accuracy: 0.9792\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1078 - binary_accuracy: 0.9792\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1054 - binary_accuracy: 0.9792\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1031 - binary_accuracy: 0.9792\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1008 - binary_accuracy: 0.9792\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0985 - binary_accuracy: 0.9821\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0959 - binary_accuracy: 0.9821\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0930 - binary_accuracy: 0.9821\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0906 - binary_accuracy: 0.9821\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0886 - binary_accuracy: 0.9821\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0868 - binary_accuracy: 0.9821\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0850 - binary_accuracy: 0.9821\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0834 - binary_accuracy: 0.9821\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0817 - binary_accuracy: 0.9821\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0801 - binary_accuracy: 0.9821\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0786 - binary_accuracy: 0.9851\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0771 - binary_accuracy: 0.9821\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0757 - binary_accuracy: 0.9821\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0743 - binary_accuracy: 0.9821\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0729 - binary_accuracy: 0.9851\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0716 - binary_accuracy: 0.9851\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0704 - binary_accuracy: 0.9821\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0692 - binary_accuracy: 0.9821\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0680 - binary_accuracy: 0.9851\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0669 - binary_accuracy: 0.9851\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0658 - binary_accuracy: 0.9851\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0648 - binary_accuracy: 0.9851\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0638 - binary_accuracy: 0.9881\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0629 - binary_accuracy: 0.9881\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0620 - binary_accuracy: 0.9881\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0611 - binary_accuracy: 0.9881\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0603 - binary_accuracy: 0.9881\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0594 - binary_accuracy: 0.9881\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0587 - binary_accuracy: 0.9881\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0579 - binary_accuracy: 0.9881\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0572 - binary_accuracy: 0.9881\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0565 - binary_accuracy: 0.9881\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0559 - binary_accuracy: 0.9881\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0552 - binary_accuracy: 0.9881\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0546 - binary_accuracy: 0.9881\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0540 - binary_accuracy: 0.9881\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0535 - binary_accuracy: 0.9881\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0529 - binary_accuracy: 0.9881\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0524 - binary_accuracy: 0.9881\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0518 - binary_accuracy: 0.9881\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0513 - binary_accuracy: 0.9881\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0509 - binary_accuracy: 0.9911\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0504 - binary_accuracy: 0.9881\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0499 - binary_accuracy: 0.9911\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0495 - binary_accuracy: 0.9911\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0491 - binary_accuracy: 0.9911\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0487 - binary_accuracy: 0.9911\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0483 - binary_accuracy: 0.9911\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0479 - binary_accuracy: 0.9911\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0475 - binary_accuracy: 0.9911\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0471 - binary_accuracy: 0.9911\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0468 - binary_accuracy: 0.9911\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0464 - binary_accuracy: 0.9911\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0461 - binary_accuracy: 0.9911\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0457 - binary_accuracy: 0.9911\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0454 - binary_accuracy: 0.9911\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0451 - binary_accuracy: 0.9911\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0448 - binary_accuracy: 0.9911\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0445 - binary_accuracy: 0.9911\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0442 - binary_accuracy: 0.9911\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0439 - binary_accuracy: 0.9911\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0437 - binary_accuracy: 0.9911\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0434 - binary_accuracy: 0.9911\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0431 - binary_accuracy: 0.9911\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0429 - binary_accuracy: 0.9911\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0426 - binary_accuracy: 0.9911\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0424 - binary_accuracy: 0.9911\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0422 - binary_accuracy: 0.9911\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0419 - binary_accuracy: 0.9911\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0417 - binary_accuracy: 0.9911\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0415 - binary_accuracy: 0.9911\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0413 - binary_accuracy: 0.9911\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0410 - binary_accuracy: 0.9911\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0408 - binary_accuracy: 0.9911\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0406 - binary_accuracy: 0.9911\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0404 - binary_accuracy: 0.9911\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0402 - binary_accuracy: 0.9911\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0400 - binary_accuracy: 0.9911\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0398 - binary_accuracy: 0.9911\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0396 - binary_accuracy: 0.9911\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0395 - binary_accuracy: 0.9911\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0393 - binary_accuracy: 0.9911\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0391 - binary_accuracy: 0.9911\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0389 - binary_accuracy: 0.9911\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0388 - binary_accuracy: 0.9911\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0386 - binary_accuracy: 0.9911\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0384 - binary_accuracy: 0.9911\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0382 - binary_accuracy: 0.9911\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0381 - binary_accuracy: 0.9911\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0379 - binary_accuracy: 0.9911\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0378 - binary_accuracy: 0.9911\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0376 - binary_accuracy: 0.9911\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0375 - binary_accuracy: 0.9911\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0373 - binary_accuracy: 0.9911\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0372 - binary_accuracy: 0.9911\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0370 - binary_accuracy: 0.9911\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0369 - binary_accuracy: 0.9911\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0367 - binary_accuracy: 0.9911\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0366 - binary_accuracy: 0.9911\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0364 - binary_accuracy: 0.9911\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0363 - binary_accuracy: 0.9911\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0362 - binary_accuracy: 0.9911\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0360 - binary_accuracy: 0.9911\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0359 - binary_accuracy: 0.9911\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0358 - binary_accuracy: 0.9911\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0356 - binary_accuracy: 0.9911\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0355 - binary_accuracy: 0.9911\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0354 - binary_accuracy: 0.9911\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0352 - binary_accuracy: 0.9911\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0351 - binary_accuracy: 0.9911\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0350 - binary_accuracy: 0.9911\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0349 - binary_accuracy: 0.9911\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0347 - binary_accuracy: 0.9911\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0346 - binary_accuracy: 0.9911\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0345 - binary_accuracy: 0.9911\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0344 - binary_accuracy: 0.9911\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0343 - binary_accuracy: 0.9911\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0341 - binary_accuracy: 0.9911\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0340 - binary_accuracy: 0.9911\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0339 - binary_accuracy: 0.9911\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0338 - binary_accuracy: 0.9911\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0337 - binary_accuracy: 0.9911\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0336 - binary_accuracy: 0.9911\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0335 - binary_accuracy: 0.9911\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0333 - binary_accuracy: 0.9911\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0332 - binary_accuracy: 0.9911\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0331 - binary_accuracy: 0.9911\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0330 - binary_accuracy: 0.9911\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0329 - binary_accuracy: 0.9911\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0328 - binary_accuracy: 0.9911\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0327 - binary_accuracy: 0.9911\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0326 - binary_accuracy: 0.9911\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0325 - binary_accuracy: 0.9911\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0324 - binary_accuracy: 0.9911\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0323 - binary_accuracy: 0.9911\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0322 - binary_accuracy: 0.9911\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0321 - binary_accuracy: 0.9911\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0320 - binary_accuracy: 0.9911\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0319 - binary_accuracy: 0.9911\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0318 - binary_accuracy: 0.9911\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0317 - binary_accuracy: 0.9911\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0316 - binary_accuracy: 0.9911\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0315 - binary_accuracy: 0.9911\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0314 - binary_accuracy: 0.9911\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0313 - binary_accuracy: 0.9911\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0312 - binary_accuracy: 0.9911\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0311 - binary_accuracy: 0.9911\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0310 - binary_accuracy: 0.9911\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0309 - binary_accuracy: 0.9911\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0308 - binary_accuracy: 0.9911\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0307 - binary_accuracy: 0.9911\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0306 - binary_accuracy: 0.9911\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0305 - binary_accuracy: 0.9911\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0304 - binary_accuracy: 0.9911\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0303 - binary_accuracy: 0.9911\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0302 - binary_accuracy: 0.9911\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0301 - binary_accuracy: 0.9911\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0300 - binary_accuracy: 0.9911\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0299 - binary_accuracy: 0.9911\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0298 - binary_accuracy: 0.9911\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0297 - binary_accuracy: 0.9911\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0296 - binary_accuracy: 0.9911\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0296 - binary_accuracy: 0.9911\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0295 - binary_accuracy: 0.9911\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0294 - binary_accuracy: 0.9911\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0293 - binary_accuracy: 0.9911\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0292 - binary_accuracy: 0.9911\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0291 - binary_accuracy: 0.9911\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0290 - binary_accuracy: 0.9911\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0289 - binary_accuracy: 0.9911\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0288 - binary_accuracy: 0.9911\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0287 - binary_accuracy: 0.9911\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0287 - binary_accuracy: 0.9911\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0286 - binary_accuracy: 0.9911\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0285 - binary_accuracy: 0.9911\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0284 - binary_accuracy: 0.9911\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0283 - binary_accuracy: 0.9911\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0282 - binary_accuracy: 0.9911\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0281 - binary_accuracy: 0.9911\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0280 - binary_accuracy: 0.9911\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0280 - binary_accuracy: 0.9911\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0279 - binary_accuracy: 0.9911\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0278 - binary_accuracy: 0.9911\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0277 - binary_accuracy: 0.9911\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0276 - binary_accuracy: 0.9911\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0275 - binary_accuracy: 0.9911\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0274 - binary_accuracy: 0.9911\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0274 - binary_accuracy: 0.9911\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0273 - binary_accuracy: 0.9911\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0272 - binary_accuracy: 0.9911\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0271 - binary_accuracy: 0.9911\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0270 - binary_accuracy: 0.9911\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0269 - binary_accuracy: 0.9911\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0268 - binary_accuracy: 0.9911\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0268 - binary_accuracy: 0.9911\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0267 - binary_accuracy: 0.9911\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0266 - binary_accuracy: 0.9911\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0265 - binary_accuracy: 0.9911\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0264 - binary_accuracy: 0.9911\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0263 - binary_accuracy: 0.9911\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0263 - binary_accuracy: 0.9911\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0262 - binary_accuracy: 0.9911\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0261 - binary_accuracy: 0.9911\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0260 - binary_accuracy: 0.9911\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0259 - binary_accuracy: 0.9911\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0259 - binary_accuracy: 0.9911\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0258 - binary_accuracy: 0.9911\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0257 - binary_accuracy: 0.9911\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0256 - binary_accuracy: 0.9911\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0255 - binary_accuracy: 0.9911\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0254 - binary_accuracy: 0.9911\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0254 - binary_accuracy: 0.9911\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0253 - binary_accuracy: 0.9911\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0252 - binary_accuracy: 0.9911\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0251 - binary_accuracy: 0.9911\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0250 - binary_accuracy: 0.9911\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0250 - binary_accuracy: 0.9911\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0249 - binary_accuracy: 0.9911\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0248 - binary_accuracy: 0.9911\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0247 - binary_accuracy: 0.9911\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0246 - binary_accuracy: 0.9911\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0246 - binary_accuracy: 0.9911\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0245 - binary_accuracy: 0.9911\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0244 - binary_accuracy: 0.9911\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0243 - binary_accuracy: 0.9911\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0242 - binary_accuracy: 0.9911\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0242 - binary_accuracy: 0.9911\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0241 - binary_accuracy: 0.9911\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0240 - binary_accuracy: 0.9911\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0239 - binary_accuracy: 0.9911\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0238 - binary_accuracy: 0.9911\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0238 - binary_accuracy: 0.9911\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0237 - binary_accuracy: 0.9911\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0236 - binary_accuracy: 0.9911\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0235 - binary_accuracy: 0.9911\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0234 - binary_accuracy: 0.9911\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0234 - binary_accuracy: 0.9911\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0233 - binary_accuracy: 0.9911\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0232 - binary_accuracy: 0.9911\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0232 - binary_accuracy: 0.9911\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0232 - binary_accuracy: 0.9911\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0233 - binary_accuracy: 0.9911\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0234 - binary_accuracy: 0.9940\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0234 - binary_accuracy: 0.9911\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0229 - binary_accuracy: 0.9911\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0227 - binary_accuracy: 0.9911\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0230 - binary_accuracy: 0.9911\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0228 - binary_accuracy: 0.9940\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0225 - binary_accuracy: 0.9911\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0225 - binary_accuracy: 0.9911\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0226 - binary_accuracy: 0.9940\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0224 - binary_accuracy: 0.9911\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0222 - binary_accuracy: 0.9911\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0223 - binary_accuracy: 0.9911\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0222 - binary_accuracy: 0.9911\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0220 - binary_accuracy: 0.9911\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0220 - binary_accuracy: 0.9911\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0220 - binary_accuracy: 0.9911\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0218 - binary_accuracy: 0.9911\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0218 - binary_accuracy: 0.9911\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0218 - binary_accuracy: 0.9911\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0216 - binary_accuracy: 0.9911\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0216 - binary_accuracy: 0.9911\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0215 - binary_accuracy: 0.9911\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0215 - binary_accuracy: 0.9911\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0214 - binary_accuracy: 0.9911\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0213 - binary_accuracy: 0.9911\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0213 - binary_accuracy: 0.9911\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0212 - binary_accuracy: 0.9911\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0211 - binary_accuracy: 0.9911\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0211 - binary_accuracy: 0.9911\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0210 - binary_accuracy: 0.9911\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0209 - binary_accuracy: 0.9911\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0209 - binary_accuracy: 0.9911\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0208 - binary_accuracy: 0.9911\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0207 - binary_accuracy: 0.9911\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0206 - binary_accuracy: 0.9911\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0206 - binary_accuracy: 0.9911\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0205 - binary_accuracy: 0.9911\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0205 - binary_accuracy: 0.9911\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0204 - binary_accuracy: 0.9911\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0203 - binary_accuracy: 0.9911\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0203 - binary_accuracy: 0.9911\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0202 - binary_accuracy: 0.9911\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0201 - binary_accuracy: 0.9911\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0201 - binary_accuracy: 0.9911\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0200 - binary_accuracy: 0.9911\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0199 - binary_accuracy: 0.9911\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0199 - binary_accuracy: 0.9911\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0198 - binary_accuracy: 0.9911\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0198 - binary_accuracy: 0.9911\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0197 - binary_accuracy: 0.9911\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0196 - binary_accuracy: 0.9911\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0196 - binary_accuracy: 0.9911\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0195 - binary_accuracy: 0.9940\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0194 - binary_accuracy: 0.9911\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0194 - binary_accuracy: 0.9911\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0193 - binary_accuracy: 0.9940\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0192 - binary_accuracy: 0.9911\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0192 - binary_accuracy: 0.9940\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0191 - binary_accuracy: 0.9940\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0191 - binary_accuracy: 0.9940\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0190 - binary_accuracy: 0.9940\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0189 - binary_accuracy: 0.9940\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0189 - binary_accuracy: 0.9940\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0188 - binary_accuracy: 0.9940\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0187 - binary_accuracy: 0.9940\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0187 - binary_accuracy: 0.9940\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0186 - binary_accuracy: 0.9940\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0185 - binary_accuracy: 0.9940\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0185 - binary_accuracy: 0.9940\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0184 - binary_accuracy: 0.9940\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0184 - binary_accuracy: 0.9940\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0183 - binary_accuracy: 0.9940\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0182 - binary_accuracy: 0.9940\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0182 - binary_accuracy: 0.9940\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0181 - binary_accuracy: 0.9940\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0180 - binary_accuracy: 0.9940\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0180 - binary_accuracy: 0.9940\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0179 - binary_accuracy: 0.9940\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0179 - binary_accuracy: 0.9940\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0178 - binary_accuracy: 0.9940\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0178 - binary_accuracy: 0.9940\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0177 - binary_accuracy: 0.9940\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0176 - binary_accuracy: 0.9940\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0176 - binary_accuracy: 0.9940\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0175 - binary_accuracy: 0.9940\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0174 - binary_accuracy: 0.9940\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0174 - binary_accuracy: 0.9940\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0173 - binary_accuracy: 0.9940\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0172 - binary_accuracy: 0.9940\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0172 - binary_accuracy: 0.9940\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0171 - binary_accuracy: 0.9940\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0171 - binary_accuracy: 0.9940\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0170 - binary_accuracy: 0.9940\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0170 - binary_accuracy: 0.9940\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0169 - binary_accuracy: 0.9940\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0169 - binary_accuracy: 0.9940\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0168 - binary_accuracy: 0.9940\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0168 - binary_accuracy: 0.9940\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0168 - binary_accuracy: 0.9911\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0168 - binary_accuracy: 0.9940\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0169 - binary_accuracy: 0.9911\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0168 - binary_accuracy: 0.9970\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0166 - binary_accuracy: 0.9940\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0164 - binary_accuracy: 0.9940\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0163 - binary_accuracy: 0.9940\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0163 - binary_accuracy: 0.9940\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0164 - binary_accuracy: 0.9940\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0163 - binary_accuracy: 0.9940\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0161 - binary_accuracy: 0.9940\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0160 - binary_accuracy: 0.9940\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0160 - binary_accuracy: 0.9940\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0160 - binary_accuracy: 0.9940\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0160 - binary_accuracy: 0.9940\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0158 - binary_accuracy: 0.9940\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0157 - binary_accuracy: 0.9940\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0157 - binary_accuracy: 0.9940\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0157 - binary_accuracy: 0.9940\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0156 - binary_accuracy: 0.9940\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0156 - binary_accuracy: 0.9940\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0155 - binary_accuracy: 0.9940\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0154 - binary_accuracy: 0.9940\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0154 - binary_accuracy: 0.9940\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0153 - binary_accuracy: 0.9940\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0153 - binary_accuracy: 0.9940\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0152 - binary_accuracy: 0.9940\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0151 - binary_accuracy: 0.9940\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0151 - binary_accuracy: 0.9940\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0150 - binary_accuracy: 0.9940\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0150 - binary_accuracy: 0.9940\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0149 - binary_accuracy: 0.9940\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0149 - binary_accuracy: 0.9970\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0149 - binary_accuracy: 0.9940\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0148 - binary_accuracy: 0.9970\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0147 - binary_accuracy: 0.9940\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0147 - binary_accuracy: 0.9940\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0146 - binary_accuracy: 0.9940\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0145 - binary_accuracy: 0.9940\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0145 - binary_accuracy: 0.9970\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0145 - binary_accuracy: 0.9940\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0144 - binary_accuracy: 0.9970\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0144 - binary_accuracy: 0.9940\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0143 - binary_accuracy: 0.9970\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0142 - binary_accuracy: 0.9940\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0142 - binary_accuracy: 0.9970\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0141 - binary_accuracy: 0.9940\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0141 - binary_accuracy: 0.9970\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0140 - binary_accuracy: 0.9970\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0140 - binary_accuracy: 0.9970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2e19fd6830>"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_dim=4))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(32, activation='relu', input_dim=4))\n",
    "model.add(Dense(3,activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "model.fit(x_train,y_train,epochs=500,batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "0.9210526315789473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[12,  0,  0],\n",
       "       [ 0, 14,  0],\n",
       "       [ 0,  3,  9]])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "yy_pred = np.argmax(y_pred,axis=1)\n",
    "yy_test = np.argmax(y_test,axis=1)\n",
    "\n",
    "print(accuracy_score(yy_test,yy_pred))\n",
    "confusion_matrix(yy_test,yy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.6020966e-06, 9.9992770e-01, 5.3148720e-05],\n",
       "       [6.6270149e-09, 2.2084201e-02, 9.8279935e-01],\n",
       "       [7.4934636e-10, 3.7157659e-03, 9.9757677e-01],\n",
       "       [9.9958754e-01, 8.2937069e-04, 9.7464650e-08],\n",
       "       [7.9521256e-10, 1.2047476e-01, 9.1299713e-01],\n",
       "       [5.1793204e-06, 9.9968290e-01, 2.5715888e-04],\n",
       "       [3.6454610e-05, 9.9945444e-01, 8.5482607e-05],\n",
       "       [9.9965632e-01, 7.3935132e-04, 4.8321169e-08],\n",
       "       [4.6326207e-07, 9.9231827e-01, 8.3136428e-03],\n",
       "       [1.9117485e-04, 9.9978745e-01, 2.9552557e-05],\n",
       "       [9.9947906e-01, 2.0156903e-03, 2.8009495e-08],\n",
       "       [2.2993781e-07, 8.5837466e-01, 2.0617901e-01],\n",
       "       [9.9976617e-01, 4.1592849e-04, 3.1477271e-08],\n",
       "       [1.4878245e-04, 9.9923879e-01, 2.1009252e-04],\n",
       "       [1.6411866e-13, 4.7180527e-07, 9.9999982e-01],\n",
       "       [1.7360902e-04, 9.9953347e-01, 4.6914833e-05],\n",
       "       [3.1132036e-05, 9.9983960e-01, 4.8790087e-05],\n",
       "       [5.6844405e-05, 9.9980879e-01, 5.9852300e-05],\n",
       "       [3.6033746e-04, 9.9903804e-01, 3.0537303e-05],\n",
       "       [9.9492007e-01, 1.9697674e-02, 8.4255589e-07],\n",
       "       [2.0755537e-12, 2.2887936e-07, 9.9999982e-01],\n",
       "       [9.9944639e-01, 1.1297861e-03, 2.3035747e-07],\n",
       "       [5.0983374e-04, 9.9916518e-01, 1.3777814e-05],\n",
       "       [1.4025181e-13, 8.0192939e-07, 9.9999982e-01],\n",
       "       [1.0608958e-05, 9.9974447e-01, 1.0457918e-04],\n",
       "       [1.2095257e-03, 9.9907207e-01, 1.9947312e-05],\n",
       "       [9.9979562e-01, 3.8039719e-04, 7.6816091e-09],\n",
       "       [9.9984396e-01, 1.3643241e-04, 2.1428571e-08],\n",
       "       [9.9971157e-01, 4.6079059e-04, 4.0106450e-08],\n",
       "       [9.9933970e-01, 1.3342560e-03, 5.7597841e-08],\n",
       "       [1.3590834e-11, 4.7683622e-07, 9.9999952e-01],\n",
       "       [9.9942994e-01, 1.6846297e-03, 6.4090891e-08],\n",
       "       [5.6845213e-08, 9.1073257e-01, 1.4119257e-01],\n",
       "       [1.1252929e-02, 9.8677206e-01, 2.9086326e-05],\n",
       "       [9.9936908e-01, 1.7868681e-03, 8.5566533e-08],\n",
       "       [2.6796290e-10, 9.8143857e-05, 9.9994755e-01],\n",
       "       [1.8334919e-11, 1.8002488e-06, 9.9999833e-01],\n",
       "       [1.3760295e-08, 9.4803333e-01, 7.3540725e-02]], dtype=float32)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Large Example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "x_digits = digits['data']\n",
    "y_digits = digits['target']\n",
    "\n",
    "labeler = LabelBinarizer()\n",
    "\n",
    "yy_digits = labeler.fit_transform(y_digits)\n",
    "xx_digits = x_digits.reshape(1797,8,8,1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(xx_digits, yy_digits)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 2), padding=\"same\", activation='relu', input_shape=(8,8,1)))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0034 - binary_accuracy: 0.9999\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0030 - binary_accuracy: 0.9999\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0029 - binary_accuracy: 0.9999\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0026 - binary_accuracy: 0.9999\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0023 - binary_accuracy: 0.9999\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0022 - binary_accuracy: 0.9999\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0021 - binary_accuracy: 0.9999\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0027 - binary_accuracy: 0.9999\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0021 - binary_accuracy: 0.9999\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0019 - binary_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2e181a1f60>"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 878us/step\n",
      "0.9866666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[43,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 35,  0,  0,  0,  0,  0,  0,  1,  0],\n",
       "       [ 0,  0, 51,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 46,  0,  1,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 40,  0,  0,  1,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0, 50,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  1,  0, 46,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 46,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 50,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 37]])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "yy_pred = np.argmax(y_pred,axis=1)\n",
    "yy_test = np.argmax(y_test,axis=1)\n",
    "\n",
    "print(accuracy_score(yy_test,yy_pred))\n",
    "confusion_matrix(yy_test,yy_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yet Another Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = fetch_olivetti_faces(data_home='/home/kaygun/local/data/scikit_learn_data/')\n",
    "binarizer = LabelBinarizer()\n",
    "\n",
    "y = binarizer.fit_transform(faces.target.flatten()).reshape(-1,40)\n",
    "X = faces.data.flatten().reshape(-1,4096)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 [==============================] - 1s 34ms/step - loss: 3.7890 - val_loss: 3.7932\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7241 - val_loss: 3.8330\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6978 - val_loss: 3.7112\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6716 - val_loss: 3.7299\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6609 - val_loss: 3.6748\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.6627 - val_loss: 3.6749\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.6433 - val_loss: 3.6804\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6359 - val_loss: 3.6690\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6206 - val_loss: 3.6894\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6018 - val_loss: 3.6585\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5838 - val_loss: 3.6776\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5502 - val_loss: 3.6205\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5061 - val_loss: 3.6129\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4759 - val_loss: 3.6675\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.4372 - val_loss: 3.5763\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.3888 - val_loss: 3.5753\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.3316 - val_loss: 3.5537\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.2860 - val_loss: 3.4908\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.2448 - val_loss: 3.5473\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.1951 - val_loss: 3.4543\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.1331 - val_loss: 3.3836\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.0404 - val_loss: 3.4049\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.9480 - val_loss: 3.4422\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.9141 - val_loss: 3.2968\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.8498 - val_loss: 3.1909\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.7232 - val_loss: 3.2316\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.6678 - val_loss: 3.1588\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.6372 - val_loss: 3.3682\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.5934 - val_loss: 3.0974\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.4954 - val_loss: 2.8614\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.3541 - val_loss: 2.7750\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.2651 - val_loss: 2.7644\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.2156 - val_loss: 2.6203\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.0557 - val_loss: 2.5837\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.0262 - val_loss: 2.5029\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.9101 - val_loss: 2.4468\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.7837 - val_loss: 2.3109\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.7968 - val_loss: 2.3597\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.6822 - val_loss: 2.3571\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.7086 - val_loss: 2.2971\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.6753 - val_loss: 2.1300\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.5931 - val_loss: 2.1406\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.6133 - val_loss: 2.0195\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.4591 - val_loss: 2.1844\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.4052 - val_loss: 1.9003\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.2960 - val_loss: 1.9024\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.2522 - val_loss: 1.8607\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.1955 - val_loss: 1.7982\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.1309 - val_loss: 1.6979\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.1240 - val_loss: 1.6751\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0564 - val_loss: 1.6248\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.0489 - val_loss: 1.5813\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9729 - val_loss: 1.6272\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.9348 - val_loss: 1.5758\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.9174 - val_loss: 1.5793\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8831 - val_loss: 1.5152\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.8489 - val_loss: 1.4847\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7920 - val_loss: 1.3528\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7117 - val_loss: 1.2916\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6850 - val_loss: 1.5229\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7105 - val_loss: 1.3950\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7358 - val_loss: 1.2972\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6472 - val_loss: 1.2092\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5972 - val_loss: 1.3472\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5746 - val_loss: 1.1594\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5273 - val_loss: 1.2384\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4994 - val_loss: 1.1137\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5193 - val_loss: 1.0992\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5332 - val_loss: 1.3243\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5620 - val_loss: 1.1465\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4272 - val_loss: 0.9918\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3715 - val_loss: 0.9990\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4128 - val_loss: 1.1149\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3740 - val_loss: 1.0395\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3685 - val_loss: 1.1745\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4100 - val_loss: 1.0248\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3320 - val_loss: 0.9178\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3072 - val_loss: 0.9055\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2834 - val_loss: 1.0510\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3227 - val_loss: 0.9156\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2822 - val_loss: 0.8568\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2581 - val_loss: 0.8936\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2444 - val_loss: 0.8195\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2137 - val_loss: 0.7847\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1961 - val_loss: 0.8052\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1996 - val_loss: 0.7788\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1759 - val_loss: 0.7887\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1753 - val_loss: 0.7644\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1660 - val_loss: 0.8244\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1654 - val_loss: 0.7323\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1548 - val_loss: 0.7547\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1527 - val_loss: 0.7701\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1453 - val_loss: 0.7123\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1395 - val_loss: 0.7635\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1417 - val_loss: 0.6937\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1283 - val_loss: 0.7370\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1213 - val_loss: 0.7117\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1120 - val_loss: 0.6882\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1131 - val_loss: 0.7203\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1081 - val_loss: 0.6742\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1008 - val_loss: 0.7189\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0975 - val_loss: 0.6654\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0919 - val_loss: 0.7065\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0909 - val_loss: 0.6739\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0917 - val_loss: 0.7038\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0860 - val_loss: 0.6763\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0880 - val_loss: 0.6791\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0784 - val_loss: 0.6519\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0725 - val_loss: 0.6429\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0649 - val_loss: 0.6612\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0668 - val_loss: 0.6471\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0676 - val_loss: 0.6423\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0636 - val_loss: 0.7050\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0613 - val_loss: 0.6287\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0586 - val_loss: 0.6429\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0685 - val_loss: 0.6537\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0575 - val_loss: 0.6343\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0535 - val_loss: 0.6481\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0503 - val_loss: 0.5980\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0483 - val_loss: 0.6074\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0446 - val_loss: 0.6127\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0436 - val_loss: 0.6262\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0453 - val_loss: 0.6035\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0402 - val_loss: 0.6259\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0399 - val_loss: 0.6097\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0381 - val_loss: 0.5911\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0367 - val_loss: 0.6117\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0361 - val_loss: 0.5981\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0341 - val_loss: 0.5861\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0352 - val_loss: 0.6020\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0326 - val_loss: 0.6155\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0311 - val_loss: 0.5947\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0308 - val_loss: 0.6002\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0291 - val_loss: 0.5797\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0291 - val_loss: 0.6061\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0276 - val_loss: 0.5709\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0277 - val_loss: 0.5807\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0284 - val_loss: 0.5965\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0263 - val_loss: 0.5817\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0250 - val_loss: 0.5854\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0248 - val_loss: 0.5903\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0242 - val_loss: 0.5820\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0238 - val_loss: 0.5685\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0231 - val_loss: 0.5967\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0224 - val_loss: 0.5834\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0231 - val_loss: 0.5943\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0226 - val_loss: 0.5794\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0209 - val_loss: 0.5707\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0203 - val_loss: 0.5928\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0197 - val_loss: 0.5740\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0190 - val_loss: 0.5843\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0189 - val_loss: 0.5823\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0180 - val_loss: 0.5583\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0178 - val_loss: 0.5947\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0172 - val_loss: 0.5706\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0168 - val_loss: 0.5561\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0168 - val_loss: 0.5814\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.5820\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.5634\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0153 - val_loss: 0.5757\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0151 - val_loss: 0.5685\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.5748\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0149 - val_loss: 0.5646\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0148 - val_loss: 0.5861\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.5580\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.5720\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0135 - val_loss: 0.5767\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.5653\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0129 - val_loss: 0.5550\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.5599\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.5745\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.5663\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.5609\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.5546\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.5696\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0114 - val_loss: 0.5602\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0110 - val_loss: 0.5672\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.5598\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.5603\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.5785\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.5480\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.5676\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.5627\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.5650\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.5731\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.5472\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.5508\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.5796\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.5543\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.5646\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.5592\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.5502\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.5774\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0085 - val_loss: 0.5543\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.5520\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0081 - val_loss: 0.5620\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.5610\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.5595\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.5633\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.5524\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0075 - val_loss: 0.5639\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0074 - val_loss: 0.5635\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0075 - val_loss: 0.5510\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0073 - val_loss: 0.5576\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.5712\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0071 - val_loss: 0.5530\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.5614\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0069 - val_loss: 0.5568\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0069 - val_loss: 0.5543\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0070 - val_loss: 0.5641\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.5453\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.5651\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0065 - val_loss: 0.5635\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0063 - val_loss: 0.5550\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0062 - val_loss: 0.5511\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.5610\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0060 - val_loss: 0.5585\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0061 - val_loss: 0.5472\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0060 - val_loss: 0.5575\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0059 - val_loss: 0.5629\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0058 - val_loss: 0.5603\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0057 - val_loss: 0.5520\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0056 - val_loss: 0.5496\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0056 - val_loss: 0.5489\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.5603\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.5478\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.5524\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0052 - val_loss: 0.5563\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0053 - val_loss: 0.5492\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0052 - val_loss: 0.5554\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0051 - val_loss: 0.5605\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.5495\n",
      "Epoch 233/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.5508\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.5529\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0048 - val_loss: 0.5545\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0048 - val_loss: 0.5528\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0047 - val_loss: 0.5514\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0046 - val_loss: 0.5535\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0047 - val_loss: 0.5651\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.5467\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.5448\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0045 - val_loss: 0.5665\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0045 - val_loss: 0.5589\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0044 - val_loss: 0.5441\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0044 - val_loss: 0.5528\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0043 - val_loss: 0.5597\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0042 - val_loss: 0.5533\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0042 - val_loss: 0.5540\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0042 - val_loss: 0.5448\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.5551\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0040 - val_loss: 0.5584\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0040 - val_loss: 0.5472\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0040 - val_loss: 0.5595\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.5508\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0039 - val_loss: 0.5457\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0038 - val_loss: 0.5549\n",
      "Epoch 257/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0038 - val_loss: 0.5487\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0037 - val_loss: 0.5477\n",
      "Epoch 259/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0037 - val_loss: 0.5581\n",
      "Epoch 260/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0037 - val_loss: 0.5562\n",
      "Epoch 261/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0037 - val_loss: 0.5397\n",
      "Epoch 262/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0036 - val_loss: 0.5557\n",
      "Epoch 263/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0036 - val_loss: 0.5553\n",
      "Epoch 264/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.5485\n",
      "Epoch 265/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0035 - val_loss: 0.5445\n",
      "Epoch 266/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.5549\n",
      "Epoch 267/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.5506\n",
      "Epoch 268/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.5530\n",
      "Epoch 269/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0033 - val_loss: 0.5593\n",
      "Epoch 270/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0033 - val_loss: 0.5526\n",
      "Epoch 271/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0032 - val_loss: 0.5488\n",
      "Epoch 272/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0033 - val_loss: 0.5480\n",
      "Epoch 273/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0032 - val_loss: 0.5483\n",
      "Epoch 274/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0032 - val_loss: 0.5589\n",
      "Epoch 275/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0032 - val_loss: 0.5462\n",
      "Epoch 276/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0031 - val_loss: 0.5490\n",
      "Epoch 277/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0031 - val_loss: 0.5518\n",
      "Epoch 278/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0031 - val_loss: 0.5565\n",
      "Epoch 279/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.5419\n",
      "Epoch 280/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.5575\n",
      "Epoch 281/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.5525\n",
      "Epoch 282/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 0.5420\n",
      "Epoch 283/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.5474\n",
      "Epoch 284/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.5566\n",
      "Epoch 285/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.5514\n",
      "Epoch 286/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.5455\n",
      "Epoch 287/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.5519\n",
      "Epoch 288/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0028 - val_loss: 0.5525\n",
      "Epoch 289/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.5467\n",
      "Epoch 290/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 0.5472\n",
      "Epoch 291/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0027 - val_loss: 0.5478\n",
      "Epoch 292/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0027 - val_loss: 0.5472\n",
      "Epoch 293/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.5517\n",
      "Epoch 294/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.5498\n",
      "Epoch 295/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.5426\n",
      "Epoch 296/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.5543\n",
      "Epoch 297/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0026 - val_loss: 0.5528\n",
      "Epoch 298/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.5438\n",
      "Epoch 299/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.5491\n",
      "Epoch 300/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 0.5554\n",
      "Epoch 301/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.5491\n",
      "Epoch 302/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 0.5451\n",
      "Epoch 303/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.5528\n",
      "Epoch 304/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.5546\n",
      "Epoch 305/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.5522\n",
      "Epoch 306/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.5418\n",
      "Epoch 307/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.5514\n",
      "Epoch 308/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.5545\n",
      "Epoch 309/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.5579\n",
      "Epoch 310/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.5406\n",
      "Epoch 311/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 0.5400\n",
      "Epoch 312/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.5545\n",
      "Epoch 313/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.5584\n",
      "Epoch 314/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.5419\n",
      "Epoch 315/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.5466\n",
      "Epoch 316/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0022 - val_loss: 0.5489\n",
      "Epoch 317/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.5493\n",
      "Epoch 318/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.5446\n",
      "Epoch 319/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.5465\n",
      "Epoch 320/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.5484\n",
      "Epoch 321/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.5543\n",
      "Epoch 322/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.5513\n",
      "Epoch 323/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.5450\n",
      "Epoch 324/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.5496\n",
      "Epoch 325/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.5480\n",
      "Epoch 326/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.5455\n",
      "Epoch 327/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.5439\n",
      "Epoch 328/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.5490\n",
      "Epoch 329/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.5469\n",
      "Epoch 330/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.5550\n",
      "Epoch 331/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.5474\n",
      "Epoch 332/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.5492\n",
      "Epoch 333/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.5545\n",
      "Epoch 334/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.5545\n",
      "Epoch 335/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.5505\n",
      "Epoch 336/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.5471\n",
      "Epoch 337/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.5518\n",
      "Epoch 338/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.5537\n",
      "Epoch 339/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.5407\n",
      "Epoch 340/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - val_loss: 0.5473\n",
      "Epoch 341/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.5618\n",
      "Epoch 342/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.5517\n",
      "Epoch 343/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.5387\n",
      "Epoch 344/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.5520\n",
      "Epoch 345/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 0.5577\n",
      "Epoch 346/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 0.5426\n",
      "Epoch 347/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.5495\n",
      "Epoch 348/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.5474\n",
      "Epoch 349/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.5507\n",
      "Epoch 350/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.5472\n",
      "Epoch 351/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.5481\n",
      "Epoch 352/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.5438\n",
      "Epoch 353/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.5507\n",
      "Epoch 354/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.5501\n",
      "Epoch 355/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.5520\n",
      "Epoch 356/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.5493\n",
      "Epoch 357/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0016 - val_loss: 0.5491\n",
      "Epoch 358/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.5471\n",
      "Epoch 359/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.5498\n",
      "Epoch 360/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.5545\n",
      "Epoch 361/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.5526\n",
      "Epoch 362/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.5498\n",
      "Epoch 363/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.5535\n",
      "Epoch 364/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.5517\n",
      "Epoch 365/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.5475\n",
      "Epoch 366/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.5522\n",
      "Epoch 367/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.5508\n",
      "Epoch 368/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.5508\n",
      "Epoch 369/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.5499\n",
      "Epoch 370/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.5523\n",
      "Epoch 371/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.5476\n",
      "Epoch 372/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.5452\n",
      "Epoch 373/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.5502\n",
      "Epoch 374/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.5508\n",
      "Epoch 375/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.5453\n",
      "Epoch 376/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.5517\n",
      "Epoch 377/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.5510\n",
      "Epoch 378/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.5512\n",
      "Epoch 379/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.5556\n",
      "Epoch 380/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.5496\n",
      "Epoch 381/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.5458\n",
      "Epoch 382/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.5531\n",
      "Epoch 383/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.5523\n",
      "Epoch 384/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.5524\n",
      "Epoch 385/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.5470\n",
      "Epoch 386/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.5458\n",
      "Epoch 387/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.5541\n",
      "Epoch 388/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.5508\n",
      "Epoch 389/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.5442\n",
      "Epoch 390/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.5493\n",
      "Epoch 391/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.5514\n",
      "Epoch 392/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.5483\n",
      "Epoch 393/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.5487\n",
      "Epoch 394/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.5521\n",
      "Epoch 395/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.5482\n",
      "Epoch 396/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.5546\n",
      "Epoch 397/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.5564\n",
      "Epoch 398/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.5437\n",
      "Epoch 399/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.5505\n",
      "Epoch 400/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.5569\n",
      "Epoch 401/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.5503\n",
      "Epoch 402/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.5468\n",
      "Epoch 403/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.5517\n",
      "Epoch 404/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.5510\n",
      "Epoch 405/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.5493\n",
      "Epoch 406/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.5555\n",
      "Epoch 407/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.5545\n",
      "Epoch 408/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.5456\n",
      "Epoch 409/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.5471\n",
      "Epoch 410/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.5544\n",
      "Epoch 411/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.5474\n",
      "Epoch 412/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.5518\n",
      "Epoch 413/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.5508\n",
      "Epoch 414/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.5567\n",
      "Epoch 415/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.5546\n",
      "Epoch 416/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.5470\n",
      "Epoch 417/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.5505\n",
      "Epoch 418/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.5560\n",
      "Epoch 419/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.5546\n",
      "Epoch 420/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.5540\n",
      "Epoch 421/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.5512\n",
      "Epoch 422/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.5509\n",
      "Epoch 423/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 0.5524\n",
      "Epoch 424/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 0.5505\n",
      "Epoch 425/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.9838e-04 - val_loss: 0.5514\n",
      "Epoch 426/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.9032e-04 - val_loss: 0.5532\n",
      "Epoch 427/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.9436e-04 - val_loss: 0.5485\n",
      "Epoch 428/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 9.7461e-04 - val_loss: 0.5484\n",
      "Epoch 429/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 9.7743e-04 - val_loss: 0.5507\n",
      "Epoch 430/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 9.6346e-04 - val_loss: 0.5496\n",
      "Epoch 431/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 9.6607e-04 - val_loss: 0.5516\n",
      "Epoch 432/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 9.4856e-04 - val_loss: 0.5526\n",
      "Epoch 433/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 9.5196e-04 - val_loss: 0.5526\n",
      "Epoch 434/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 9.5341e-04 - val_loss: 0.5472\n",
      "Epoch 435/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.4285e-04 - val_loss: 0.5593\n",
      "Epoch 436/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.3109e-04 - val_loss: 0.5521\n",
      "Epoch 437/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.2637e-04 - val_loss: 0.5478\n",
      "Epoch 438/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.2873e-04 - val_loss: 0.5464\n",
      "Epoch 439/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.1879e-04 - val_loss: 0.5523\n",
      "Epoch 440/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.0986e-04 - val_loss: 0.5549\n",
      "Epoch 441/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.0919e-04 - val_loss: 0.5518\n",
      "Epoch 442/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.9685e-04 - val_loss: 0.5488\n",
      "Epoch 443/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.9600e-04 - val_loss: 0.5473\n",
      "Epoch 444/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.8573e-04 - val_loss: 0.5539\n",
      "Epoch 445/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 8.8402e-04 - val_loss: 0.5566\n",
      "Epoch 446/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.7722e-04 - val_loss: 0.5441\n",
      "Epoch 447/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.7242e-04 - val_loss: 0.5486\n",
      "Epoch 448/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.7061e-04 - val_loss: 0.5540\n",
      "Epoch 449/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.5964e-04 - val_loss: 0.5482\n",
      "Epoch 450/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.6491e-04 - val_loss: 0.5477\n",
      "Epoch 451/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.5239e-04 - val_loss: 0.5540\n",
      "Epoch 452/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.4897e-04 - val_loss: 0.5554\n",
      "Epoch 453/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.4222e-04 - val_loss: 0.5487\n",
      "Epoch 454/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.3943e-04 - val_loss: 0.5481\n",
      "Epoch 455/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.2995e-04 - val_loss: 0.5508\n",
      "Epoch 456/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.2882e-04 - val_loss: 0.5499\n",
      "Epoch 457/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.2197e-04 - val_loss: 0.5516\n",
      "Epoch 458/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.1900e-04 - val_loss: 0.5519\n",
      "Epoch 459/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.1120e-04 - val_loss: 0.5482\n",
      "Epoch 460/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.0794e-04 - val_loss: 0.5510\n",
      "Epoch 461/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.0266e-04 - val_loss: 0.5504\n",
      "Epoch 462/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.9970e-04 - val_loss: 0.5492\n",
      "Epoch 463/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.9368e-04 - val_loss: 0.5521\n",
      "Epoch 464/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.9036e-04 - val_loss: 0.5517\n",
      "Epoch 465/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.8547e-04 - val_loss: 0.5522\n",
      "Epoch 466/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.8071e-04 - val_loss: 0.5497\n",
      "Epoch 467/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 7.7598e-04 - val_loss: 0.5478\n",
      "Epoch 468/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.7274e-04 - val_loss: 0.5532\n",
      "Epoch 469/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.6638e-04 - val_loss: 0.5527\n",
      "Epoch 470/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.6580e-04 - val_loss: 0.5474\n",
      "Epoch 471/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.6107e-04 - val_loss: 0.5491\n",
      "Epoch 472/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.5494e-04 - val_loss: 0.5535\n",
      "Epoch 473/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.5241e-04 - val_loss: 0.5485\n",
      "Epoch 474/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.4505e-04 - val_loss: 0.5496\n",
      "Epoch 475/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.4058e-04 - val_loss: 0.5517\n",
      "Epoch 476/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4276e-04 - val_loss: 0.5496\n",
      "Epoch 477/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.3556e-04 - val_loss: 0.5493\n",
      "Epoch 478/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.3013e-04 - val_loss: 0.5482\n",
      "Epoch 479/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.2532e-04 - val_loss: 0.5498\n",
      "Epoch 480/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.2347e-04 - val_loss: 0.5489\n",
      "Epoch 481/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.2105e-04 - val_loss: 0.5503\n",
      "Epoch 482/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.1807e-04 - val_loss: 0.5551\n",
      "Epoch 483/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.1196e-04 - val_loss: 0.5502\n",
      "Epoch 484/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.1012e-04 - val_loss: 0.5513\n",
      "Epoch 485/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.0073e-04 - val_loss: 0.5563\n",
      "Epoch 486/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.9734e-04 - val_loss: 0.5520\n",
      "Epoch 487/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.0012e-04 - val_loss: 0.5450\n",
      "Epoch 488/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.9299e-04 - val_loss: 0.5500\n",
      "Epoch 489/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.8968e-04 - val_loss: 0.5562\n",
      "Epoch 490/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.8331e-04 - val_loss: 0.5529\n",
      "Epoch 491/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.8211e-04 - val_loss: 0.5503\n",
      "Epoch 492/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.7791e-04 - val_loss: 0.5511\n",
      "Epoch 493/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.7397e-04 - val_loss: 0.5502\n",
      "Epoch 494/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.6827e-04 - val_loss: 0.5522\n",
      "Epoch 495/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.6758e-04 - val_loss: 0.5548\n",
      "Epoch 496/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.6179e-04 - val_loss: 0.5542\n",
      "Epoch 497/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.5813e-04 - val_loss: 0.5457\n",
      "Epoch 498/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.5688e-04 - val_loss: 0.5491\n",
      "Epoch 499/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.5034e-04 - val_loss: 0.5537\n",
      "Epoch 500/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.4884e-04 - val_loss: 0.5521\n",
      "Epoch 501/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.4310e-04 - val_loss: 0.5498\n",
      "Epoch 502/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 6.4174e-04 - val_loss: 0.5535\n",
      "Epoch 503/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.4175e-04 - val_loss: 0.5511\n",
      "Epoch 504/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.4150e-04 - val_loss: 0.5518\n",
      "Epoch 505/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.3525e-04 - val_loss: 0.5504\n",
      "Epoch 506/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.2742e-04 - val_loss: 0.5494\n",
      "Epoch 507/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 6.2779e-04 - val_loss: 0.5468\n",
      "Epoch 508/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.1984e-04 - val_loss: 0.5546\n",
      "Epoch 509/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.1599e-04 - val_loss: 0.5517\n",
      "Epoch 510/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.1395e-04 - val_loss: 0.5510\n",
      "Epoch 511/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 6.1272e-04 - val_loss: 0.5560\n",
      "Epoch 512/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.1435e-04 - val_loss: 0.5487\n",
      "Epoch 513/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.0449e-04 - val_loss: 0.5509\n",
      "Epoch 514/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.0233e-04 - val_loss: 0.5533\n",
      "Epoch 515/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.0022e-04 - val_loss: 0.5501\n",
      "Epoch 516/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9411e-04 - val_loss: 0.5504\n",
      "Epoch 517/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.9372e-04 - val_loss: 0.5533\n",
      "Epoch 518/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.9060e-04 - val_loss: 0.5556\n",
      "Epoch 519/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.8485e-04 - val_loss: 0.5463\n",
      "Epoch 520/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8256e-04 - val_loss: 0.5462\n",
      "Epoch 521/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 5.8342e-04 - val_loss: 0.5581\n",
      "Epoch 522/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 5.8395e-04 - val_loss: 0.5575\n",
      "Epoch 523/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.7641e-04 - val_loss: 0.5483\n",
      "Epoch 524/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.7225e-04 - val_loss: 0.5509\n",
      "Epoch 525/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.6823e-04 - val_loss: 0.5543\n",
      "Epoch 526/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.6489e-04 - val_loss: 0.5546\n",
      "Epoch 527/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 5.6310e-04 - val_loss: 0.5555\n",
      "Epoch 528/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.5871e-04 - val_loss: 0.5462\n",
      "Epoch 529/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.5665e-04 - val_loss: 0.5473\n",
      "Epoch 530/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.5388e-04 - val_loss: 0.5578\n",
      "Epoch 531/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.5014e-04 - val_loss: 0.5556\n",
      "Epoch 532/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.4800e-04 - val_loss: 0.5532\n",
      "Epoch 533/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.4568e-04 - val_loss: 0.5523\n",
      "Epoch 534/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.4240e-04 - val_loss: 0.5531\n",
      "Epoch 535/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.3923e-04 - val_loss: 0.5532\n",
      "Epoch 536/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.3773e-04 - val_loss: 0.5557\n",
      "Epoch 537/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.3254e-04 - val_loss: 0.5538\n",
      "Epoch 538/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.2946e-04 - val_loss: 0.5556\n",
      "Epoch 539/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.3072e-04 - val_loss: 0.5547\n",
      "Epoch 540/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.2520e-04 - val_loss: 0.5571\n",
      "Epoch 541/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.2237e-04 - val_loss: 0.5512\n",
      "Epoch 542/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.1991e-04 - val_loss: 0.5505\n",
      "Epoch 543/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.1620e-04 - val_loss: 0.5570\n",
      "Epoch 544/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 5.1810e-04 - val_loss: 0.5565\n",
      "Epoch 545/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 5.1203e-04 - val_loss: 0.5534\n",
      "Epoch 546/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.1105e-04 - val_loss: 0.5533\n",
      "Epoch 547/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.0660e-04 - val_loss: 0.5541\n",
      "Epoch 548/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.0262e-04 - val_loss: 0.5549\n",
      "Epoch 549/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 5.0478e-04 - val_loss: 0.5598\n",
      "Epoch 550/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.0027e-04 - val_loss: 0.5544\n",
      "Epoch 551/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.9405e-04 - val_loss: 0.5506\n",
      "Epoch 552/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.9565e-04 - val_loss: 0.5520\n",
      "Epoch 553/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.9353e-04 - val_loss: 0.5581\n",
      "Epoch 554/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.9008e-04 - val_loss: 0.5566\n",
      "Epoch 555/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.8812e-04 - val_loss: 0.5510\n",
      "Epoch 556/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.8589e-04 - val_loss: 0.5534\n",
      "Epoch 557/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.8363e-04 - val_loss: 0.5589\n",
      "Epoch 558/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.7964e-04 - val_loss: 0.5558\n",
      "Epoch 559/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.7829e-04 - val_loss: 0.5530\n",
      "Epoch 560/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.7580e-04 - val_loss: 0.5572\n",
      "Epoch 561/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.7247e-04 - val_loss: 0.5561\n",
      "Epoch 562/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.7145e-04 - val_loss: 0.5523\n",
      "Epoch 563/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.7038e-04 - val_loss: 0.5512\n",
      "Epoch 564/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.6393e-04 - val_loss: 0.5580\n",
      "Epoch 565/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.6278e-04 - val_loss: 0.5616\n",
      "Epoch 566/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.6326e-04 - val_loss: 0.5598\n",
      "Epoch 567/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5961e-04 - val_loss: 0.5520\n",
      "Epoch 568/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5822e-04 - val_loss: 0.5522\n",
      "Epoch 569/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5616e-04 - val_loss: 0.5588\n",
      "Epoch 570/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5280e-04 - val_loss: 0.5591\n",
      "Epoch 571/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.5180e-04 - val_loss: 0.5541\n",
      "Epoch 572/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.4758e-04 - val_loss: 0.5543\n",
      "Epoch 573/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.4892e-04 - val_loss: 0.5600\n",
      "Epoch 574/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.4402e-04 - val_loss: 0.5589\n",
      "Epoch 575/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.4317e-04 - val_loss: 0.5562\n",
      "Epoch 576/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.4000e-04 - val_loss: 0.5515\n",
      "Epoch 577/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.3922e-04 - val_loss: 0.5568\n",
      "Epoch 578/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.3431e-04 - val_loss: 0.5597\n",
      "Epoch 579/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.3449e-04 - val_loss: 0.5631\n",
      "Epoch 580/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.3338e-04 - val_loss: 0.5547\n",
      "Epoch 581/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.2776e-04 - val_loss: 0.5532\n",
      "Epoch 582/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.2907e-04 - val_loss: 0.5584\n",
      "Epoch 583/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.2729e-04 - val_loss: 0.5603\n",
      "Epoch 584/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.2391e-04 - val_loss: 0.5579\n",
      "Epoch 585/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.1979e-04 - val_loss: 0.5537\n",
      "Epoch 586/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.2068e-04 - val_loss: 0.5530\n",
      "Epoch 587/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.1807e-04 - val_loss: 0.5612\n",
      "Epoch 588/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.1477e-04 - val_loss: 0.5564\n",
      "Epoch 589/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.1215e-04 - val_loss: 0.5585\n",
      "Epoch 590/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.0962e-04 - val_loss: 0.5569\n",
      "Epoch 591/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.0992e-04 - val_loss: 0.5553\n",
      "Epoch 592/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.0765e-04 - val_loss: 0.5567\n",
      "Epoch 593/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.0615e-04 - val_loss: 0.5585\n",
      "Epoch 594/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.0267e-04 - val_loss: 0.5568\n",
      "Epoch 595/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.0132e-04 - val_loss: 0.5608\n",
      "Epoch 596/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.9925e-04 - val_loss: 0.5578\n",
      "Epoch 597/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.9667e-04 - val_loss: 0.5594\n",
      "Epoch 598/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.9486e-04 - val_loss: 0.5573\n",
      "Epoch 599/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.9332e-04 - val_loss: 0.5557\n",
      "Epoch 600/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.9273e-04 - val_loss: 0.5540\n",
      "Epoch 601/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.9254e-04 - val_loss: 0.5600\n",
      "Epoch 602/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.8746e-04 - val_loss: 0.5613\n",
      "Epoch 603/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.8484e-04 - val_loss: 0.5561\n",
      "Epoch 604/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8480e-04 - val_loss: 0.5532\n",
      "Epoch 605/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.8212e-04 - val_loss: 0.5611\n",
      "Epoch 606/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.8175e-04 - val_loss: 0.5617\n",
      "Epoch 607/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7850e-04 - val_loss: 0.5565\n",
      "Epoch 608/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7719e-04 - val_loss: 0.5529\n",
      "Epoch 609/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7682e-04 - val_loss: 0.5608\n",
      "Epoch 610/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.7366e-04 - val_loss: 0.5645\n",
      "Epoch 611/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.7210e-04 - val_loss: 0.5616\n",
      "Epoch 612/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.6933e-04 - val_loss: 0.5586\n",
      "Epoch 613/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6920e-04 - val_loss: 0.5547\n",
      "Epoch 614/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.6548e-04 - val_loss: 0.5594\n",
      "Epoch 615/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.6688e-04 - val_loss: 0.5675\n",
      "Epoch 616/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.6401e-04 - val_loss: 0.5592\n",
      "Epoch 617/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.6237e-04 - val_loss: 0.5587\n",
      "Epoch 618/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.6068e-04 - val_loss: 0.5600\n",
      "Epoch 619/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5689e-04 - val_loss: 0.5578\n",
      "Epoch 620/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.5626e-04 - val_loss: 0.5597\n",
      "Epoch 621/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.5445e-04 - val_loss: 0.5620\n",
      "Epoch 622/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.5368e-04 - val_loss: 0.5601\n",
      "Epoch 623/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.5067e-04 - val_loss: 0.5580\n",
      "Epoch 624/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.4905e-04 - val_loss: 0.5559\n",
      "Epoch 625/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.4779e-04 - val_loss: 0.5606\n",
      "Epoch 626/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4753e-04 - val_loss: 0.5638\n",
      "Epoch 627/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.4842e-04 - val_loss: 0.5606\n",
      "Epoch 628/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.4421e-04 - val_loss: 0.5602\n",
      "Epoch 629/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.4272e-04 - val_loss: 0.5589\n",
      "Epoch 630/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.4018e-04 - val_loss: 0.5605\n",
      "Epoch 631/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.3948e-04 - val_loss: 0.5612\n",
      "Epoch 632/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.3876e-04 - val_loss: 0.5611\n",
      "Epoch 633/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.3502e-04 - val_loss: 0.5614\n",
      "Epoch 634/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.3393e-04 - val_loss: 0.5596\n",
      "Epoch 635/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.3317e-04 - val_loss: 0.5600\n",
      "Epoch 636/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.3092e-04 - val_loss: 0.5614\n",
      "Epoch 637/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.3032e-04 - val_loss: 0.5586\n",
      "Epoch 638/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.3008e-04 - val_loss: 0.5557\n",
      "Epoch 639/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.2761e-04 - val_loss: 0.5590\n",
      "Epoch 640/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.2656e-04 - val_loss: 0.5654\n",
      "Epoch 641/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.2423e-04 - val_loss: 0.5602\n",
      "Epoch 642/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.2218e-04 - val_loss: 0.5590\n",
      "Epoch 643/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.2301e-04 - val_loss: 0.5564\n",
      "Epoch 644/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.1925e-04 - val_loss: 0.5626\n",
      "Epoch 645/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.1823e-04 - val_loss: 0.5663\n",
      "Epoch 646/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.1669e-04 - val_loss: 0.5592\n",
      "Epoch 647/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.1639e-04 - val_loss: 0.5571\n",
      "Epoch 648/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.1368e-04 - val_loss: 0.5612\n",
      "Epoch 649/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.1339e-04 - val_loss: 0.5640\n",
      "Epoch 650/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.1129e-04 - val_loss: 0.5620\n",
      "Epoch 651/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.1091e-04 - val_loss: 0.5616\n",
      "Epoch 652/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.0928e-04 - val_loss: 0.5645\n",
      "Epoch 653/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3.0705e-04 - val_loss: 0.5613\n",
      "Epoch 654/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.0539e-04 - val_loss: 0.5600\n",
      "Epoch 655/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.0412e-04 - val_loss: 0.5606\n",
      "Epoch 656/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.0269e-04 - val_loss: 0.5633\n",
      "Epoch 657/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.0347e-04 - val_loss: 0.5584\n",
      "Epoch 658/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.0003e-04 - val_loss: 0.5661\n",
      "Epoch 659/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.9854e-04 - val_loss: 0.5664\n",
      "Epoch 660/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.0034e-04 - val_loss: 0.5608\n",
      "Epoch 661/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.9574e-04 - val_loss: 0.5610\n",
      "Epoch 662/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.9647e-04 - val_loss: 0.5578\n",
      "Epoch 663/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.9516e-04 - val_loss: 0.5611\n",
      "Epoch 664/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.9433e-04 - val_loss: 0.5630\n",
      "Epoch 665/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.9266e-04 - val_loss: 0.5600\n",
      "Epoch 666/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.8966e-04 - val_loss: 0.5611\n",
      "Epoch 667/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.8871e-04 - val_loss: 0.5628\n",
      "Epoch 668/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.8722e-04 - val_loss: 0.5679\n",
      "Epoch 669/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.8681e-04 - val_loss: 0.5649\n",
      "Epoch 670/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.8539e-04 - val_loss: 0.5587\n",
      "Epoch 671/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.8481e-04 - val_loss: 0.5639\n",
      "Epoch 672/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.8329e-04 - val_loss: 0.5603\n",
      "Epoch 673/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.8238e-04 - val_loss: 0.5591\n",
      "Epoch 674/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.7967e-04 - val_loss: 0.5642\n",
      "Epoch 675/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.7902e-04 - val_loss: 0.5651\n",
      "Epoch 676/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.7744e-04 - val_loss: 0.5630\n",
      "Epoch 677/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.7667e-04 - val_loss: 0.5613\n",
      "Epoch 678/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.7600e-04 - val_loss: 0.5602\n",
      "Epoch 679/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.7402e-04 - val_loss: 0.5649\n",
      "Epoch 680/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.7369e-04 - val_loss: 0.5664\n",
      "Epoch 681/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.7155e-04 - val_loss: 0.5636\n",
      "Epoch 682/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7057e-04 - val_loss: 0.5603\n",
      "Epoch 683/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.7024e-04 - val_loss: 0.5587\n",
      "Epoch 684/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.6868e-04 - val_loss: 0.5650\n",
      "Epoch 685/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.6749e-04 - val_loss: 0.5653\n",
      "Epoch 686/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.6536e-04 - val_loss: 0.5612\n",
      "Epoch 687/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.6609e-04 - val_loss: 0.5572\n",
      "Epoch 688/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.6580e-04 - val_loss: 0.5663\n",
      "Epoch 689/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.6349e-04 - val_loss: 0.5631\n",
      "Epoch 690/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.6172e-04 - val_loss: 0.5610\n",
      "Epoch 691/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.6133e-04 - val_loss: 0.5664\n",
      "Epoch 692/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.5936e-04 - val_loss: 0.5608\n",
      "Epoch 693/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.5828e-04 - val_loss: 0.5608\n",
      "Epoch 694/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.5858e-04 - val_loss: 0.5655\n",
      "Epoch 695/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.5672e-04 - val_loss: 0.5596\n",
      "Epoch 696/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.5464e-04 - val_loss: 0.5609\n",
      "Epoch 697/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.5313e-04 - val_loss: 0.5641\n",
      "Epoch 698/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5305e-04 - val_loss: 0.5627\n",
      "Epoch 699/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.5172e-04 - val_loss: 0.5627\n",
      "Epoch 700/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.5024e-04 - val_loss: 0.5619\n",
      "Epoch 701/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.5044e-04 - val_loss: 0.5649\n",
      "Epoch 702/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.4937e-04 - val_loss: 0.5629\n",
      "Epoch 703/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.4750e-04 - val_loss: 0.5624\n",
      "Epoch 704/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.4622e-04 - val_loss: 0.5622\n",
      "Epoch 705/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.4551e-04 - val_loss: 0.5659\n",
      "Epoch 706/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.4461e-04 - val_loss: 0.5648\n",
      "Epoch 707/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4366e-04 - val_loss: 0.5641\n",
      "Epoch 708/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4269e-04 - val_loss: 0.5608\n",
      "Epoch 709/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.4255e-04 - val_loss: 0.5641\n",
      "Epoch 710/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.4076e-04 - val_loss: 0.5608\n",
      "Epoch 711/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.3919e-04 - val_loss: 0.5629\n",
      "Epoch 712/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.3894e-04 - val_loss: 0.5655\n",
      "Epoch 713/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.3710e-04 - val_loss: 0.5647\n",
      "Epoch 714/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.3713e-04 - val_loss: 0.5620\n",
      "Epoch 715/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.3602e-04 - val_loss: 0.5601\n",
      "Epoch 716/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.3470e-04 - val_loss: 0.5625\n",
      "Epoch 717/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.3394e-04 - val_loss: 0.5627\n",
      "Epoch 718/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.3232e-04 - val_loss: 0.5649\n",
      "Epoch 719/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.3208e-04 - val_loss: 0.5661\n",
      "Epoch 720/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.3147e-04 - val_loss: 0.5639\n",
      "Epoch 721/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.2941e-04 - val_loss: 0.5653\n",
      "Epoch 722/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2818e-04 - val_loss: 0.5668\n",
      "Epoch 723/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.2768e-04 - val_loss: 0.5649\n",
      "Epoch 724/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2736e-04 - val_loss: 0.5608\n",
      "Epoch 725/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.2585e-04 - val_loss: 0.5611\n",
      "Epoch 726/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.2484e-04 - val_loss: 0.5648\n",
      "Epoch 727/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.2411e-04 - val_loss: 0.5664\n",
      "Epoch 728/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.2369e-04 - val_loss: 0.5650\n",
      "Epoch 729/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.2241e-04 - val_loss: 0.5683\n",
      "Epoch 730/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.2126e-04 - val_loss: 0.5644\n",
      "Epoch 731/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.2042e-04 - val_loss: 0.5627\n",
      "Epoch 732/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.1938e-04 - val_loss: 0.5629\n",
      "Epoch 733/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.1888e-04 - val_loss: 0.5649\n",
      "Epoch 734/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.1749e-04 - val_loss: 0.5637\n",
      "Epoch 735/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.1703e-04 - val_loss: 0.5667\n",
      "Epoch 736/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.1581e-04 - val_loss: 0.5658\n",
      "Epoch 737/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.1509e-04 - val_loss: 0.5651\n",
      "Epoch 738/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.1406e-04 - val_loss: 0.5657\n",
      "Epoch 739/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.1335e-04 - val_loss: 0.5641\n",
      "Epoch 740/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.1300e-04 - val_loss: 0.5643\n",
      "Epoch 741/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.1158e-04 - val_loss: 0.5684\n",
      "Epoch 742/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.1165e-04 - val_loss: 0.5674\n",
      "Epoch 743/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.1086e-04 - val_loss: 0.5587\n",
      "Epoch 744/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.0985e-04 - val_loss: 0.5609\n",
      "Epoch 745/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.0881e-04 - val_loss: 0.5678\n",
      "Epoch 746/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.0747e-04 - val_loss: 0.5683\n",
      "Epoch 747/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.0746e-04 - val_loss: 0.5634\n",
      "Epoch 748/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.0647e-04 - val_loss: 0.5620\n",
      "Epoch 749/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.0562e-04 - val_loss: 0.5676\n",
      "Epoch 750/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.0560e-04 - val_loss: 0.5683\n",
      "Epoch 751/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.0301e-04 - val_loss: 0.5654\n",
      "Epoch 752/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.0220e-04 - val_loss: 0.5644\n",
      "Epoch 753/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.0154e-04 - val_loss: 0.5673\n",
      "Epoch 754/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.0175e-04 - val_loss: 0.5670\n",
      "Epoch 755/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2.0082e-04 - val_loss: 0.5604\n",
      "Epoch 756/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.9932e-04 - val_loss: 0.5647\n",
      "Epoch 757/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9874e-04 - val_loss: 0.5678\n",
      "Epoch 758/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.9821e-04 - val_loss: 0.5647\n",
      "Epoch 759/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.9743e-04 - val_loss: 0.5673\n",
      "Epoch 760/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.9620e-04 - val_loss: 0.5655\n",
      "Epoch 761/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.9571e-04 - val_loss: 0.5613\n",
      "Epoch 762/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.9489e-04 - val_loss: 0.5639\n",
      "Epoch 763/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.9455e-04 - val_loss: 0.5700\n",
      "Epoch 764/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.9360e-04 - val_loss: 0.5664\n",
      "Epoch 765/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.9242e-04 - val_loss: 0.5623\n",
      "Epoch 766/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.9152e-04 - val_loss: 0.5642\n",
      "Epoch 767/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.9089e-04 - val_loss: 0.5690\n",
      "Epoch 768/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.9032e-04 - val_loss: 0.5642\n",
      "Epoch 769/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.8914e-04 - val_loss: 0.5652\n",
      "Epoch 770/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.8886e-04 - val_loss: 0.5645\n",
      "Epoch 771/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.8875e-04 - val_loss: 0.5686\n",
      "Epoch 772/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.8723e-04 - val_loss: 0.5648\n",
      "Epoch 773/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.8613e-04 - val_loss: 0.5661\n",
      "Epoch 774/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.8537e-04 - val_loss: 0.5658\n",
      "Epoch 775/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.8483e-04 - val_loss: 0.5650\n",
      "Epoch 776/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.8430e-04 - val_loss: 0.5671\n",
      "Epoch 777/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.8337e-04 - val_loss: 0.5691\n",
      "Epoch 778/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.8281e-04 - val_loss: 0.5687\n",
      "Epoch 779/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.8171e-04 - val_loss: 0.5647\n",
      "Epoch 780/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.8182e-04 - val_loss: 0.5642\n",
      "Epoch 781/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.8055e-04 - val_loss: 0.5643\n",
      "Epoch 782/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.8004e-04 - val_loss: 0.5673\n",
      "Epoch 783/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.7934e-04 - val_loss: 0.5686\n",
      "Epoch 784/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.7797e-04 - val_loss: 0.5688\n",
      "Epoch 785/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.7805e-04 - val_loss: 0.5631\n",
      "Epoch 786/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.7781e-04 - val_loss: 0.5621\n",
      "Epoch 787/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.7599e-04 - val_loss: 0.5694\n",
      "Epoch 788/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.7630e-04 - val_loss: 0.5722\n",
      "Epoch 789/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7532e-04 - val_loss: 0.5668\n",
      "Epoch 790/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.7506e-04 - val_loss: 0.5656\n",
      "Epoch 791/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.7373e-04 - val_loss: 0.5685\n",
      "Epoch 792/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.7277e-04 - val_loss: 0.5654\n",
      "Epoch 793/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.7254e-04 - val_loss: 0.5667\n",
      "Epoch 794/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.7244e-04 - val_loss: 0.5652\n",
      "Epoch 795/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.7099e-04 - val_loss: 0.5657\n",
      "Epoch 796/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.7016e-04 - val_loss: 0.5691\n",
      "Epoch 797/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.7045e-04 - val_loss: 0.5712\n",
      "Epoch 798/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.6875e-04 - val_loss: 0.5674\n",
      "Epoch 799/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6885e-04 - val_loss: 0.5657\n",
      "Epoch 800/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.6817e-04 - val_loss: 0.5682\n",
      "Epoch 801/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6689e-04 - val_loss: 0.5685\n",
      "Epoch 802/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.6687e-04 - val_loss: 0.5722\n",
      "Epoch 803/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.6602e-04 - val_loss: 0.5712\n",
      "Epoch 804/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.6506e-04 - val_loss: 0.5673\n",
      "Epoch 805/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.6524e-04 - val_loss: 0.5664\n",
      "Epoch 806/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.6472e-04 - val_loss: 0.5666\n",
      "Epoch 807/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.6385e-04 - val_loss: 0.5681\n",
      "Epoch 808/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.6277e-04 - val_loss: 0.5704\n",
      "Epoch 809/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.6224e-04 - val_loss: 0.5713\n",
      "Epoch 810/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.6158e-04 - val_loss: 0.5667\n",
      "Epoch 811/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.6087e-04 - val_loss: 0.5652\n",
      "Epoch 812/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.6048e-04 - val_loss: 0.5682\n",
      "Epoch 813/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.6009e-04 - val_loss: 0.5719\n",
      "Epoch 814/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.5952e-04 - val_loss: 0.5662\n",
      "Epoch 815/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.5862e-04 - val_loss: 0.5631\n",
      "Epoch 816/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5792e-04 - val_loss: 0.5682\n",
      "Epoch 817/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5666e-04 - val_loss: 0.5698\n",
      "Epoch 818/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.5718e-04 - val_loss: 0.5652\n",
      "Epoch 819/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.5673e-04 - val_loss: 0.5699\n",
      "Epoch 820/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5527e-04 - val_loss: 0.5691\n",
      "Epoch 821/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.5468e-04 - val_loss: 0.5660\n",
      "Epoch 822/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5424e-04 - val_loss: 0.5688\n",
      "Epoch 823/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5323e-04 - val_loss: 0.5713\n",
      "Epoch 824/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.5307e-04 - val_loss: 0.5698\n",
      "Epoch 825/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5244e-04 - val_loss: 0.5675\n",
      "Epoch 826/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.5207e-04 - val_loss: 0.5687\n",
      "Epoch 827/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5117e-04 - val_loss: 0.5697\n",
      "Epoch 828/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.5084e-04 - val_loss: 0.5712\n",
      "Epoch 829/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.5003e-04 - val_loss: 0.5725\n",
      "Epoch 830/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5059e-04 - val_loss: 0.5738\n",
      "Epoch 831/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.4922e-04 - val_loss: 0.5688\n",
      "Epoch 832/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.4845e-04 - val_loss: 0.5654\n",
      "Epoch 833/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.4749e-04 - val_loss: 0.5686\n",
      "Epoch 834/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.4733e-04 - val_loss: 0.5726\n",
      "Epoch 835/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.4673e-04 - val_loss: 0.5701\n",
      "Epoch 836/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.4673e-04 - val_loss: 0.5649\n",
      "Epoch 837/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.4545e-04 - val_loss: 0.5688\n",
      "Epoch 838/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.4491e-04 - val_loss: 0.5730\n",
      "Epoch 839/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.4484e-04 - val_loss: 0.5717\n",
      "Epoch 840/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4368e-04 - val_loss: 0.5675\n",
      "Epoch 841/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4333e-04 - val_loss: 0.5667\n",
      "Epoch 842/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.4277e-04 - val_loss: 0.5700\n",
      "Epoch 843/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.4207e-04 - val_loss: 0.5696\n",
      "Epoch 844/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.4151e-04 - val_loss: 0.5670\n",
      "Epoch 845/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.4111e-04 - val_loss: 0.5682\n",
      "Epoch 846/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4061e-04 - val_loss: 0.5710\n",
      "Epoch 847/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.4027e-04 - val_loss: 0.5704\n",
      "Epoch 848/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.4003e-04 - val_loss: 0.5729\n",
      "Epoch 849/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.3934e-04 - val_loss: 0.5691\n",
      "Epoch 850/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.3926e-04 - val_loss: 0.5645\n",
      "Epoch 851/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.3859e-04 - val_loss: 0.5717\n",
      "Epoch 852/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.3740e-04 - val_loss: 0.5733\n",
      "Epoch 853/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.3719e-04 - val_loss: 0.5698\n",
      "Epoch 854/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.3657e-04 - val_loss: 0.5686\n",
      "Epoch 855/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.3604e-04 - val_loss: 0.5714\n",
      "Epoch 856/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.3609e-04 - val_loss: 0.5729\n",
      "Epoch 857/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.3494e-04 - val_loss: 0.5680\n",
      "Epoch 858/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.3513e-04 - val_loss: 0.5678\n",
      "Epoch 859/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.3494e-04 - val_loss: 0.5761\n",
      "Epoch 860/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.3395e-04 - val_loss: 0.5748\n",
      "Epoch 861/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.3295e-04 - val_loss: 0.5692\n",
      "Epoch 862/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.3277e-04 - val_loss: 0.5659\n",
      "Epoch 863/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.3245e-04 - val_loss: 0.5695\n",
      "Epoch 864/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.3182e-04 - val_loss: 0.5754\n",
      "Epoch 865/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.3136e-04 - val_loss: 0.5731\n",
      "Epoch 866/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.3078e-04 - val_loss: 0.5684\n",
      "Epoch 867/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.3003e-04 - val_loss: 0.5706\n",
      "Epoch 868/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.2972e-04 - val_loss: 0.5728\n",
      "Epoch 869/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.2913e-04 - val_loss: 0.5714\n",
      "Epoch 870/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.2902e-04 - val_loss: 0.5685\n",
      "Epoch 871/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.2852e-04 - val_loss: 0.5698\n",
      "Epoch 872/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.2768e-04 - val_loss: 0.5733\n",
      "Epoch 873/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.2711e-04 - val_loss: 0.5727\n",
      "Epoch 874/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.2708e-04 - val_loss: 0.5670\n",
      "Epoch 875/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.2618e-04 - val_loss: 0.5696\n",
      "Epoch 876/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.2630e-04 - val_loss: 0.5712\n",
      "Epoch 877/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.2514e-04 - val_loss: 0.5701\n",
      "Epoch 878/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.2556e-04 - val_loss: 0.5660\n",
      "Epoch 879/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.2439e-04 - val_loss: 0.5729\n",
      "Epoch 880/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.2383e-04 - val_loss: 0.5739\n",
      "Epoch 881/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.2383e-04 - val_loss: 0.5739\n",
      "Epoch 882/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.2355e-04 - val_loss: 0.5685\n",
      "Epoch 883/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.2274e-04 - val_loss: 0.5656\n",
      "Epoch 884/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.2203e-04 - val_loss: 0.5716\n",
      "Epoch 885/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.2156e-04 - val_loss: 0.5721\n",
      "Epoch 886/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.2106e-04 - val_loss: 0.5723\n",
      "Epoch 887/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.2087e-04 - val_loss: 0.5714\n",
      "Epoch 888/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.2043e-04 - val_loss: 0.5693\n",
      "Epoch 889/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1998e-04 - val_loss: 0.5690\n",
      "Epoch 890/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1958e-04 - val_loss: 0.5743\n",
      "Epoch 891/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.1902e-04 - val_loss: 0.5750\n",
      "Epoch 892/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.1867e-04 - val_loss: 0.5711\n",
      "Epoch 893/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1840e-04 - val_loss: 0.5678\n",
      "Epoch 894/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.1785e-04 - val_loss: 0.5696\n",
      "Epoch 895/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1716e-04 - val_loss: 0.5700\n",
      "Epoch 896/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.1673e-04 - val_loss: 0.5698\n",
      "Epoch 897/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.1647e-04 - val_loss: 0.5699\n",
      "Epoch 898/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1584e-04 - val_loss: 0.5723\n",
      "Epoch 899/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1581e-04 - val_loss: 0.5691\n",
      "Epoch 900/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.1520e-04 - val_loss: 0.5719\n",
      "Epoch 901/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1473e-04 - val_loss: 0.5714\n",
      "Epoch 902/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1419e-04 - val_loss: 0.5715\n",
      "Epoch 903/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.1403e-04 - val_loss: 0.5713\n",
      "Epoch 904/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.1362e-04 - val_loss: 0.5712\n",
      "Epoch 905/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.1300e-04 - val_loss: 0.5726\n",
      "Epoch 906/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.1268e-04 - val_loss: 0.5719\n",
      "Epoch 907/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.1219e-04 - val_loss: 0.5718\n",
      "Epoch 908/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1199e-04 - val_loss: 0.5704\n",
      "Epoch 909/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.1141e-04 - val_loss: 0.5682\n",
      "Epoch 910/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.1138e-04 - val_loss: 0.5700\n",
      "Epoch 911/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1068e-04 - val_loss: 0.5710\n",
      "Epoch 912/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.1064e-04 - val_loss: 0.5764\n",
      "Epoch 913/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.1025e-04 - val_loss: 0.5698\n",
      "Epoch 914/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0956e-04 - val_loss: 0.5690\n",
      "Epoch 915/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0945e-04 - val_loss: 0.5753\n",
      "Epoch 916/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0895e-04 - val_loss: 0.5750\n",
      "Epoch 917/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0822e-04 - val_loss: 0.5699\n",
      "Epoch 918/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0801e-04 - val_loss: 0.5680\n",
      "Epoch 919/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0813e-04 - val_loss: 0.5746\n",
      "Epoch 920/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0722e-04 - val_loss: 0.5702\n",
      "Epoch 921/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0725e-04 - val_loss: 0.5709\n",
      "Epoch 922/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0650e-04 - val_loss: 0.5725\n",
      "Epoch 923/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0613e-04 - val_loss: 0.5731\n",
      "Epoch 924/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0580e-04 - val_loss: 0.5739\n",
      "Epoch 925/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.0540e-04 - val_loss: 0.5711\n",
      "Epoch 926/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0497e-04 - val_loss: 0.5717\n",
      "Epoch 927/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0463e-04 - val_loss: 0.5712\n",
      "Epoch 928/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0470e-04 - val_loss: 0.5755\n",
      "Epoch 929/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0382e-04 - val_loss: 0.5709\n",
      "Epoch 930/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0337e-04 - val_loss: 0.5722\n",
      "Epoch 931/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0316e-04 - val_loss: 0.5726\n",
      "Epoch 932/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.0277e-04 - val_loss: 0.5751\n",
      "Epoch 933/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0228e-04 - val_loss: 0.5721\n",
      "Epoch 934/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0191e-04 - val_loss: 0.5706\n",
      "Epoch 935/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0167e-04 - val_loss: 0.5744\n",
      "Epoch 936/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0153e-04 - val_loss: 0.5733\n",
      "Epoch 937/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.0087e-04 - val_loss: 0.5725\n",
      "Epoch 938/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0058e-04 - val_loss: 0.5702\n",
      "Epoch 939/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0021e-04 - val_loss: 0.5731\n",
      "Epoch 940/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.9670e-05 - val_loss: 0.5739\n",
      "Epoch 941/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.9651e-05 - val_loss: 0.5746\n",
      "Epoch 942/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.9386e-05 - val_loss: 0.5729\n",
      "Epoch 943/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.8734e-05 - val_loss: 0.5703\n",
      "Epoch 944/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.8447e-05 - val_loss: 0.5741\n",
      "Epoch 945/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.8013e-05 - val_loss: 0.5738\n",
      "Epoch 946/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.7948e-05 - val_loss: 0.5769\n",
      "Epoch 947/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.7385e-05 - val_loss: 0.5742\n",
      "Epoch 948/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.6916e-05 - val_loss: 0.5719\n",
      "Epoch 949/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.6747e-05 - val_loss: 0.5744\n",
      "Epoch 950/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.6386e-05 - val_loss: 0.5741\n",
      "Epoch 951/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.6211e-05 - val_loss: 0.5718\n",
      "Epoch 952/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.6176e-05 - val_loss: 0.5714\n",
      "Epoch 953/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.5276e-05 - val_loss: 0.5731\n",
      "Epoch 954/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.4928e-05 - val_loss: 0.5724\n",
      "Epoch 955/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.4633e-05 - val_loss: 0.5737\n",
      "Epoch 956/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.4264e-05 - val_loss: 0.5731\n",
      "Epoch 957/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.4228e-05 - val_loss: 0.5732\n",
      "Epoch 958/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 9.3692e-05 - val_loss: 0.5753\n",
      "Epoch 959/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.3775e-05 - val_loss: 0.5722\n",
      "Epoch 960/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.3248e-05 - val_loss: 0.5742\n",
      "Epoch 961/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.2759e-05 - val_loss: 0.5731\n",
      "Epoch 962/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.2409e-05 - val_loss: 0.5764\n",
      "Epoch 963/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 9.2221e-05 - val_loss: 0.5738\n",
      "Epoch 964/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.1837e-05 - val_loss: 0.5744\n",
      "Epoch 965/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.1322e-05 - val_loss: 0.5734\n",
      "Epoch 966/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.1083e-05 - val_loss: 0.5732\n",
      "Epoch 967/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.0538e-05 - val_loss: 0.5757\n",
      "Epoch 968/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.0505e-05 - val_loss: 0.5783\n",
      "Epoch 969/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.0186e-05 - val_loss: 0.5755\n",
      "Epoch 970/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 8.9822e-05 - val_loss: 0.5725\n",
      "Epoch 971/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.9592e-05 - val_loss: 0.5764\n",
      "Epoch 972/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.9446e-05 - val_loss: 0.5714\n",
      "Epoch 973/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.8679e-05 - val_loss: 0.5794\n",
      "Epoch 974/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.8540e-05 - val_loss: 0.5812\n",
      "Epoch 975/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.8364e-05 - val_loss: 0.5758\n",
      "Epoch 976/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.7649e-05 - val_loss: 0.5738\n",
      "Epoch 977/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.7686e-05 - val_loss: 0.5740\n",
      "Epoch 978/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.7086e-05 - val_loss: 0.5756\n",
      "Epoch 979/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.6853e-05 - val_loss: 0.5767\n",
      "Epoch 980/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.6715e-05 - val_loss: 0.5757\n",
      "Epoch 981/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.6283e-05 - val_loss: 0.5743\n",
      "Epoch 982/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 8.5809e-05 - val_loss: 0.5760\n",
      "Epoch 983/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.5699e-05 - val_loss: 0.5747\n",
      "Epoch 984/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.5363e-05 - val_loss: 0.5728\n",
      "Epoch 985/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.5306e-05 - val_loss: 0.5761\n",
      "Epoch 986/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.4837e-05 - val_loss: 0.5786\n",
      "Epoch 987/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.4563e-05 - val_loss: 0.5747\n",
      "Epoch 988/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.4213e-05 - val_loss: 0.5731\n",
      "Epoch 989/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.3893e-05 - val_loss: 0.5761\n",
      "Epoch 990/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.3774e-05 - val_loss: 0.5766\n",
      "Epoch 991/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 8.3284e-05 - val_loss: 0.5733\n",
      "Epoch 992/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.3207e-05 - val_loss: 0.5749\n",
      "Epoch 993/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.2846e-05 - val_loss: 0.5719\n",
      "Epoch 994/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.2734e-05 - val_loss: 0.5752\n",
      "Epoch 995/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.2295e-05 - val_loss: 0.5765\n",
      "Epoch 996/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.1900e-05 - val_loss: 0.5769\n",
      "Epoch 997/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.1681e-05 - val_loss: 0.5748\n",
      "Epoch 998/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.1686e-05 - val_loss: 0.5767\n",
      "Epoch 999/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.1315e-05 - val_loss: 0.5740\n",
      "Epoch 1000/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.0889e-05 - val_loss: 0.5764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2e064c03a0>"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, activation=\"relu\",input_shape=(4096,)))\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(40, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy')\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=1000, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "0.87\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "yy_pred = np.argmax(y_pred,axis=1)\n",
    "yy_test = np.argmax(y_test,axis=1)\n",
    "\n",
    "print(accuracy_score(yy_test,yy_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      0.50      0.67         2\n",
      "           3       0.67      1.00      0.80         2\n",
      "           4       0.67      1.00      0.80         4\n",
      "           5       1.00      1.00      1.00         5\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       1.00      0.50      0.67         2\n",
      "           8       1.00      1.00      1.00         2\n",
      "           9       1.00      1.00      1.00         3\n",
      "          10       1.00      1.00      1.00         4\n",
      "          11       0.75      1.00      0.86         3\n",
      "          12       1.00      1.00      1.00         3\n",
      "          13       1.00      1.00      1.00         1\n",
      "          14       1.00      1.00      1.00         4\n",
      "          15       0.75      1.00      0.86         3\n",
      "          16       1.00      1.00      1.00         1\n",
      "          17       0.50      1.00      0.67         2\n",
      "          18       1.00      1.00      1.00         3\n",
      "          19       1.00      0.83      0.91         6\n",
      "          20       1.00      0.33      0.50         3\n",
      "          21       1.00      1.00      1.00         3\n",
      "          22       1.00      1.00      1.00         2\n",
      "          23       1.00      1.00      1.00         3\n",
      "          24       1.00      1.00      1.00         3\n",
      "          27       1.00      1.00      1.00         3\n",
      "          28       0.50      1.00      0.67         3\n",
      "          29       1.00      0.50      0.67         2\n",
      "          30       0.50      1.00      0.67         1\n",
      "          31       1.00      0.75      0.86         4\n",
      "          32       1.00      1.00      1.00         1\n",
      "          33       1.00      1.00      1.00         3\n",
      "          34       1.00      1.00      1.00         4\n",
      "          35       1.00      0.50      0.67         2\n",
      "          36       1.00      1.00      1.00         1\n",
      "          37       0.50      0.20      0.29         5\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.87       100\n",
      "   macro avg       0.88      0.87      0.85       100\n",
      "weighted avg       0.90      0.87      0.86       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kaygun/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yy_test,yy_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
