{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "24aa875c-1b54-41d6-a8b4-41bd6d9e2a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.cluster.hierarchy as hc\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.spatial.distance as ssd\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2982bc4-dc8d-4d0c-b8c2-c195de06b0b9",
   "metadata": {},
   "source": [
    "# MAT 388E HW3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2793a97-fd44-48a5-90a2-6a2a9e5dfb4e",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "This is going to be an image classification problem. For this problem we are going to use [the corrected Indian Pines Dataset](https://www.ehu.eus/ccwintco/index.php?title=Hyperspectral_Remote_Sensing_Scenes#Indian_Pines).\n",
    "\n",
    "1. Download the data (both the corrected dataset and the ground-truth dataset) into a subdirectory called `data`, and ingest it as I did in [Lecture 8](https://github.com/kaygun/2022-Fall-388E/blob/main/lecture-8.ipynb).\n",
    "2. Instead of using a categorical target variable with 17 classes, from the ground-truth data you ingested create 17 binary classifiers using scikit-learn's [`LabelBinarizer`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html).\n",
    "\n",
    "For the steps 3,4, and 5 below write a properly written function that takes a model type ('LR','SVM', or 'KNN'), the independent variable (the dataset you ingested above) and binary target variable and returns the accuracy score of a properly constructed model given by a 10-fold cross-validation. Use scikitlearn's [cross validation](https://scikit-learn.org/stable/modules/cross_validation.html) routines. Record your results from Steps 2,3 and 4 in a pandas data frame.  \n",
    "\n",
    "3. Construct a logistic regression model for each of the 17 class, and evaluate them using a 10-fold cross-validation. \n",
    "4. Construct an SVM model for each of the 17 class, and evaluate them using a 10-fold cross-validation. \n",
    "5. Construct a KNN model for each of the 17 class and evaluate them using a 10-fold cross-validation. You must determine what would be an appropriate K-value for each class separately, or you may decide to use a single K-value.\n",
    "6. Display and analyze your cross-validation results in a table. What is the best model overall? What is the best model for each class? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a5187d-da9f-4cab-a770-3fc8eac37b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d55b8ac-78ba-433a-a5f5-bcb91b8d2803",
   "metadata": {},
   "source": [
    "## Q2\n",
    "\n",
    "For this question, we are going to analyze some [NBA datasets](https://sports-statistics.com/sports-data/nba-basketball-datasets-csv-files/). Specifically, we look at the season 2018-2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ea63d3d-6236-46cd-aab1-c37d4bda5eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'EVENTMSGACTIONTYPE', 'EVENTMSGTYPE', 'EVENTNUM',\n",
       "       'GAME_ID', 'HOMEDESCRIPTION', 'NEUTRALDESCRIPTION', 'PCTIMESTRING',\n",
       "       'PERIOD', 'PERSON1TYPE', 'PERSON2TYPE', 'PERSON3TYPE', 'PLAYER1_ID',\n",
       "       'PLAYER1_NAME', 'PLAYER1_TEAM_ABBREVIATION', 'PLAYER1_TEAM_CITY',\n",
       "       'PLAYER1_TEAM_ID', 'PLAYER1_TEAM_NICKNAME', 'PLAYER2_ID',\n",
       "       'PLAYER2_NAME', 'PLAYER2_TEAM_ABBREVIATION', 'PLAYER2_TEAM_CITY',\n",
       "       'PLAYER2_TEAM_ID', 'PLAYER2_TEAM_NICKNAME', 'PLAYER3_ID',\n",
       "       'PLAYER3_NAME', 'PLAYER3_TEAM_ABBREVIATION', 'PLAYER3_TEAM_CITY',\n",
       "       'PLAYER3_TEAM_ID', 'PLAYER3_TEAM_NICKNAME', 'SCORE', 'SCOREMARGIN',\n",
       "       'VISITORDESCRIPTION', 'WCTIMESTRING'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBA = pd.read_csv('https://sports-statistics.com/database/basketball-data/nba/2018-19_pbp.csv')\n",
    "NBA.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd77fc41-fb2b-4717-b61d-9a8ec7bc4607",
   "metadata": {},
   "source": [
    "1. Using the columns `PLAYER1_TEAM_ABBREVIATION`, `PLAYER2_TEAM_ABBREVIATION`, `PLAYER3_TEAM_ABBREVIATION` construct a 30x30 matrix that has the total number of interactions the teams had during the season.\n",
    "2. Using the matrix you constructed in the previous step, construct a hiearchical clustering model and split the NBA teams into 2 clusters.\n",
    "3. NBA Teams are split into 2 Leagues: [The Eastern Conference](https://en.wikipedia.org/wiki/Eastern_Conference_(NBA)) and [The Western Conference](https://en.wikipedia.org/wiki/Western_Conference_(NBA)). What is the relationships of the clusters with these leagues. Explain.\n",
    "4. Using the columns `PLAYER1_NAME`, `PLAYER2_NAME`, `PLAYER3_NAME` construct a matrix (don't display) that has the total number of interactions the players had during the season. Then keep the players that has more than 500 interactions during the season, and display the resulting matrix.\n",
    "5. Using the matrix you constructed in the previous step, draw a dendrogram of the players (with 500 or more interactions), and decide how many clusters are appropriate.\n",
    "6. Using the matrix and the dendrogram you constructed in the previous steps, construct a hiearchical clustering model for the players and split them into the number of clusters you determined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941c9613-b016-45d3-878d-2ea312ab6f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1197e7e6-c471-4065-8b0f-5129410b4779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
